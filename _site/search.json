[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "hands-on_ex/hands-on_ex02/hands-on_ex02.html",
    "href": "hands-on_ex/hands-on_ex02/hands-on_ex02.html",
    "title": "Hands-On Exercise 2: Choropleth Mapping with R",
    "section": "",
    "text": "In this exercise, we will go through how to plot functional and truthful choropleth maps by using the tmap package in R."
  },
  {
    "objectID": "hands-on_ex/hands-on_ex02/hands-on_ex02.html#import-tidyverse-tmap-and-sf",
    "href": "hands-on_ex/hands-on_ex02/hands-on_ex02.html#import-tidyverse-tmap-and-sf",
    "title": "Hands-On Exercise 2: Choropleth Mapping with R",
    "section": "Import tidyverse, tmap, and sf",
    "text": "Import tidyverse, tmap, and sf\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "hands-on_ex/hands-on_ex02/hands-on_ex02.html#importing-data",
    "href": "hands-on_ex/hands-on_ex02/hands-on_ex02.html#importing-data",
    "title": "Hands-On Exercise 2: Choropleth Mapping with R",
    "section": "Importing data",
    "text": "Importing data\n\nMaster Plan 2014 Subzone Boundary (Web)\n\nmpsz <- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\guga-nesh\\IS415-GAA\\hands-on_ex\\hands-on_ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\nSG Residents by Planning Area, Age Group, Sex and Type of Dwelling\nAlthough this data set does not include any coordinate values, its PA and SZ fields can be used as unique identifiers to geocode the data.\n\npopdata <- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\npopdata\n\n# A tibble: 984,656 × 7\n   PA         SZ                     AG     Sex     TOD                Pop  Time\n   <chr>      <chr>                  <chr>  <chr>   <chr>            <dbl> <dbl>\n 1 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 1- and 2-Ro…     0  2011\n 2 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 3-Room Flats    10  2011\n 3 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 4-Room Flats    30  2011\n 4 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HDB 5-Room and …    50  2011\n 5 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   HUDC Flats (exc…     0  2011\n 6 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   Landed Properti…     0  2011\n 7 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   Condominiums an…    40  2011\n 8 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males   Others               0  2011\n 9 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females HDB 1- and 2-Ro…     0  2011\n10 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Females HDB 3-Room Flats    10  2011\n# … with 984,646 more rows"
  },
  {
    "objectID": "hands-on_ex/hands-on_ex02/hands-on_ex02.html#data-preparation",
    "href": "hands-on_ex/hands-on_ex02/hands-on_ex02.html#data-preparation",
    "title": "Hands-On Exercise 2: Choropleth Mapping with R",
    "section": "Data Preparation",
    "text": "Data Preparation\nPrepare a data table with the year 2020 values. The table should include the following variables: PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\npopdata2020 <- popdata %>%\n  filter(Time == 2020) %>%\n  group_by(PA, SZ, AG) %>%\n  summarise(`POP` = sum(`Pop`)) %>%\n  ungroup()%>%\n  pivot_wider(names_from=AG, \n              values_from=POP) %>%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %>%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%>%\nmutate(`AGED`=rowSums(.[16:21])) %>%\nmutate(`TOTAL`=rowSums(.[3:21])) %>%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %>%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n# convert the values in PA and SZ fields to uppercase since the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase\n\npopdata2020 <- popdata2020 %>%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = funs(toupper)) %>%\n  filter(`ECONOMY ACTIVE` > 0)\n\n\n# left join geographical data and attribute table using planning subzone name and sz as the common identifier -- output will be a simple features dataframe\n\nmpsz_pop2020 <- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "hands-on_ex/hands-on_ex02/hands-on_ex02.html#choropleth-mapping-using-tmap",
    "href": "hands-on_ex/hands-on_ex02/hands-on_ex02.html#choropleth-mapping-using-tmap",
    "title": "Hands-On Exercise 2: Choropleth Mapping with R",
    "section": "Choropleth Mapping using tmap",
    "text": "Choropleth Mapping using tmap\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\nCreating a more detailed map using tmap’s elements:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\nDrawing a base map\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\nDrawing maps using tm_fill() and tm_border()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\nalpha = used to define transparency number between 0 (totally transparent) and 1 (not transparent).\ncol = border colour\nlwd = border line width (default = 1)\nlty = border line type (default is “solid”)\n\n\n\nData classification methods of tmap\nThere are 10 different classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks. For instance:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nDIY\nPrepare chloropleth maps using different classification methods supported by tmap and compare their differences.\nPrepare choropleth maps by using the same classification method but with different number of classes (i.e., 2, 6, 10, 20). Compare the output maps, what observation can you draw?\n\n\nPlotting choropleth map using custome break\n\n# always good practice to get some descriptive stats on the variable before setting the break points\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\nColour Scheme\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "hands-on_ex/hands-on_ex03/hands-on_ex03.html",
    "href": "hands-on_ex/hands-on_ex03/hands-on_ex03.html",
    "title": "Hands-On Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Spatial Point Pattern Analysis is the evaluation of the pattern or distribution, of a set of points on a surface. Using appropriate functions of spatstat, this exercise aims to discover the spatial point processes of childcare centers in Singapore."
  },
  {
    "objectID": "hands-on_ex/hands-on_ex03/hands-on_ex03.html#installing-and-loading-the-relevant-packages",
    "href": "hands-on_ex/hands-on_ex03/hands-on_ex03.html#installing-and-loading-the-relevant-packages",
    "title": "Hands-On Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "2 Installing and loading the relevant packages",
    "text": "2 Installing and loading the relevant packages\n\npacman::p_load(maptools, sf, raster, spatstat, tmap)"
  },
  {
    "objectID": "hands-on_ex/hands-on_ex03/hands-on_ex03.html#spatial-data-wrangling",
    "href": "hands-on_ex/hands-on_ex03/hands-on_ex03.html#spatial-data-wrangling",
    "title": "Hands-On Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "3 Spatial Data Wrangling",
    "text": "3 Spatial Data Wrangling\n\n3.1 Importing the spatial data\n\nchildcare_sf <- st_read(\"data/child-care-services-geojson.geojson\") %>%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\guga-nesh\\IS415-GAA\\hands-on_ex\\hands-on_ex03\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf <- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\guga-nesh\\IS415-GAA\\hands-on_ex\\hands-on_ex03\\data' using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf <- st_read(dsn = \"data\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\guga-nesh\\IS415-GAA\\hands-on_ex\\hands-on_ex03\\data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n3.2 Ensure all data is projected in the same projection system\n\nchildcare_df_ps = st_crs(childcare_sf)\nchildcare_df_ps\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\nsg_sf_ps = st_crs(sg_sf)\nsg_sf_ps\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n# does not have proper crs information\n\n\nmpsz_sf_ps = st_crs(mpsz_sf)\nmpsz_sf_ps\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n# does not have proper crs information\n\n\n# they do not have proper crs information, we need to transform them to the Singapore national projected coordinate system\n\nsg_sf = st_transform(sg_sf, 3414)\nmpsz_sf = st_transform(mpsz_sf, 3414)\n\n\n# crs transformed!\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n# crs transformed!\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n3.3 Mapping the geospatial data sets\n\ntmap_mode(\"plot\")\nqtm(childcare_sf, \n    fill = \"Name\")\n\n\n\n# for some reason, unable to get the map lines\n\n\n# we can also create a pin map - by using an interactive map we can navigate and zoom around the map freely\n\ntmap_mode('plot') # this was 'view'\ntm_shape(childcare_sf)+\n  tm_dots()"
  },
  {
    "objectID": "hands-on_ex/hands-on_ex03/hands-on_ex03.html#geospatial-data-wrangling",
    "href": "hands-on_ex/hands-on_ex03/hands-on_ex03.html#geospatial-data-wrangling",
    "title": "Hands-On Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4 Geospatial Data Wrangling",
    "text": "4 Geospatial Data Wrangling\n\n4.1 Converting sf data frames to sp’s Spatial class\n\nchildcare <- as_Spatial(childcare_sf)\nmpsz <- as_Spatial(mpsz_sf)\nsg <- as_Spatial(sg_sf)\n\n\nprint(childcare)\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>018989</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>08F73931F4A691F4</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center> \nmax values  : kml_999,                  <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>829646</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>RAFFLES KIDZ @ PUNGGOL PTE LTD</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>379D017BF244B0FA</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center> \n\nprint(mpsz)\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\nprint(sg)\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND \n\n\n\n\n4.2 Converting Spatial classes into generic sp format\nspatstat requires the analytical data in ppp object form. There is no direct way to convert a Spatial Class into ppp object so we convert them into Spatial object first.\n\nchildcare_sp <- as(childcare, \"SpatialPoints\")\nsg_sp <- as(sg, \"SpatialPolygons\")\n\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\n\n4.3 Converting the generic sp format into spatstat’s ppp format\n\nchildcare_ppp <- as(childcare_sp, \"ppp\")\nchildcare_ppp\n\nPlanar point pattern: 1545 points\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\n\nplot(childcare_ppp)\n\n\n\n\n\nsummary(childcare_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\n\n\n4.4 Handling duplicated points\nLet’s check if there are any duplicated points…\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\nSo there are duplicated points. We need to use the multiplicity() function to count the number of points.\n\n# to find out the number of locations with duplicated points:\nsum(multiplicity(childcare_ppp) > 1)\n\n[1] 128\n\n\nLet’s view these locations\n\ntmap_mode('view')\ntm_shape(childcare) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\n\n\nThere are three ways to overcome this problem:\n\nDelete duplicates - some useful point events will be lost\nJittering - add a small pertubation to the duplicate points so they do not occupy the exact same space\nMake each point “unique” - attach duplicates of the points to the patterns as marks (attributes of the points). Then you would need analytical techniques that account for these marks.\n\n\n# Jittering\nchildcare_ppp_jit <- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE\n\n\n\n\n4.5 Creating an owinobject\nWhen analysing spatial point patterns, it is good practice to confine the analysis with a geographical area like the Singapore boundary. In spatstat an object called owin helps represent this polygonal region\n\nsg_owin <- as(sg_sp, \"owin\")\n\n\n# owin obj can be displayed using plot()\nplot(sg_owin)\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n60 separate polygons (no holes)\n            vertices        area relative.area\npolygon 1         38 1.56140e+04      2.09e-05\npolygon 2        735 4.69093e+06      6.27e-03\npolygon 3         49 1.66986e+04      2.23e-05\npolygon 4         76 3.12332e+05      4.17e-04\npolygon 5       5141 6.36179e+08      8.50e-01\npolygon 6         42 5.58317e+04      7.46e-05\npolygon 7         67 1.31354e+06      1.75e-03\npolygon 8         15 4.46420e+03      5.96e-06\npolygon 9         14 5.46674e+03      7.30e-06\npolygon 10        37 5.26194e+03      7.03e-06\npolygon 11        53 3.44003e+04      4.59e-05\npolygon 12        74 5.82234e+04      7.78e-05\npolygon 13        69 5.63134e+04      7.52e-05\npolygon 14       143 1.45139e+05      1.94e-04\npolygon 15       165 3.38736e+05      4.52e-04\npolygon 16       130 9.40465e+04      1.26e-04\npolygon 17        19 1.80977e+03      2.42e-06\npolygon 18        16 2.01046e+03      2.69e-06\npolygon 19        93 4.30642e+05      5.75e-04\npolygon 20        90 4.15092e+05      5.54e-04\npolygon 21       721 1.92795e+06      2.57e-03\npolygon 22       330 1.11896e+06      1.49e-03\npolygon 23       115 9.28394e+05      1.24e-03\npolygon 24        37 1.01705e+04      1.36e-05\npolygon 25        25 1.66227e+04      2.22e-05\npolygon 26        10 2.14507e+03      2.86e-06\npolygon 27       190 2.02489e+05      2.70e-04\npolygon 28       175 9.25904e+05      1.24e-03\npolygon 29      1993 9.99217e+06      1.33e-02\npolygon 30        38 2.42492e+04      3.24e-05\npolygon 31        24 6.35239e+03      8.48e-06\npolygon 32        53 6.35791e+05      8.49e-04\npolygon 33        41 1.60161e+04      2.14e-05\npolygon 34        22 2.54368e+03      3.40e-06\npolygon 35        30 1.08382e+04      1.45e-05\npolygon 36       327 2.16921e+06      2.90e-03\npolygon 37       111 6.62927e+05      8.85e-04\npolygon 38        90 1.15991e+05      1.55e-04\npolygon 39        98 6.26829e+04      8.37e-05\npolygon 40       415 3.25384e+06      4.35e-03\npolygon 41       222 1.51142e+06      2.02e-03\npolygon 42       107 6.33039e+05      8.45e-04\npolygon 43         7 2.48299e+03      3.32e-06\npolygon 44        17 3.28303e+04      4.38e-05\npolygon 45        26 8.34758e+03      1.11e-05\npolygon 46       177 4.67446e+05      6.24e-04\npolygon 47        16 3.19460e+03      4.27e-06\npolygon 48        15 4.87296e+03      6.51e-06\npolygon 49        66 1.61841e+04      2.16e-05\npolygon 50       149 5.63430e+06      7.53e-03\npolygon 51       609 2.62570e+07      3.51e-02\npolygon 52         8 7.82256e+03      1.04e-05\npolygon 53       976 2.33447e+07      3.12e-02\npolygon 54        55 8.25379e+04      1.10e-04\npolygon 55       976 2.33447e+07      3.12e-02\npolygon 56        61 3.33449e+05      4.45e-04\npolygon 57         6 1.68410e+04      2.25e-05\npolygon 58         4 9.45963e+03      1.26e-05\npolygon 59        46 6.99702e+05      9.35e-04\npolygon 60        13 7.00873e+04      9.36e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 748741000 square units\nFraction of frame area: 0.414\n\n\n\n\n4.6 Combining point events object and owin object\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\n\nsummary(childcareSG_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 2.063463e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: polygonal boundary\n60 separate polygons (no holes)\n            vertices        area relative.area\npolygon 1         38 1.56140e+04      2.09e-05\npolygon 2        735 4.69093e+06      6.27e-03\npolygon 3         49 1.66986e+04      2.23e-05\npolygon 4         76 3.12332e+05      4.17e-04\npolygon 5       5141 6.36179e+08      8.50e-01\npolygon 6         42 5.58317e+04      7.46e-05\npolygon 7         67 1.31354e+06      1.75e-03\npolygon 8         15 4.46420e+03      5.96e-06\npolygon 9         14 5.46674e+03      7.30e-06\npolygon 10        37 5.26194e+03      7.03e-06\npolygon 11        53 3.44003e+04      4.59e-05\npolygon 12        74 5.82234e+04      7.78e-05\npolygon 13        69 5.63134e+04      7.52e-05\npolygon 14       143 1.45139e+05      1.94e-04\npolygon 15       165 3.38736e+05      4.52e-04\npolygon 16       130 9.40465e+04      1.26e-04\npolygon 17        19 1.80977e+03      2.42e-06\npolygon 18        16 2.01046e+03      2.69e-06\npolygon 19        93 4.30642e+05      5.75e-04\npolygon 20        90 4.15092e+05      5.54e-04\npolygon 21       721 1.92795e+06      2.57e-03\npolygon 22       330 1.11896e+06      1.49e-03\npolygon 23       115 9.28394e+05      1.24e-03\npolygon 24        37 1.01705e+04      1.36e-05\npolygon 25        25 1.66227e+04      2.22e-05\npolygon 26        10 2.14507e+03      2.86e-06\npolygon 27       190 2.02489e+05      2.70e-04\npolygon 28       175 9.25904e+05      1.24e-03\npolygon 29      1993 9.99217e+06      1.33e-02\npolygon 30        38 2.42492e+04      3.24e-05\npolygon 31        24 6.35239e+03      8.48e-06\npolygon 32        53 6.35791e+05      8.49e-04\npolygon 33        41 1.60161e+04      2.14e-05\npolygon 34        22 2.54368e+03      3.40e-06\npolygon 35        30 1.08382e+04      1.45e-05\npolygon 36       327 2.16921e+06      2.90e-03\npolygon 37       111 6.62927e+05      8.85e-04\npolygon 38        90 1.15991e+05      1.55e-04\npolygon 39        98 6.26829e+04      8.37e-05\npolygon 40       415 3.25384e+06      4.35e-03\npolygon 41       222 1.51142e+06      2.02e-03\npolygon 42       107 6.33039e+05      8.45e-04\npolygon 43         7 2.48299e+03      3.32e-06\npolygon 44        17 3.28303e+04      4.38e-05\npolygon 45        26 8.34758e+03      1.11e-05\npolygon 46       177 4.67446e+05      6.24e-04\npolygon 47        16 3.19460e+03      4.27e-06\npolygon 48        15 4.87296e+03      6.51e-06\npolygon 49        66 1.61841e+04      2.16e-05\npolygon 50       149 5.63430e+06      7.53e-03\npolygon 51       609 2.62570e+07      3.51e-02\npolygon 52         8 7.82256e+03      1.04e-05\npolygon 53       976 2.33447e+07      3.12e-02\npolygon 54        55 8.25379e+04      1.10e-04\npolygon 55       976 2.33447e+07      3.12e-02\npolygon 56        61 3.33449e+05      4.45e-04\npolygon 57         6 1.68410e+04      2.25e-05\npolygon 58         4 9.45963e+03      1.26e-05\npolygon 59        46 6.99702e+05      9.35e-04\npolygon 60        13 7.00873e+04      9.36e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 748741000 square units\nFraction of frame area: 0.414\n\n\n\nplot(childcareSG_ppp)"
  },
  {
    "objectID": "hands-on_ex/hands-on_ex03/hands-on_ex03.html#first-order-spatial-point-patterns-analysis",
    "href": "hands-on_ex/hands-on_ex03/hands-on_ex03.html#first-order-spatial-point-patterns-analysis",
    "title": "Hands-On Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "5 First-order Spatial Point Patterns Analysis",
    "text": "5 First-order Spatial Point Patterns Analysis\n\n5.1 Kernel Density Estimation\nThis section is to compute the kernel density estimation (KDE) of childcare services in Singapore.\n\n# we use the density() function of spatstat\n# bw.diggle - automatic bandwidth selection method\n# the smoothening kernel used is gaussian (default)\n# the intensity estimate is corrected for edge effect bias\nkde_childcareSG_bw <- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\n\nplot(kde_childcareSG_bw)\n\n\n\n\nThe density values are too small to comprehend. This is because the default measurement of svy21 is in meter. As a result, the density values computed is in “number of points per square meter”.\n\n# good to know you can retrieve the bandwidth like so:\nbw <- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n298.4095 \n\n\n\n\n5.2 Rescalling KDE values\n\n# convert unit of measurement from m to km using rescale()\nchildcareSG_ppp.km <- rescale(childcareSG_ppp, 1000, \"km\")\n\n\nkde_childcareSG.bw <- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG.bw)\n\n\n\n\n\n\n5.3 Working with different automatic bandwidth methods\n\n bw.CvL(childcareSG_ppp.km)\n\n   sigma \n4.543278 \n\n\n\nbw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\n\n\nbw.ppl(childcareSG_ppp.km)\n\n    sigma \n0.3897114 \n\n\n\nbw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.2984095 \n\n\nBaddeley et. (2016) suggested the use of the bw.ppl() algorithm because in their experience it tends to produce the more appropriate values when the pattern consists predominantly of tight clusters. But they also insist that if the purpose of study is to detect a single tight cluster in the midst of random noise then the bw.diggle() method seems to work best. So let’s compare the output using bw.diggle and bw.ppl methods:\n\nkde_childcareSG.ppl <- density(childcareSG_ppp.km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n5.4 Working with different kernel methods\n\npar(mfrow=c(2,2))\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")"
  },
  {
    "objectID": "hands-on_ex/hands-on_ex03/hands-on_ex03.html#fixed-and-adaptive-kde",
    "href": "hands-on_ex/hands-on_ex03/hands-on_ex03.html#fixed-and-adaptive-kde",
    "title": "Hands-On Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "6 Fixed and Adaptive KDE",
    "text": "6 Fixed and Adaptive KDE\n\n6.1 Computing KDE by using fixed bandwidth\n\n# using bw of 600m\nkde_childcareSG_600 <- density(childcareSG_ppp.km, sigma=0.6, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG_600)\n\n\n\n\n\n\n6.2 Computing KDE by using adaptive bandwidth\nFixed bandwidth is very sensitive to highly skewed distribution of spatial point patterns over geographical units (e.g., urban vs rural). One way to overcome this is by using adaptive bandwidth.\n\nkde_childcareSG_adaptive <- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n# Compare fixed and adaptive KDE outputs\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\n\n\n6.3 Converting KDE output into grid object\nThe result is the same, we just convert it so that it is suitable for mapping purposes.\n\ngridded_kde_childcareSG_bw <- as.SpatialGridDataFrame.im(kde_childcareSG.bw)\nspplot(gridded_kde_childcareSG_bw)\n\n\n\n\n\n\n6.4 Convert gridded output into raster\n\nkde_childcareSG_bw_raster <- raster(gridded_kde_childcareSG_bw)\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\n\n\n6.5 Assigning projection systems\n\nprojection(kde_childcareSG_bw_raster) <- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +init=EPSG:3414 \nsource     : memory\nnames      : v \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\n\n\n6.6 Visualising output in tmap\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"v\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\n\n\n\n\n\n\n6.7 Comparing Spatial Point Patterns using KDE\nWe will be comparing the KDE of childcares at Punggol, Tampines, CCK, and Jurong West planning areas.\n\n# Extract study areas\npg = mpsz[mpsz@data$PLN_AREA_N == \"PUNGGOL\",]\ntm = mpsz[mpsz@data$PLN_AREA_N == \"TAMPINES\",]\nck = mpsz[mpsz@data$PLN_AREA_N == \"CHOA CHU KANG\",]\njw = mpsz[mpsz@data$PLN_AREA_N == \"JURONG WEST\",]\n\n\n# plot target planning areas\npar(mfrow=c(2,2))\nplot(pg, main = \"Ponggol\")\nplot(tm, main = \"Tampines\")\nplot(ck, main = \"Choa Chu Kang\")\nplot(jw, main = \"Jurong West\")\n\n\n\n\n\n# convert spatial point datafrane into generic sp format\npg_sp = as(pg, \"SpatialPolygons\")\ntm_sp = as(tm, \"SpatialPolygons\")\nck_sp = as(ck, \"SpatialPolygons\")\njw_sp = as(jw, \"SpatialPolygons\")\n\n\n# convert SpatialPolygons object into owin objects required by spatstat\npg_owin = as(pg_sp, \"owin\")\ntm_owin = as(tm_sp, \"owin\")\nck_owin = as(ck_sp, \"owin\")\njw_owin = as(jw_sp, \"owin\")\n\n\n# combine childcare points with study areas\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\n\n# use rescale() to transform unit of measurement to km\nchildcare_pg_ppp.km = rescale(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale(childcare_jw_ppp, 1000, \"km\")\n\n\n# plot output\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\n\n\n\n\n# computing KDE\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Jurong West\")\n\n\n\n\n\n# computing fixed bandwidth KDE\npar(mfrow=c(2,2))\nplot(density(childcare_ck_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Chou Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Jurong West\")\nplot(density(childcare_pg_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")"
  },
  {
    "objectID": "hands-on_ex/hands-on_ex03/hands-on_ex03.html#nearest-neighbour-analysis",
    "href": "hands-on_ex/hands-on_ex03/hands-on_ex03.html#nearest-neighbour-analysis",
    "title": "Hands-On Exercise 3: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "7 Nearest Neighbour Analysis",
    "text": "7 Nearest Neighbour Analysis\nWe will perform the Clark-Evans test of aggregation for a spatial point pattern by using clarkevans.test() of spatstat. The hypothesis are:\n\nH0: Distribution of childcare services are randomly distributed\nH1: Distribution of childcare services are not randomly distributed\n\nThe 95% confident interval will be used. If the index is:\n\n*\n\n\n7.1 Testing spatial point patterns using Clark and Evans Test\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99) # minimum is 99... which is 100 simulations\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 99 simulations of CSR with fixed n\n\ndata:  childcareSG_ppp\nR = 0.54756, p-value = 0.01\nalternative hypothesis: clustered (R < 1)\n\n\n\n\n7.2 Clark and Evans Test: CCK planning area\n\n\n\n\n\nclarkevans.test(childcare_ck_ppp,\n\n\n      correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 999 simulations of CSR with fixed n\n\ndata:  childcare_ck_ppp\nR = 0.96368, p-value = 0.178\nalternative hypothesis: two-sided\n\n\n\n\n\n\n\n\n7.3 Clark and Evans Test: Tampines planning area\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 999 simulations of CSR with fixed n\n\ndata:  childcare_tm_ppp\nR = 0.79322, p-value = 0.002\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "hands-on_ex/hands-on_ex05/hands-on_ex05.html",
    "href": "hands-on_ex/hands-on_ex05/hands-on_ex05.html",
    "title": "Hands-On Exercise 7A: Global Measures of Spatial Autocorrelation",
    "section": "",
    "text": "In this hands-on exercise, we will be computing Global and Local Measure of Spatial Autocorrelation (GLSA) using the spdep package."
  },
  {
    "objectID": "hands-on_ex/hands-on_ex05/hands-on_ex05.html#setup",
    "href": "hands-on_ex/hands-on_ex05/hands-on_ex05.html#setup",
    "title": "Hands-On Exercise 7A: Global Measures of Spatial Autocorrelation",
    "section": "2 Setup",
    "text": "2 Setup\n\n2.1 Understanding The Context\nIn spatial policy, one of the main development objective of the local government and planners is to ensure equal distribution of development in the province. Our task in this study is to apply appropriate spatial statistical methods to discover if developments are evenly distributed geographically.\nIf the answer is No. Then we need to check if there are signs of spatial clustering and where are they.\n\n\n2.2 Study Area and Data\n\n\n\n\n\n\n\n\n\nType\nName\nFormat\nDescription\n\n\n\n\nGeospatial\nHunan Province Administrative Boundary\n.shp\nData is at the County level.\n\n\nAspatial\nHunan_2012\n.xlsx\nSelected Hunan’s local development indicators in 2012.\n\n\n\n\n\n2.3 Packages used\n\nsf - used for importing and handling geospatial data in R\ntidyverse - mainly used for wrangling attribute data in R\nspdep - to compute spatial weights, global and local spatial autocorrelation statistics\ntmap - to prepare cartographic quality chropleth map\n\n\npacman::p_load(sf, tidyverse, spdep, tmap)"
  },
  {
    "objectID": "hands-on_ex/hands-on_ex05/hands-on_ex05.html#importing-geospatial-data",
    "href": "hands-on_ex/hands-on_ex05/hands-on_ex05.html#importing-geospatial-data",
    "title": "Hands-On Exercise 7A: Global Measures of Spatial Autocorrelation",
    "section": "3 Importing Geospatial Data",
    "text": "3 Importing Geospatial Data\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\guga-nesh\\IS415-GAA\\hands-on_ex\\hands-on_ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\n\n\n\nNote\n\n\n\nst_read() of sf package is used to import shapefile into R as a simple features object. Please refer to the documentation here."
  },
  {
    "objectID": "hands-on_ex/hands-on_ex05/hands-on_ex05.html#importing-aspatial-data",
    "href": "hands-on_ex/hands-on_ex05/hands-on_ex05.html#importing-aspatial-data",
    "title": "Hands-On Exercise 7A: Global Measures of Spatial Autocorrelation",
    "section": "4 Importing Aspatial Data",
    "text": "4 Importing Aspatial Data\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")"
  },
  {
    "objectID": "hands-on_ex/hands-on_ex05/hands-on_ex05.html#data-wrangling",
    "href": "hands-on_ex/hands-on_ex05/hands-on_ex05.html#data-wrangling",
    "title": "Hands-On Exercise 7A: Global Measures of Spatial Autocorrelation",
    "section": "5 Data Wrangling",
    "text": "5 Data Wrangling\n\n5.1 Performing relational join\n\nhunan <- left_join(hunan,hunan2012) %>%\n  select(1:4, 7, 15)\n\n# auto takes the columns that exist in both objects\n\n\n\n\n\n\n\nNote\n\n\n\nThe above code chunk will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute field of hunan2012 dataframe. This is performed by using left_join() of dplyr package."
  },
  {
    "objectID": "hands-on_ex/hands-on_ex05/hands-on_ex05.html#basic-esda",
    "href": "hands-on_ex/hands-on_ex05/hands-on_ex05.html#basic-esda",
    "title": "Hands-On Exercise 7A: Global Measures of Spatial Autocorrelation",
    "section": "6 Basic ESDA",
    "text": "6 Basic ESDA\n\n6.1 Visualising Regional Development Indicator\nWe will prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nequal <- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile <- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "hands-on_ex/hands-on_ex05/hands-on_ex05.html#global-spatial-autocorrelation",
    "href": "hands-on_ex/hands-on_ex05/hands-on_ex05.html#global-spatial-autocorrelation",
    "title": "Hands-On Exercise 7A: Global Measures of Spatial Autocorrelation",
    "section": "7 Global Spatial Autocorrelation",
    "text": "7 Global Spatial Autocorrelation\nIn this section, we will compute the global spatial autocorrelation statistics and to perform spatial complete randomness test for global spatial autocorrelation.\n\n7.1 Computing Contiguity Spatial Weights\nBefore we can compute the global spatial autocorrelation statistics, we need to construct the spatial weights of the study area (to define the neighbourhood relationships between the counties in the study area).\n\ncw_queen <- poly2nb(hunan,\n                    queen=TRUE)\n\nsummary(cw_queen)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\n\n\n\n\n\n\nNote\n\n\n\npoly2nb() of spdep package is used to compute contiguity weight matrices for the study area by building a neighbours list based on regions with contiguous boundaries using Queen’s method. Please refer to the documentation here.\n\n\nThe summary report shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours while there are two least connected area units with only 1 neighbour.\n\n\n7.2 Row-standardised weights matrix\nNext, we need to assign weights to each neighbouring polygon. In our case each neighbour will be assigned equal weight (i.e., style = \"W\"). This is accomplished by assigning (1/# of neighbours) to each neighbouring county then summing the weighted income values. One drawback is that the polygons along the edge of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data.\nstyle = \"B\" is a more robust option. Others are available as well…\n\nrswm_queen <- nb2listw(cw_queen,\n                       style = \"W\",\n                       zero.policy = TRUE)\n\nrswm_queen\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\n\n\n\n\nNote\n\n\n\nInput of nb2list2() must be an object of class nb.\n\nstyle can take values “W”, “B”. “C”, “U”, “minmax”, and “S”. (Refer to in-class_ex06)\nIf zero.policy is set to TRUE, weight vectors of zero length are inserted for regions without neighbour in the neighbours list. This will generate lag values of zero…\n\n\n\n\n\n7.3 Global Spatial Autocorrelation: Moran’s I\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_queen, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_queen    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\n\n\n\n\n\nNote\n\n\n\nuse moran.test() of spdep to perform Moran’s I statistical testing. Please refer to the documentation here.\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuestion: What statistical conclusion can you draw from the output above?\nThe Moran’s I statistic is 0.30074990 which is close to 0. Hence, we can deduce that the observations are arranged randomly over the study area.\n\n\n\n7.3.1 Computing Monte Carlo Moran’s I\n\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_queen, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_queen  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou can perform permutation test for Moran’s I statistic by using moran.mc() of spdep. A total of 100 simulations were performed. Please refer to the documentation here.\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuestion: What statistical conclusion can you draw from the output above?\n\n\n\n\n7.3.2 Visualising Monte Carlo Moran’s I\nIt is always good practice for us to examine the simulated Moran’s I test statistics in greater detail. This can be achieved by plotting the distribution of the statistical values as a histogram.\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\") \n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe have used hist() and abline() of R Graphics to draw the histogram. Please refer to their respective documentations here and here.\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuestion: What statistical observation can you draw from the output above?\n\n\n\n\n\n\n\n\nNote\n\n\n\nChallenge: Instead of using Base Graph to plot the values, plot the values by using ggplot2 package.\n\n# code here:\n\n\n\n\n\n\n7.4 Global Spatial Autocorrelation: Geary’s\n\n7.4.1 Geary’s C Test\n\ngeary.test(hunan$GDPPC, listw=rswm_queen)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_queen \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\n\n\n\n\n\nNote\n\n\n\nuse geary.test() of spdep to perform Geary’s C test for spatial autocorrelation.\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuestion: What statistical conclusion can you draw from the output above?\n\n\n\n\n7.4.2 Computing Monte Carlo Geary’s C\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_queen, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_queen \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n\n\n\n\nNote\n\n\n\nPerform Geary’s C test for spatial autocorrelation by using geary.test() of spdep. Please refer to the documentation here.\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuestion: What statistical conclusion can you draw from the output above?\n\n\n\n\n7.4.3 Visualising the Monte Carlo Geary’s C\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\n\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\")"
  },
  {
    "objectID": "hands-on_ex/hands-on_ex05/hands-on_ex05.html#spatial-correlogram",
    "href": "hands-on_ex/hands-on_ex05/hands-on_ex05.html#spatial-correlogram",
    "title": "Hands-On Exercise 7A: Global Measures of Spatial Autocorrelation",
    "section": "8 Spatial Correlogram",
    "text": "8 Spatial Correlogram\nSpatial Correlograms are useful in examining patterns of spatial autocorrelation in your data or model residuals. They show how correlated pairs of spatial observations are as you increase the distance (i.e., lag) between them. But… they are not as fundamental as variogramsbut are useful as an exploratory and descriptive tool. For this purpose they actually provide richer information than variograms.\n\n8.1 Compute Moran I’s correlogram\n\nMI_corr <- sp.correlogram(cw_queen, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe have used sp_correlogram() of spdep package to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used is Moran’s I. The plot() of base Graph is used to plot the output.\n\n\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nImportant to fully print out the analysis results as not all autocorrelation values are statistically significant.\n\n\n\n\n\n\nNote\n\n\n\nQuestion: What statistical observation can you draw from the plot above?\n\n\n\n\n8.2 Compute Geary’s C correlogram and plot\n\nGC_corr <- sp.correlogram(cw_queen, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "hands-on_ex/hands-on_ex06/hands-on_ex06.html",
    "href": "hands-on_ex/hands-on_ex06/hands-on_ex06.html",
    "title": "Hands-On Exercise 7B: Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "Before we dive into this Hands-On Exercise, it should be noted that this is exercise contains steps from Hands-On Exercise 7A from Section 1 - 4."
  },
  {
    "objectID": "hands-on_ex/hands-on_ex06/hands-on_ex06.html#overview",
    "href": "hands-on_ex/hands-on_ex06/hands-on_ex06.html#overview",
    "title": "Hands-On Exercise 7B: Local Measures of Spatial Autocorrelation",
    "section": "1 Overview",
    "text": "1 Overview\nWe will be computing the Global and Local Measure of Spatial Autocorrelation (GLSA) by using the spdep package."
  },
  {
    "objectID": "hands-on_ex/hands-on_ex06/hands-on_ex06.html#setup",
    "href": "hands-on_ex/hands-on_ex06/hands-on_ex06.html#setup",
    "title": "Hands-On Exercise 7B: Local Measures of Spatial Autocorrelation",
    "section": "2 Setup",
    "text": "2 Setup\n\n2.1 Understanding The Context\nIn spatial policy, one of the main development objective of the local government and planners is to ensure equal distribution of development in the province. Our task in this study is to apply appropriate spatial statistical methods to discover if developments are evenly distributed geographically.If the answer is No. Then we need to check if there are signs of spatial clustering and where are they.\n\n\n2.2 Study Area and Data\n\n\n2.3 Understanding The Context\nIn spatial policy, one of the main development objective of the local government and planners is to ensure equal distribution of development in the province. Our task in this study is to apply appropriate spatial statistical methods to discover if developments are evenly distributed geographically.\nIf the answer is No. Then we need to check if there are signs of spatial clustering and where are they.\n\n\n2.4 Study Area and Data\n\n\n\n\n\n\n\n\n\nType\nName\nFormat\nDescription\n\n\n\n\nGeospatial\nHunan Province Administrative Boundary\n.shp\nData is at the County level.\n\n\nAspatial\nHunan_2012\n.xlsx\nSelected Hunan’s local development indicators in 2012.\n\n\n\n\n\n2.5 Packages used\n\nsf - used for importing and handling geospatial data in R\ntidyverse - mainly used for wrangling attribute data in R\nspdep - to compute spatial weights, global and local spatial autocorrelation statistics\ntmap - to prepare cartographic quality chropleth map\n\n\npacman::p_load(sf, tidyverse, spdep, tmap)\n\n\n\n2.6 Importing Geospatial Data\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\guga-nesh\\IS415-GAA\\hands-on_ex\\hands-on_ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n2.7 Importing Aspatial Data\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\n\n2.8 Performing relational join\n\nhunan <- left_join(hunan,hunan2012) %>%\n  select(1:4, 7, 15)\n\n\n\n2.9 Visualising Regional Development Indicator\n\nequal <- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile <- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "hands-on_ex/hands-on_ex06/hands-on_ex06.html#global-spatial-autocorrelation",
    "href": "hands-on_ex/hands-on_ex06/hands-on_ex06.html#global-spatial-autocorrelation",
    "title": "Hands-On Exercise 7B: Local Measures of Spatial Autocorrelation",
    "section": "3 Global Spatial Autocorrelation",
    "text": "3 Global Spatial Autocorrelation\n\n3.1 Computing Contiguity Spatial Weights\n\nwm_q <- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\n\n\n3.2 Row-standardised weights matrix\n\nrswm_q <- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\n3.3 Global Spatial Autocorrelation: Moran’s I\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\n\n\n\n\n\nNote\n\n\n\nQuestion: What statistical conclusion can you draw from the output above?\n\n\n\n3.3.1 Computing Monte Carlo Moran’s I\n\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuestion: What statistical conclusion can you draw from the output above?\n\n\n\n\n3.3.2 Visualising Monte Carlo Moran’s I\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\") \n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuestion: What statistical conclusion can you draw from the output above?\n\n\n\n\n\n3.4 Global Spatial Autocorrelation: Geary’s\n\n3.4.1 Geary’s C test\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\n\n\n\n\n\nNote\n\n\n\nQuestion: What statistical conclusion can you draw from the output above?\n\n\n\n\n3.4.2 Computing Monte Carlo Geary’s C\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuestion: What statistical conclusion can you draw from the output above?\n\n\n\n\n3.4.3 Visualising the Monte Carlo Geary’s C\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\n\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\") \n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuestion: What statistical observation can you draw from the output?"
  },
  {
    "objectID": "hands-on_ex/hands-on_ex06/hands-on_ex06.html#spatial-correlogram",
    "href": "hands-on_ex/hands-on_ex06/hands-on_ex06.html#spatial-correlogram",
    "title": "Hands-On Exercise 7B: Local Measures of Spatial Autocorrelation",
    "section": "4 Spatial Correlogram",
    "text": "4 Spatial Correlogram\n\n4.1 Compute Moran’s I correlogram\n\nMI_corr <- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuestion: What statistical observation can you draw from the plot above?\n\n\n\n\n4.2 Compute Geary’s C correlogram and plot\n\nGC_corr <- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "hands-on_ex/hands-on_ex06/hands-on_ex06.html#cluster-and-outlier-analysis",
    "href": "hands-on_ex/hands-on_ex06/hands-on_ex06.html#cluster-and-outlier-analysis",
    "title": "Hands-On Exercise 7B: Local Measures of Spatial Autocorrelation",
    "section": "5 Cluster and Outlier Analysis",
    "text": "5 Cluster and Outlier Analysis\nNow we get to the main part of this Hands-On Exercise 😎\nLocal Indicators of Spatial Association (i.e., LISA) are statistics that evaluate the existence of clusters in the spatial arrangement of a given variable. For instance, if we are studying cancer rates among census tracts in a given city, clusters in the rates mean that there are areas that have higher or lower rates than is to be expected by chance alone. Basically, the values occurring are above or below those of a random distribution in space.\nIn this section, we will be applying appropriate LISA, especially Moran’s I to detect cluster and/or outlier from GDP per capita of Hunan Province, China (2012).\n\n5.1 Computing local Moran’s I\n\nfips <- order(hunan$County)\nlocalMI <- localmoran(hunan$GDPPC, rswm_q)\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe localmoran() function of spdep is used to compute local Moran’s I. It computes li (the local Moran’s I statistics) values, given a set of zi values and a weights list object.\n\nli - the local Moran’s I statistics\nE.li - expectation of local moran statistics under the randomisation hypothesis\nVar.li - the variance of local moran statistic under the randomisation hypothesis\nZ.li - the standard deviate of local moran statistic\nPr() - the p-value of local moran statistic\n\n\n\n\nprintCoefmat(data.frame(\n  localMI[fips,], \n  row.names=hunan$County[fips]),\n  check.names=FALSE)\n\n                       Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua         -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren         -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang       -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing        3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling        2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning     -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\nChangsha       4.9022e+00 -2.1348e-01  2.3194e+00  3.3590e+00         0.0008\nChengbu        7.3725e-01 -1.0534e-02  2.2132e-01  1.5895e+00         0.1119\nChenxi         1.4544e-01 -2.8156e-03  4.7116e-02  6.8299e-01         0.4946\nCili           7.3176e-02 -1.6747e-03  4.7902e-02  3.4200e-01         0.7324\nDao            2.1420e-01 -2.0824e-03  4.4123e-02  1.0297e+00         0.3032\nDongan         1.5210e-01 -6.3485e-04  1.3471e-02  1.3159e+00         0.1882\nDongkou        5.2918e-01 -6.4461e-03  1.0748e-01  1.6338e+00         0.1023\nFenghuang      1.8013e-01 -6.2832e-03  1.3257e-01  5.1198e-01         0.6087\nGuidong       -5.9160e-01 -1.3086e-02  3.7003e-01 -9.5104e-01         0.3416\nGuiyang        1.8240e-01 -3.6908e-03  3.2610e-02  1.0305e+00         0.3028\nGuzhang        2.8466e-01 -8.5054e-03  1.4152e-01  7.7931e-01         0.4358\nHanshou        2.5878e-02 -6.0620e-04  1.0167e-02  2.6266e-01         0.7928\nHengdong       9.9964e-03 -4.9063e-04  6.7742e-03  1.2742e-01         0.8986\nHengnan        2.8064e-02 -3.2160e-04  3.7597e-03  4.6294e-01         0.6434\nHengshan      -5.8201e-03 -3.0437e-05  5.1076e-04 -2.5618e-01         0.7978\nHengyang       6.2997e-02 -1.3046e-03  2.1865e-02  4.3486e-01         0.6637\nHongjiang      1.8790e-01 -2.3019e-03  3.1725e-02  1.0678e+00         0.2856\nHuarong       -1.5389e-02 -1.8667e-03  8.1030e-02 -4.7503e-02         0.9621\nHuayuan        8.3772e-02 -8.5569e-04  2.4495e-02  5.4072e-01         0.5887\nHuitong        2.5997e-01 -5.2447e-03  1.1077e-01  7.9685e-01         0.4255\nJiahe         -1.2431e-01 -3.0550e-03  5.1111e-02 -5.3633e-01         0.5917\nJianghua       2.8651e-01 -3.8280e-03  8.0968e-02  1.0204e+00         0.3076\nJiangyong      2.4337e-01 -2.7082e-03  1.1746e-01  7.1800e-01         0.4728\nJingzhou       1.8270e-01 -8.5106e-04  2.4363e-02  1.1759e+00         0.2396\nJinshi        -1.1988e-02 -5.3666e-03  1.1334e-01 -1.9667e-02         0.9843\nJishou        -2.8680e-01 -2.6305e-03  4.4028e-02 -1.3543e+00         0.1756\nLanshan        6.3334e-02 -9.6365e-04  2.0441e-02  4.4972e-01         0.6529\nLeiyang        1.1581e-02 -1.4948e-04  2.5082e-03  2.3422e-01         0.8148\nLengshuijiang -1.7903e+00 -8.2129e-02  2.1598e+00 -1.1623e+00         0.2451\nLi             1.0225e-03 -2.4048e-07  5.1060e-06  4.5260e-01         0.6508\nLianyuan      -1.4672e-01 -1.8983e-03  1.9145e-02 -1.0467e+00         0.2952\nLiling         1.3774e+00 -1.5097e-02  4.2601e-01  2.1335e+00         0.0329\nLinli          1.4815e-02 -6.8294e-05  1.4499e-03  3.9086e-01         0.6959\nLinwu         -2.4621e-03 -9.0703e-06  1.9258e-04 -1.7676e-01         0.8597\nLinxiang       6.5904e-02 -2.9028e-03  2.5470e-01  1.3634e-01         0.8916\nLiuyang        3.3688e+00 -7.7502e-02  1.5180e+00  2.7972e+00         0.0052\nLonghui        8.0801e-01 -1.1377e-02  1.5538e-01  2.0787e+00         0.0376\nLongshan       7.5663e-01 -1.1100e-02  3.1449e-01  1.3690e+00         0.1710\nLuxi           1.8177e-01 -2.4855e-03  3.4249e-02  9.9561e-01         0.3194\nMayang         2.1852e-01 -5.8773e-03  9.8049e-02  7.1663e-01         0.4736\nMiluo          1.8704e+00 -1.6927e-02  2.7925e-01  3.5715e+00         0.0004\nNan           -9.5789e-03 -4.9497e-04  6.8341e-03 -1.0988e-01         0.9125\nNingxiang      1.5607e+00 -7.3878e-02  8.0012e-01  1.8274e+00         0.0676\nNingyuan       2.0910e-01 -7.0884e-03  8.2306e-02  7.5356e-01         0.4511\nPingjiang     -9.8964e-01 -2.6457e-03  5.6027e-02 -4.1698e+00         0.0000\nQidong         1.1806e-01 -2.1207e-03  2.4747e-02  7.6396e-01         0.4449\nQiyang         6.1966e-02 -7.3374e-04  8.5743e-03  6.7712e-01         0.4983\nRucheng       -3.6992e-01 -8.8999e-03  2.5272e-01 -7.1814e-01         0.4727\nSangzhi        2.5053e-01 -4.9470e-03  6.8000e-02  9.7972e-01         0.3272\nShaodong      -3.2659e-02 -3.6592e-05  5.0546e-04 -1.4510e+00         0.1468\nShaoshan       2.1223e+00 -5.0227e-02  1.3668e+00  1.8583e+00         0.0631\nShaoyang       5.9499e-01 -1.1253e-02  1.3012e-01  1.6807e+00         0.0928\nShimen        -3.8794e-02 -3.8603e-04  6.4756e-03 -4.7729e-01         0.6332\nShuangfeng     9.2835e-03 -2.2867e-03  3.1516e-02  6.5174e-02         0.9480\nShuangpai      8.0591e-02 -3.1366e-04  8.9838e-03  8.5358e-01         0.3933\nSuining        3.7585e-01 -3.5933e-03  4.1870e-02  1.8544e+00         0.0637\nTaojiang      -2.5394e-01 -1.2395e-03  1.4477e-02 -2.1002e+00         0.0357\nTaoyuan        1.4729e-02 -1.2039e-04  8.5103e-04  5.0903e-01         0.6107\nTongdao        4.6482e-01 -6.9870e-03  1.9879e-01  1.0582e+00         0.2900\nWangcheng      4.4220e+00 -1.1067e-01  1.3596e+00  3.8873e+00         0.0001\nWugang         7.1003e-01 -7.8144e-03  1.0710e-01  2.1935e+00         0.0283\nXiangtan       2.4530e-01 -3.6457e-04  3.2319e-03  4.3213e+00         0.0000\nXiangxiang     2.6271e-01 -1.2703e-03  2.1290e-02  1.8092e+00         0.0704\nXiangyin       5.4525e-01 -4.7442e-03  7.9236e-02  1.9539e+00         0.0507\nXinhua         1.1810e-01 -6.2649e-03  8.6001e-02  4.2409e-01         0.6715\nXinhuang       1.5725e-01 -4.1820e-03  3.6648e-01  2.6667e-01         0.7897\nXinning        6.8928e-01 -9.6674e-03  2.0328e-01  1.5502e+00         0.1211\nXinshao        5.7578e-02 -8.5932e-03  1.1769e-01  1.9289e-01         0.8470\nXintian       -7.4050e-03 -5.1493e-03  1.0877e-01 -6.8395e-03         0.9945\nXupu           3.2406e-01 -5.7468e-03  5.7735e-02  1.3726e+00         0.1699\nYanling       -6.9021e-02 -5.9211e-04  9.9306e-03 -6.8667e-01         0.4923\nYizhang       -2.6844e-01 -2.2463e-03  4.7588e-02 -1.2202e+00         0.2224\nYongshun       6.3064e-01 -1.1350e-02  1.8830e-01  1.4795e+00         0.1390\nYongxing       4.3411e-01 -9.0735e-03  1.5088e-01  1.1409e+00         0.2539\nYou            7.8750e-02 -7.2728e-03  1.2116e-01  2.4714e-01         0.8048\nYuanjiang      2.0004e-04 -1.7760e-04  2.9798e-03  6.9181e-03         0.9945\nYuanling       8.7298e-03 -2.2981e-06  2.3221e-05  1.8121e+00         0.0700\nYueyang        4.1189e-02 -1.9768e-04  2.3113e-03  8.6085e-01         0.3893\nZhijiang       1.0476e-01 -7.8123e-04  1.3100e-02  9.2214e-01         0.3565\nZhongfang     -2.2685e-01 -2.1455e-03  3.5927e-02 -1.1855e+00         0.2358\nZhuzhou        3.2864e-01 -5.2432e-04  7.2391e-03  3.8688e+00         0.0001\nZixing        -7.6849e-01 -8.8210e-02  9.4057e-01 -7.0144e-01         0.4830\n\n\n\n\n\n\n\n\nNote\n\n\n\nprintCoefmat() is used to list the content of the local Moran matrix derived. Please see the documentation here.\n\n\n\n5.1.1 Mapping the local Moran’s I\nBefore mapping the local Moran’s I, it is wise to append the local Moran’s I dataframe (i.e., localMI) onto hunan(which is a SpatialPolygonDataFrame).\n\nhunan.localMI <- cbind(hunan,localMI) %>%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n5.1.2 Mapping local Moran’s I p-values\nThe choropleth shows us that there is evidence for both positive and negative li values. However, it is useful to consider the p-values for each of those values.\n\n\n\n\n\n\nNote\n\n\n\nWhy is the p-value important?\n\n\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n5.1.3 Mapping both local Moran’s I values and p-values\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\n\nlocalMI.map <- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map <- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)"
  },
  {
    "objectID": "hands-on_ex/hands-on_ex06/hands-on_ex06.html#creating-a-lisa-cluster-map",
    "href": "hands-on_ex/hands-on_ex06/hands-on_ex06.html#creating-a-lisa-cluster-map",
    "title": "Hands-On Exercise 7B: Local Measures of Spatial Autocorrelation",
    "section": "6 Creating a LISA Cluster Map",
    "text": "6 Creating a LISA Cluster Map\nThe LISA Cluster Map shows the significant locations color coded by type of spatial autocorrelation. The first step before we can generate the LISA cluster map is to plot the Moran scatterplot.\n\n6.1 Plotting Moran scatterplot\nThe Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighbouring locations.\n\nnci <- moran.plot(hunan$GDPPC, rswm_q,\n                  labels=as.character(hunan$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe use moran.plot() of spdep package to plot the Moran scatterplot of GDPPC 2012. Please refer to the documentation here.\n\n\nThe plot is split into 4 quadrants. The top right corner belongs to areas that have high GDPPC and are surrounded by other areas that have the average level of GDPPC. This quadrant contains the “high-high” locations in the lesson slide. Refer to the slide image below:\n\n\n\nHH = high surrounded by high (cluster)\nLH = low surrounded by high (outliers)\nHL = high surrounded by low (outliers)\nLL = low surrounded by low (cluster)\n\n\n\n\n6.2 Plotting Moran scatterplot with standardised variable\n\nhunan$Z.GDPPC <- scale(hunan$GDPPC) %>% \n  as.vector \n\n\n\n\n\n\n\nNote\n\n\n\n\nuse scale() to center and scale the variable. Centering is done by subtracting the mean of the corresponding columns and scaling is done by diving the (centered) variables by their s.d.\nadd as.vector()to the end to make sure the output data type is a vector. This ensures that it can be mapped neatly.\n\n\n\n\nnci2 <- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels=as.character(hunan$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuestion: Why plot Moran scatterplot with standardised variable?\n\n\n\n\n6.3 Preparing LISA map classes\nIn this section we will look at how to prepare a LISA cluster map.\nStep 1: Create the quadrant object (we will use this to create the 4 areas in Step 5)\n\nquadrant <- vector(mode=\"numeric\",length=nrow(localMI))\n\nStep 2: Derive the spatially lagged variable of interest (i.e., GDPPC) and center it around its mean\n\nhunan$lag_GDPPC <- lag.listw(rswm_q, hunan$GDPPC)\nDV <- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \n\nStep 3: Center the local Moran’s around the mean\n\nLM_I <- localMI[,1] - mean(localMI[,1])    \n\nStep 4: Set the statistical significance level for the local Moran\n\nsignif <- 0.05\n\nStep 5: Define LL, LH, HL, and HH categories using the quadrant variable\n\nquadrant[DV <0 & LM_I>0] <- 1\nquadrant[DV >0 & LM_I<0] <- 2\nquadrant[DV <0 & LM_I<0] <- 3  \nquadrant[DV >0 & LM_I>0] <- 4      \n\nStep 6: place non-significant Moran in category 0\n\nquadrant[localMI[,5]>signif] <- 0\n\n\n\n6.4 Plotting the LISA map\n\ngdppc <- qtm(hunan, \"GDPPC\")\n\nhunan.localMI$quadrant <- quadrant\ncolors <- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters <- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap <- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote: For effective interpretation, is it better to plot both the GDPPC values map and its corresponding quadrants map next to each other. This is to show proof of which are the clusters and which aren’t. Those not part of the “quadrant” map are basically not statistically significant and we cannot put them in the quadrants.\nWe can also include the local Moran’s I map and p-value map as shown below for easy comparison.\n\n\n\nlocalMI.map <- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map <- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuestion: What statistical observations can you draw from the LISA map above?"
  },
  {
    "objectID": "hands-on_ex/hands-on_ex06/hands-on_ex06.html#emerging-hot-spot-and-cold-spot-area-analysis",
    "href": "hands-on_ex/hands-on_ex06/hands-on_ex06.html#emerging-hot-spot-and-cold-spot-area-analysis",
    "title": "Hands-On Exercise 7B: Local Measures of Spatial Autocorrelation",
    "section": "7 Emerging Hot Spot and Cold Spot Area Analysis",
    "text": "7 Emerging Hot Spot and Cold Spot Area Analysis\nBesides detecting clusters and outliers, localised spatial statistics can also be used to detect hot spot and/or cold spot areas.\nHot Spot = describes a region or value that is higher relative to its surroundings.\nLISA is to help us understand clusters and outliers but this one helps to identify Hot and Cold Spots. While yes, they are related (since Hot and Cold Spots are clusters), this helps us distinguish clusters from HH (i.e., Hot Spot) and LL (Cold Spot)\n\n\n\n\n\n\nNote\n\n\n\nThe goal of EHSA is to evaluate how cold or hot spots are changing over time. It helps us answer the questions: are they becoming increasingly hotter, are they cooling down, or are they staying the same?\nWe need to use Mann-Kendall test to assess whether a set of data values is increasing or decreasing over time. Please refer to this article for more info. Do note that the Mann-Kendall test does not assess the magnitude of change. Example of H0 and H1 = “There is no monotonic trend in the series” and “A trend exists”. Please refer to the data requirements here.\nTo use Mann-Kendall test effectively, need to show trendline and map it out as well. Then, use this slide and this slide to describe it.\n\n\n\n7.1 Getis and Ord’s G-Statistics\nGetis and Ord’s G-statistics is an alternative spatial statistics method to detect spatial anomalies. It looks at neighbours within a defined proximity to identify where either high or low values cluster spatially.\nHere, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values.\nThis analysis has three steps:\n\nDeriving spatial weight matrix\nComputing Gi statistics\nMapping Gi statistics\n\n\n\n7.2 Deriving distance-based weight matrix\nFirst we need to define a new set of neighbours. Whilst the spatial autocorrelation considered units which shared borders, for Getis-Ord we are defining neighbours based on distance.\nRemember, there are two types of distance-based proximity matrix:\n\nfixed distance weight matrix\nadaptive distance weight matrix\n\n\n7.2.1 Deriving the centroid\nWe need the points to be associated with each polygon before we can before we can make our connectivity graph. But this is not so simple, we need to get the coordinates in a separate dataframe for this to work.\nWe need to use a mapping function (it applies a given function to each element of a vector and returns a vector of the same length)\n\n\n\n\n\n\nNote\n\n\n\nOur function to be mapped is st_centroid() over the geometry column. map_dbl() variation of map from the purr package will be used as the mapping function.\n\n\n\nlongitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\n\nlatitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\n\ncoords <- cbind(longitude, latitude)\n\n\n\n7.2.2 Determine the cut-off distance\nTo determine the upper limit for the distance band we need to:\n\nreturn a matrix with the indices of the points belonging to the set of k nearest neighbours by using knearneigh() of spdep package. Please refer to the documentation here.\nconvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region ids by using knn2nb(). Please refer to the documentation here.\nreturn the length of relationship edges by using nbdists() of spdep. The function returns the units of coords in if they are projected. Else, its in km. Please refer to the documentation here.\nremove the list structure of the returned object by using unlist(). Please refer to the documentation here.\n\n\n#coords <- coordinates(hunan)\nk1 <- knn2nb(knearneigh(coords))\nk1dists <- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe above summary report shows that the largest first nearest neighbour distance is 61.79km. So let’s use this as the upper threshold to be certain that all units will have at least one neighbour.\n\n\n7.2.3 Computing fixed distance weight matrix\n\nwm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\n\n\n\n\n\n\nNote\n\n\n\nWe use dnearneigh() to compute the distance weight matrix. Please refer to the documentation here.\n\n\n\nwm62_lw <- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n#nb2listw() is used to convert the nb object into spatial weights object (i.e., wm62_lw)\n\n\n\n7.2.4 Computing adaptive distance weight matrix\nUsing fixed weight distance means that more densely settled areas (i.e., urban areas) tend to have more neighbours than the less densely settled areas (i.e., rural counties).\nHaving many neighbours smooths the neighbour relationship across more neighbours. So we can control the number of neighbours using k-nearest neighbours and either accepting asymmetric neighbours or imposing symmetry as shown in this code chunk below.\n\nknn <- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\n\nknn_lw <- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014\n\n\n\n\n\n7.3 Computing Gi statistics\n\n7.3.1 Gi statistics using fixed distance\n\nfips <- order(hunan$County)\ngi.fixed <- localG(hunan$GDPPC, wm62_lw)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.064192949 0.05747126 2.375922e-04  0.436075843   6.627817e-01\n [2,] 0.042300020 0.04597701 1.917951e-04 -0.265505650   7.906200e-01\n [3,] 0.044961480 0.04597701 1.933486e-04 -0.073033665   9.417793e-01\n [4,] 0.039475779 0.03448276 1.461473e-04  0.413017033   6.795941e-01\n [5,] 0.049767939 0.04597701 1.927263e-04  0.273070579   7.847990e-01\n [6,] 0.008825335 0.01149425 4.998177e-05 -0.377510776   7.057941e-01\n [7,] 0.050807266 0.02298851 9.435398e-05  2.863898821   4.184617e-03\n [8,] 0.083966739 0.04597701 1.848292e-04  2.794350420   5.200409e-03\n [9,] 0.115751554 0.04597701 1.789361e-04  5.216125401   1.827045e-07\n[10,] 0.049115587 0.04597701 1.891013e-04  0.228236603   8.194623e-01\n[11,] 0.045819180 0.03448276 1.420884e-04  0.951035346   3.415864e-01\n[12,] 0.049183846 0.05747126 2.387633e-04 -0.536334231   5.917276e-01\n[13,] 0.048429181 0.04597701 1.924532e-04  0.176761556   8.596957e-01\n[14,] 0.034733752 0.02298851 9.651140e-05  1.195564020   2.318667e-01\n[15,] 0.011262043 0.01149425 4.945294e-05 -0.033020610   9.736582e-01\n[16,] 0.065131196 0.04597701 1.931870e-04  1.378081093   1.681783e-01\n[17,] 0.027587075 0.03448276 1.385862e-04 -0.585756761   5.580390e-01\n[18,] 0.029409313 0.03448276 1.461397e-04 -0.419680565   6.747188e-01\n[19,] 0.061466754 0.05747126 2.383385e-04  0.258805141   7.957856e-01\n[20,] 0.057656917 0.05747126 2.371303e-04  0.012056111   9.903808e-01\n[21,] 0.066518379 0.06896552 2.820326e-04 -0.145716531   8.841452e-01\n[22,] 0.045599896 0.04597701 1.928108e-04 -0.027158687   9.783332e-01\n[23,] 0.030646753 0.03448276 1.449523e-04 -0.318615290   7.500183e-01\n[24,] 0.035635552 0.04597701 1.906613e-04 -0.748946051   4.538897e-01\n[25,] 0.032606647 0.04597701 1.932888e-04 -0.961700582   3.362000e-01\n[26,] 0.035001352 0.04597701 1.897172e-04 -0.796851342   4.255374e-01\n[27,] 0.012746354 0.02298851 9.812587e-05 -1.033949773   3.011596e-01\n[28,] 0.061287917 0.06896552 2.773884e-04 -0.460979158   6.448136e-01\n[29,] 0.014277403 0.02298851 9.683314e-05 -0.885240161   3.760271e-01\n[30,] 0.009622875 0.01149425 4.924586e-05 -0.266671512   7.897221e-01\n[31,] 0.014258398 0.02298851 9.705244e-05 -0.886168613   3.755267e-01\n[32,] 0.005453443 0.01149425 4.986245e-05 -0.855476971   3.922871e-01\n[33,] 0.043283712 0.05747126 2.367109e-04 -0.922143185   3.564539e-01\n[34,] 0.020763514 0.03448276 1.393165e-04 -1.162328599   2.451020e-01\n[35,] 0.081261843 0.06896552 2.794398e-04  0.735582222   4.619850e-01\n[36,] 0.057419907 0.05747126 2.338437e-04 -0.003358489   9.973203e-01\n[37,] 0.013497133 0.02298851 9.624821e-05 -0.967459309   3.333145e-01\n[38,] 0.019289310 0.03448276 1.455643e-04 -1.259299080   2.079223e-01\n[39,] 0.025996272 0.04597701 1.892938e-04 -1.452256513   1.464303e-01\n[40,] 0.016092694 0.03448276 1.424776e-04 -1.540671121   1.233968e-01\n[41,] 0.035952614 0.05747126 2.379439e-04 -1.395011407   1.630124e-01\n[42,] 0.031690963 0.05747126 2.350604e-04 -1.681505286   9.266481e-02\n[43,] 0.018750079 0.03448276 1.433314e-04 -1.314110709   1.888090e-01\n[44,] 0.015449080 0.02298851 9.638666e-05 -0.767944457   4.425202e-01\n[45,] 0.065760689 0.06896552 2.760533e-04 -0.192889342   8.470456e-01\n[46,] 0.098966900 0.05747126 2.326002e-04  2.720804542   6.512325e-03\n[47,] 0.085415780 0.05747126 2.385746e-04  1.809191360   7.042128e-02\n[48,] 0.038816536 0.05747126 2.343951e-04 -1.218469473   2.230456e-01\n[49,] 0.038931873 0.04597701 1.893501e-04 -0.511984469   6.086619e-01\n[50,] 0.055098610 0.06896552 2.760948e-04 -0.834546363   4.039732e-01\n[51,] 0.033405005 0.04597701 1.916312e-04 -0.908179070   3.637836e-01\n[52,] 0.043040784 0.06896552 2.829941e-04 -1.541081516   1.232969e-01\n[53,] 0.011297699 0.02298851 9.615920e-05 -1.192199867   2.331829e-01\n[54,] 0.040968457 0.05747126 2.356318e-04 -1.075080164   2.823388e-01\n[55,] 0.023629663 0.04597701 1.877170e-04 -1.631075961   1.028743e-01\n[56,] 0.006281129 0.01149425 4.916619e-05 -0.743472246   4.571958e-01\n[57,] 0.063918654 0.05747126 2.369553e-04  0.418842387   6.753313e-01\n[58,] 0.070325003 0.05747126 2.381374e-04  0.832943753   4.048765e-01\n[59,] 0.025947288 0.03448276 1.444058e-04 -0.710289083   4.775249e-01\n[60,] 0.039752578 0.04597701 1.915656e-04 -0.449718820   6.529132e-01\n[61,] 0.049934283 0.05747126 2.334965e-04 -0.493238743   6.218439e-01\n[62,] 0.030964195 0.04597701 1.920248e-04 -1.083386776   2.786368e-01\n[63,] 0.058129184 0.05747126 2.343319e-04  0.042979051   9.657182e-01\n[64,] 0.046096514 0.04597701 1.932637e-04  0.008596093   9.931414e-01\n[65,] 0.012459080 0.01149425 5.008051e-05  0.136337469   8.915545e-01\n[66,] 0.091447733 0.05747126 2.377744e-04  2.203411744   2.756574e-02\n[67,] 0.049575872 0.02298851 9.766513e-05  2.690329952   7.138140e-03\n[68,] 0.107907212 0.04597701 1.933581e-04  4.453703219   8.440175e-06\n[69,] 0.019616151 0.02298851 9.789454e-05 -0.340842743   7.332220e-01\n[70,] 0.032923393 0.03448276 1.454032e-04 -0.129318589   8.971056e-01\n[71,] 0.030317663 0.02298851 9.867859e-05  0.737806634   4.606320e-01\n[72,] 0.019437582 0.03448276 1.455870e-04 -1.246912658   2.124295e-01\n[73,] 0.055245460 0.04597701 1.932838e-04  0.666667559   5.049845e-01\n[74,] 0.074278054 0.05747126 2.383538e-04  1.088613505   2.763244e-01\n[75,] 0.013269580 0.02298851 9.719982e-05 -0.985792573   3.242349e-01\n[76,] 0.049407829 0.03448276 1.463785e-04  1.233609606   2.173484e-01\n[77,] 0.028605749 0.03448276 1.455139e-04 -0.487196415   6.261191e-01\n[78,] 0.039087662 0.02298851 9.801040e-05  1.626174042   1.039126e-01\n[79,] 0.031447120 0.04597701 1.877464e-04 -1.060416797   2.889550e-01\n[80,] 0.064005294 0.05747126 2.359641e-04  0.425361422   6.705732e-01\n[81,] 0.044606529 0.05747126 2.357330e-04 -0.837897118   4.020885e-01\n[82,] 0.063700493 0.06896552 2.801427e-04 -0.314565243   7.530918e-01\n[83,] 0.051142205 0.04597701 1.933560e-04  0.371456331   7.102977e-01\n[84,] 0.102121112 0.04597701 1.610278e-04  4.424392623   9.671399e-06\n[85,] 0.021901462 0.02298851 9.843172e-05 -0.109566928   9.127528e-01\n[86,] 0.064931813 0.04597701 1.929430e-04  1.364597995   1.723794e-01\n[87,] 0.031747344 0.04597701 1.909867e-04 -1.029658605   3.031703e-01\n[88,] 0.015893319 0.02298851 9.765131e-05 -0.718000620   4.727569e-01\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n# output of localG() is a vector of G or Gstar values with attributes\n# Gi statistics represented as a Z-score. Greater values = greater intensity of clustering and the direction (i.e., +ve or -ve) indicates high or low clusters.\n\n\nhunan.gi <- cbind(hunan, as.matrix(gi.fixed)) %>%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\n# this is to join the Gi values to their corresponding hunan sf dataframe\n# 1. convert output vector (i.e., gi.fixed) into r matrix object using as.matrix()\n# 2. use cbind() to join hunan and gi.fixed matrix to get a new SpatialPolygonDataFrame (i.e., hunan.gi)\n# 3. rename() used to rename gi values column name to gstat_fixed\n\n\n\n7.3.2 Mapping Gi values with fixed distance weights\n\ngdppc <- qtm(hunan, \"GDPPC\")\n\nGimap <-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuestion: What statistical observation can you draw from the Gi map above?\n\n\n\n\n7.3.3 Gi statistics using adaptive distance\n\nfips <- order(hunan$County)\ngi.adaptive <- localG(hunan$GDPPC, knn_lw)\nhunan.gi <- cbind(hunan, as.matrix(gi.adaptive)) %>%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\n\n7.3.4 Mapping Gi values with adaptive distance\n\ngdppc<- qtm(hunan, \"GDPPC\")\n\nGimap <- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuestion: What statistical observation can you draw from the Gi map above?"
  },
  {
    "objectID": "hands-on_ex/hands-on_ex07/hands-on_ex07.html",
    "href": "hands-on_ex/hands-on_ex07/hands-on_ex07.html",
    "title": "Hands-On Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "",
    "text": "Geographically weighted regression (GWR) is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and an outcome of interest (also known as dependent variable). In this hands-on exercise, you will learn how to build hedonic pricing models by using GWR methods. The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and locational data."
  },
  {
    "objectID": "hands-on_ex/hands-on_ex07/hands-on_ex07.html#overview-of-data-used",
    "href": "hands-on_ex/hands-on_ex07/hands-on_ex07.html#overview-of-data-used",
    "title": "Hands-On Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "2 Overview Of Data Used",
    "text": "2 Overview Of Data Used\n\n\n\n\n\n\n\n\n\nType\nName\nFormat\nDescription\n\n\n\n\nGeospatial\nMP14_SUBZONE_WEB_PL\n.shp\nURA Master Plan subzone boundary in shapefile format.\n\n\nAspatial\ncondo_resale_2015.csv\n.csv\nSpecific details of individual Condo units in 2015."
  },
  {
    "objectID": "hands-on_ex/hands-on_ex07/hands-on_ex07.html#leading-relevant-packages",
    "href": "hands-on_ex/hands-on_ex07/hands-on_ex07.html#leading-relevant-packages",
    "title": "Hands-On Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "3 Leading relevant packages",
    "text": "3 Leading relevant packages\n\nolsrr - for building OLS and performing diagnostic tests\nGWmodel - for calibrating geographical weighted family of models\n\n\n\n\n\n\nNote\n\n\n\n\n\nProvides a collection of localised spatial statistical methods, namely: GW summary statistics, GW principal components analysis, GW discriminant analysis and various forms of GW regression; some of which are provided in basic and robust (outlier resistant) forms. Commonly, outputs or parameters of the GWmodel are mapped to provide a useful exploratory tool, which can often precede (and direct) a more traditional or sophisticated statistical analysis.\n\n\n\ncorrplot - for multivariate data visualisation and analysis\nsf - spatial data handling\ntidyverse (readr, ggplot2, and dyplyr) - for handling attribute data\ntmap - for choropleth mapping\n\n\n\nShow code\n# do not load corrplot onto our memory using pacman\n\npacman::p_load(olsrr, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary)"
  },
  {
    "objectID": "hands-on_ex/hands-on_ex07/hands-on_ex07.html#geospatial-data-wrangling",
    "href": "hands-on_ex/hands-on_ex07/hands-on_ex07.html#geospatial-data-wrangling",
    "title": "Hands-On Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "4 Geospatial Data Wrangling",
    "text": "4 Geospatial Data Wrangling\n\n\nShow code\n# import and update CRS information\nmpsz = st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\") %>%\n  st_transform(crs = 3414)\n\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\guga-nesh\\IS415-GAA\\hands-on_ex\\hands-on_ex07\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nShow code\n# check crs\nst_crs(mpsz)\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\nShow code\n# reveal the extent of mpsz by using st_bbox()\nst_bbox(mpsz)\n\n\n     xmin      ymin      xmax      ymax \n 2667.538 15748.721 56396.440 50256.334"
  },
  {
    "objectID": "hands-on_ex/hands-on_ex07/hands-on_ex07.html#aspatial-data-wrangling",
    "href": "hands-on_ex/hands-on_ex07/hands-on_ex07.html#aspatial-data-wrangling",
    "title": "Hands-On Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "5 Aspatial Data Wrangling",
    "text": "5 Aspatial Data Wrangling\n\n5.1 Import & View Data\n\n\nShow code\n# read file into a tibble data frame\ncondo_resale = read_csv(\"data/aspatial/Condo_resale_2015.csv\")\n\n# see glimpse\nprint(glimpse(condo_resale))\n\n\nRows: 1,436\nColumns: 23\n$ LATITUDE             <dbl> 1.287145, 1.328698, 1.313727, 1.308563, 1.321437,…\n$ LONGITUDE            <dbl> 103.7802, 103.8123, 103.7971, 103.8247, 103.9505,…\n$ POSTCODE             <dbl> 118635, 288420, 267833, 258380, 467169, 466472, 3…\n$ SELLING_PRICE        <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1320…\n$ AREA_SQM             <dbl> 309, 290, 248, 127, 145, 139, 218, 141, 165, 168,…\n$ AGE                  <dbl> 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22, 6,…\n$ PROX_CBD             <dbl> 7.941259, 6.609797, 6.898000, 4.038861, 11.783402…\n$ PROX_CHILDCARE       <dbl> 0.16597932, 0.28027246, 0.42922669, 0.39473543, 0…\n$ PROX_ELDERLYCARE     <dbl> 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.121…\n$ PROX_URA_GROWTH_AREA <dbl> 6.618741, 7.505109, 6.463887, 4.906512, 6.410632,…\n$ PROX_HAWKER_MARKET   <dbl> 1.76542207, 0.54507614, 0.37789301, 1.68259969, 0…\n$ PROX_KINDERGARTEN    <dbl> 0.05835552, 0.61592412, 0.14120309, 0.38200076, 0…\n$ PROX_MRT             <dbl> 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.528…\n$ PROX_PARK            <dbl> 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.116…\n$ PROX_PRIMARY_SCH     <dbl> 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.709…\n$ PROX_TOP_PRIMARY_SCH <dbl> 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.709…\n$ PROX_SHOPPING_MALL   <dbl> 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.307…\n$ PROX_SUPERMARKET     <dbl> 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.581…\n$ PROX_BUS_STOP        <dbl> 0.10336166, 0.28673408, 0.28504777, 0.29872340, 0…\n$ NO_Of_UNITS          <dbl> 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34, 3…\n$ FAMILY_FRIENDLY      <dbl> 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD             <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n# A tibble: 1,436 × 23\n   LATIT…¹ LONGI…² POSTC…³ SELLI…⁴ AREA_…⁵   AGE PROX_…⁶ PROX_…⁷ PROX_…⁸ PROX_…⁹\n     <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1    1.29    104.  118635 3000000     309    30    7.94   0.166   2.52     6.62\n 2    1.33    104.  288420 3880000     290    32    6.61   0.280   1.93     7.51\n 3    1.31    104.  267833 3325000     248    33    6.90   0.429   0.502    6.46\n 4    1.31    104.  258380 4250000     127     7    4.04   0.395   1.99     4.91\n 5    1.32    104.  467169 1400000     145    28   11.8    0.119   1.12     6.41\n 6    1.31    104.  466472 1320000     139    22   10.3    0.125   0.789    5.09\n 7    1.32    104.  309502 3410000     218    24    4.24   0.326   1.33     5.18\n 8    1.32    104.  468497 1420000     141    24   11.6    0.162   0.813    6.14\n 9    1.28    104.  118450 2025000     165    27    6.46   0.123   1.82     6.78\n10    1.32    104.  268157 2550000     168    31    6.52   0.609   1.04     6.97\n# … with 1,426 more rows, 13 more variables: PROX_HAWKER_MARKET <dbl>,\n#   PROX_KINDERGARTEN <dbl>, PROX_MRT <dbl>, PROX_PARK <dbl>,\n#   PROX_PRIMARY_SCH <dbl>, PROX_TOP_PRIMARY_SCH <dbl>,\n#   PROX_SHOPPING_MALL <dbl>, PROX_SUPERMARKET <dbl>, PROX_BUS_STOP <dbl>,\n#   NO_Of_UNITS <dbl>, FAMILY_FRIENDLY <dbl>, FREEHOLD <dbl>,\n#   LEASEHOLD_99YR <dbl>, and abbreviated variable names ¹​LATITUDE, ²​LONGITUDE,\n#   ³​POSTCODE, ⁴​SELLING_PRICE, ⁵​AREA_SQM, ⁶​PROX_CBD, ⁷​PROX_CHILDCARE, …\n\n\nShow code\n# see data in XCOORD column\nprint(head(condo_resale$LONGITUDE))\n\n\n[1] 103.7802 103.8123 103.7971 103.8247 103.9505 103.9386\n\n\nShow code\n# see data in YCOORD column\nprint(head(condo_resale$LATITUDE))\n\n\n[1] 1.287145 1.328698 1.313727 1.308563 1.321437 1.314198\n\n\nShow code\n# see summary of data\nprint(summary(condo_resale))\n\n\n    LATITUDE       LONGITUDE        POSTCODE      SELLING_PRICE     \n Min.   :1.240   Min.   :103.7   Min.   : 18965   Min.   :  540000  \n 1st Qu.:1.309   1st Qu.:103.8   1st Qu.:259849   1st Qu.: 1100000  \n Median :1.328   Median :103.8   Median :469298   Median : 1383222  \n Mean   :1.334   Mean   :103.8   Mean   :440439   Mean   : 1751211  \n 3rd Qu.:1.357   3rd Qu.:103.9   3rd Qu.:589486   3rd Qu.: 1950000  \n Max.   :1.454   Max.   :104.0   Max.   :828833   Max.   :18000000  \n    AREA_SQM          AGE           PROX_CBD       PROX_CHILDCARE    \n Min.   : 34.0   Min.   : 0.00   Min.   : 0.3869   Min.   :0.004927  \n 1st Qu.:103.0   1st Qu.: 5.00   1st Qu.: 5.5574   1st Qu.:0.174481  \n Median :121.0   Median :11.00   Median : 9.3567   Median :0.258135  \n Mean   :136.5   Mean   :12.14   Mean   : 9.3254   Mean   :0.326313  \n 3rd Qu.:156.0   3rd Qu.:18.00   3rd Qu.:12.6661   3rd Qu.:0.368293  \n Max.   :619.0   Max.   :37.00   Max.   :19.1804   Max.   :3.465726  \n PROX_ELDERLYCARE  PROX_URA_GROWTH_AREA PROX_HAWKER_MARKET PROX_KINDERGARTEN \n Min.   :0.05451   Min.   :0.2145       Min.   :0.05182    Min.   :0.004927  \n 1st Qu.:0.61254   1st Qu.:3.1643       1st Qu.:0.55245    1st Qu.:0.276345  \n Median :0.94179   Median :4.6186       Median :0.90842    Median :0.413385  \n Mean   :1.05351   Mean   :4.5981       Mean   :1.27987    Mean   :0.458903  \n 3rd Qu.:1.35122   3rd Qu.:5.7550       3rd Qu.:1.68578    3rd Qu.:0.578474  \n Max.   :3.94916   Max.   :9.1554       Max.   :5.37435    Max.   :2.229045  \n    PROX_MRT         PROX_PARK       PROX_PRIMARY_SCH  PROX_TOP_PRIMARY_SCH\n Min.   :0.05278   Min.   :0.02906   Min.   :0.07711   Min.   :0.07711     \n 1st Qu.:0.34646   1st Qu.:0.26211   1st Qu.:0.44024   1st Qu.:1.34451     \n Median :0.57430   Median :0.39926   Median :0.63505   Median :1.88213     \n Mean   :0.67316   Mean   :0.49802   Mean   :0.75471   Mean   :2.27347     \n 3rd Qu.:0.84844   3rd Qu.:0.65592   3rd Qu.:0.95104   3rd Qu.:2.90954     \n Max.   :3.48037   Max.   :2.16105   Max.   :3.92899   Max.   :6.74819     \n PROX_SHOPPING_MALL PROX_SUPERMARKET PROX_BUS_STOP       NO_Of_UNITS    \n Min.   :0.0000     Min.   :0.0000   Min.   :0.001595   Min.   :  18.0  \n 1st Qu.:0.5258     1st Qu.:0.3695   1st Qu.:0.098356   1st Qu.: 188.8  \n Median :0.9357     Median :0.5687   Median :0.151710   Median : 360.0  \n Mean   :1.0455     Mean   :0.6141   Mean   :0.193974   Mean   : 409.2  \n 3rd Qu.:1.3994     3rd Qu.:0.7862   3rd Qu.:0.220466   3rd Qu.: 590.0  \n Max.   :3.4774     Max.   :2.2441   Max.   :2.476639   Max.   :1703.0  \n FAMILY_FRIENDLY     FREEHOLD      LEASEHOLD_99YR  \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.4868   Mean   :0.4227   Mean   :0.4882  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n\n\n\n\n5.2 Convert Data Frame into sf Object\n\n\nShow code\n# transform df into sf object and use st_transform() to update the CRS\ncondo_resale.sf <- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs=4326) %>%\n  st_transform(crs=3414)\n\n# view data\nhead(condo_resale.sf)\n\n\nSimple feature collection with 6 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 22085.12 ymin: 29951.54 xmax: 41042.56 ymax: 34546.2\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 22\n  POSTCODE SELLI…¹ AREA_…²   AGE PROX_…³ PROX_…⁴ PROX_…⁵ PROX_…⁶ PROX_…⁷ PROX_…⁸\n     <dbl>   <dbl>   <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1   118635 3000000     309    30    7.94   0.166   2.52     6.62   1.77   0.0584\n2   288420 3880000     290    32    6.61   0.280   1.93     7.51   0.545  0.616 \n3   267833 3325000     248    33    6.90   0.429   0.502    6.46   0.378  0.141 \n4   258380 4250000     127     7    4.04   0.395   1.99     4.91   1.68   0.382 \n5   467169 1400000     145    28   11.8    0.119   1.12     6.41   0.565  0.461 \n6   466472 1320000     139    22   10.3    0.125   0.789    5.09   0.781  0.0994\n# … with 12 more variables: PROX_MRT <dbl>, PROX_PARK <dbl>,\n#   PROX_PRIMARY_SCH <dbl>, PROX_TOP_PRIMARY_SCH <dbl>,\n#   PROX_SHOPPING_MALL <dbl>, PROX_SUPERMARKET <dbl>, PROX_BUS_STOP <dbl>,\n#   NO_Of_UNITS <dbl>, FAMILY_FRIENDLY <dbl>, FREEHOLD <dbl>,\n#   LEASEHOLD_99YR <dbl>, geometry <POINT [m]>, and abbreviated variable names\n#   ¹​SELLING_PRICE, ²​AREA_SQM, ³​PROX_CBD, ⁴​PROX_CHILDCARE, ⁵​PROX_ELDERLYCARE,\n#   ⁶​PROX_URA_GROWTH_AREA, ⁷​PROX_HAWKER_MARKET, ⁸​PROX_KINDERGARTEN"
  },
  {
    "objectID": "hands-on_ex/hands-on_ex07/hands-on_ex07.html#exploratory-data-analysis",
    "href": "hands-on_ex/hands-on_ex07/hands-on_ex07.html#exploratory-data-analysis",
    "title": "Hands-On Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "6 Exploratory Data Analysis",
    "text": "6 Exploratory Data Analysis\nWe will be using ggplot2 to visualise the distribution of the data. This is mainly to check for skewness and perform any transformation if necessary.\nTransform the dependent variable.\n\n\nShow code\n# let's check out the dependent variable first\nbefore <- ggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n# since the data is right skewed, more condo units are transacted at a lower relatively lower price. We can also normalise the data by using log()\ncondo_resale.sf <- condo_resale.sf %>%\n  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\n# view LOG_SELLING_PRICE\nafter <- ggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n# use ggpubr's ggarrange() to view the change\nggarrange(before, after, ncol=2)\n\n\n\n\n\nView the other features in the data set.\n\n\nShow code\nAREA_SQM <- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nAGE <- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CBD <- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CHILDCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_ELDERLYCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_URA_GROWTH_AREA <- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_HAWKER_MARKET <- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_KINDERGARTEN <- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_MRT <- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PARK <- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PRIMARY_SCH <- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_TOP_PRIMARY_SCH <- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, \n          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,\n          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  \n          ncol = 3, nrow = 4)\n\n\n\n\n\nReveal geospatial distribution of condo resale prices in Singapore.\n\n\nShow code\n# need to fix tmap_options - was not included in the Hands-On Document so not sure why this error is occurring here...\ntmap_options(check.and.fix = TRUE)\n\n\n\n\nShow code\n# turn on the interactive mode of tmap\ntmap_mode(\"view\")\n\n# we use tm_dots() instead of bubbles\n# set.zoom.limits argument sets the min and max zoom level to 11 and 14 respectively\ntm_shape(mpsz)+\n  tm_polygons() +\ntm_shape(condo_resale.sf) +  \n  tm_dots(col = \"SELLING_PRICE\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\n\n\nShow code\n# turn tmap mode back to plot\ntmap_mode(\"plot\")\n\n\nWe can see that most of the condos are around the southern region of Singapore."
  },
  {
    "objectID": "hands-on_ex/hands-on_ex07/hands-on_ex07.html#hedonic-pricing-model-using-r",
    "href": "hands-on_ex/hands-on_ex07/hands-on_ex07.html#hedonic-pricing-model-using-r",
    "title": "Hands-On Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "7 Hedonic Pricing Model using R",
    "text": "7 Hedonic Pricing Model using R\nWe will be using lm() to build the hedonic pricing models for condo resale units.\n\n7.1 Simple Linear Regression Method\n\n\nShow code\n# build an SLR using SELLING_PRICE as y and AREA_SQM as x\n# lm() returns class lm\ncondo.slr <- lm(formula=SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\n\n\n\nShow code\n# use summary() and anova() to get summary and analysis of variance table of the results\nsummary(condo.slr)\n\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3695815  -391764   -87517   258900 13503875 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -258121.1    63517.2  -4.064 5.09e-05 ***\nAREA_SQM      14719.0      428.1  34.381  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 942700 on 1434 degrees of freedom\nMultiple R-squared:  0.4518,    Adjusted R-squared:  0.4515 \nF-statistic:  1182 on 1 and 1434 DF,  p-value: < 2.2e-16\n\n\nShow code\nprint(\"-----------------\")\n\n\n[1] \"-----------------\"\n\n\nShow code\nanova(condo.slr)\n\n\nAnalysis of Variance Table\n\nResponse: SELLING_PRICE\n            Df     Sum Sq    Mean Sq F value    Pr(>F)    \nAREA_SQM     1 1.0504e+15 1.0504e+15    1182 < 2.2e-16 ***\nResiduals 1434 1.2743e+15 8.8861e+11                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nHence, SELLING_PRICE can be explained using: \\(y = -258121.1 + 14719x1\\)\nR-squared of 0.4518 reveals that the simple regression model built is able to explain about 45% of the resale prices. Since p-value is less than 0.0001 we will reject the null huypothesis that mean is a good estimator of SELLING_PRICE. This allows us to infer that the SLR model above is a good estimator of SELLING_PRICE.\nAdditionally, the report reveals that the p-values of both the estimates of the Intercept and AREA_SQM are smaller than 0.001. Hence, the null hypothesis that B0 and B1 are equal to 0 will be rejected. Hence, we can inter that B0 and B1 are good parameter estimates.\nVisualising the best fit curve on a scatterplot using lm()\n\n\nShow code\nggplot(data=condo_resale.sf,  \n       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n\n\n\n\nThe figure also reveals that there are a few statistical outliers with relatively high selling prices.\n\n\n7.2 Multiple Linear Regression Method\nVisualising the relationships of the independent variables\n\n\nShow code\n# this is done to ensure that the x variables used are not highly correlated to each other (quality of model will be compromised)\n# we will use a correlation matrix to visualise this - the order argument is very important for mining the hidden structure and pattern of the matrix. Four main methods in corrplot: \"AOE\", \"FPC\", \"hclust\", \"alphabet\". AOE uses angular order of the eigenvectors method suggested by Michael Friendly.\n\ncorrplot::corrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = \"AOE\",\n         tl.pos = \"td\", tl.cex = 0.5, method = \"number\", type = \"upper\")\n\n\n\n\n\nFrom the scatterplot matrix it is clear that FREEHOLD is highly correlated to LEASE_99YEAR. Hence, we will remove one of them: LEASE_99YEAR.\nBuilding a hedomic pricing model using MLR method.\n\n\nShow code\n# using lm() to get the formula\ncondo.mlr <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + \n                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                data=condo_resale.sf)\nsummary(condo.mlr)\n\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(>|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  < 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  < 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  < 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  < 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: < 2.2e-16\n\n\nFrom the report above, we can clearly see that not all the independent variables are statistically significant. We will revise the model by removing the statistically insignificant variables.\nPreparing Publication Quality Table\n\nolsrr method\n\n\n\nShow code\n# statistically insignificant variables removed\ncondo.mlr1 <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                   PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + \n                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL    + PROX_BUS_STOP + \n                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,\n                 data=condo_resale.sf)\nols_regress(condo.mlr1)\n\n\n                             Model Summary                               \n------------------------------------------------------------------------\nR                       0.807       RMSE                     755957.289 \nR-Squared               0.651       Coef. Var                    43.168 \nAdj. R-Squared          0.647       MSE                571471422208.591 \nPred R-Squared          0.638       MAE                      414819.628 \n------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.591                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n-----------------------------------------------------------------------------------------------------------------\n\n\n\ngtsummary method\n\n\n\nShow code\n# gtsummary package provides an elegant and flexible way to create publication-ready summary tables in R\n# model statistics can be included in the report by adding the add_glance_table() or add_glance_source_note() methods.\ntbl_regression(condo.mlr1, \n               intercept = TRUE) %>% \n  add_glance_source_note(\n    label = list(sigma ~ \"\\U03C3\"),\n    include = c(r.squared, adj.r.squared, \n                AIC, statistic,\n                p.value, sigma))\n\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n<0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n<0.001\n    AGE\n-24,688\n-30,092, -19,284\n<0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n<0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n<0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n<0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n<0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n<0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n<0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n<0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n<0.001\n  \n  \n    \n      R² = 0.651; Adjusted R² = 0.647; AIC = 42,967; Statistic = 189; p-value = <0.001; σ = 755,957\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\nChecking for multicolinearity\nolsrr provides a collection of many useful methods for building better multiple linear regression models:\n\ncomprehensive regression output\nresidual diagnostics\nmeasures of influence\nheteroskedasticity tests\ncollinearity diagnostics\nmodel fit assessment\nvariable contribution assessment\nvariable selection procedures\n\n\n\nShow code\n# we will use ols_vif_tol() to test if there are signs of multicollinearity\nols_vif_tol(condo.mlr1)\n\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8728554 1.145665\n2                   AGE 0.7071275 1.414172\n3              PROX_CBD 0.6356147 1.573280\n4        PROX_CHILDCARE 0.3066019 3.261559\n5      PROX_ELDERLYCARE 0.6598479 1.515501\n6  PROX_URA_GROWTH_AREA 0.7510311 1.331503\n7              PROX_MRT 0.5236090 1.909822\n8             PROX_PARK 0.8279261 1.207837\n9      PROX_PRIMARY_SCH 0.4524628 2.210126\n10   PROX_SHOPPING_MALL 0.6738795 1.483945\n11        PROX_BUS_STOP 0.3514118 2.845664\n12          NO_Of_UNITS 0.6901036 1.449058\n13      FAMILY_FRIENDLY 0.7244157 1.380423\n14             FREEHOLD 0.6931163 1.442759\n\n\nSince all VIF < 10, we can safely conclude that there are no signs of multicollinearity among the independent variables.\nTest for Non-Linearity\n\n\nShow code\n# it is important for us to test the assumption of linearity and additivity of the relationship between dependent and independent variables\nols_plot_resid_fit(condo.mlr1)\n\n\n\n\n\nThe figure above reveals that most of the data points are scattered around the 0 line. Hence, we can safely conclude that the relationships between the dependent variable and independent variables are linear.\nTest for Normality Assumption\n\n\nShow code\nols_plot_resid_hist(condo.mlr1)\n\n\n\n\n\nShow code\n# for a more formal statistical test method - p-values of the 4 tests are way smaller than the alpha value of 0.05 hence we reject the H0 and infer that there is sufficient statistical evidence that residuals are not normally distributed\nols_test_normality(condo.mlr1)\n\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\nThe figure reveals that the residual of the MLR model resembles a normal distribution.\nTesting for Spatial Autocorrelation\nThe hedonic model uses geographically referenced attributes. Hence, it is important to visualise the residuals of the hedonic pricing model.\n\n\nShow code\n# to perform spatial autocorrelation test, we need to convert the sf data frame into a SpatialPointsDataFrame\nmlr.output <- as.data.frame(condo.mlr1$residuals)\ncondo_resale.res.sf <- cbind(condo_resale.sf, \n                        condo.mlr1$residuals) %>%\nrename(`MLR_RES` = `condo.mlr1.residuals`)\n\n# we make this conversion since spdep package can only process sp conformed spatial data objects\ncondo_resale.sp <- as_Spatial(condo_resale.res.sf)\ncondo_resale.sp\n\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1436 \nextent      : 14940.85, 43352.45, 24765.67, 48382.81  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 23\nnames       : POSTCODE, SELLING_PRICE, AREA_SQM, AGE,    PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN,    PROX_MRT,   PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH, PROX_SHOPPING_MALL, ... \nmin values  :    18965,        540000,       34,   0, 0.386916393,    0.004927023,      0.054508623,          0.214539508,        0.051817113,       0.004927023, 0.052779424, 0.029064164,      0.077106132,          0.077106132,                  0, ... \nmax values  :   828833,       1.8e+07,      619,  37, 19.18042832,     3.46572633,      3.949157205,           9.15540001,        5.374348075,       2.229045366,  3.48037319,  2.16104919,      3.928989144,          6.748192062,        3.477433767, ... \n\n\n\n\nShow code\ntmap_mode(\"view\")\ntm_shape(mpsz)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale.res.sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\n\n\nShow code\ntmap_mode(\"plot\")\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nNeed to check with prof, do we say there is spatial autocorrelation because the residual changes based on the spaces?\n\n\n\nThe figure above reveals that there is a sign of spatial autocorrelation. To proof that our observation is indeed true, the Moran’s I test will be performed.\nMoran’s I Test\n\n\nShow code\n# compute distance-based weight matrix\nnb <- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)\nsummary(nb)\n\n\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\n\nShow code\n# convert the neighbours list into spatial weights\nnb_lw <- nb2listw(nb, style = 'W')\nsummary(nb_lw)\n\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\nWeights style: W \nWeights constants summary:\n     n      nn   S0       S1       S2\nW 1436 2062096 1436 94.81916 5798.341\n\n\nShow code\n# perform Moran's I test\nlm.morantest(condo.mlr1, nb_lw)\n\n\n\n    Global Moran I for regression residuals\n\ndata:  \nmodel: lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD +\nPROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_MRT +\nPROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +\nNO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data = condo_resale.sf)\nweights: nb_lw\n\nMoran I statistic standard deviate = 24.366, p-value < 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nObserved Moran I      Expectation         Variance \n    1.438876e-01    -5.487594e-03     3.758259e-05 \n\n\nThe Global Moran’s I test for residual spatial autocorrelation shows that it’s p-value is less than 0.00000000000000022 which is less than the alpha value of 0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.\nSince the Observed Global Moran I = 0.1424418 which is greater than 0, we can infer than the residuals resemble cluster distribution."
  },
  {
    "objectID": "hands-on_ex/hands-on_ex07/hands-on_ex07.html#building-hedonic-pricing-models-using-gwmodel",
    "href": "hands-on_ex/hands-on_ex07/hands-on_ex07.html#building-hedonic-pricing-models-using-gwmodel",
    "title": "Hands-On Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "8 Building Hedonic Pricing Models using GWmodel",
    "text": "8 Building Hedonic Pricing Models using GWmodel\n\n8.1 Building Fixed Bandwidth GWR Model\n\n\nShow code\n# there are 2 approaches to figuring out the optimal fixed bandwidth to use: CV and AIC (they are used to determine the stopping rule)\nbw.fixed <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                     PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                     PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                     PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                     FAMILY_FRIENDLY + FREEHOLD, \n                   data=condo_resale.sp, \n                   approach=\"CV\", \n                   kernel=\"gaussian\", \n                   adaptive=FALSE, \n                   longlat=FALSE)\n\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.378294e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3408 CV score: 4.721292e+14 \nFixed bandwidth: 971.3403 CV score: 4.721292e+14 \nFixed bandwidth: 971.3406 CV score: 4.721292e+14 \nFixed bandwidth: 971.3404 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \n\n\n\n\nShow code\n# from the code above we can see that the recommended bandwidth is 971.3405m (why metres?)\n# we can use that to calibrate our gwr model\n\ngwr.fixed <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                         PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                         PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                         PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                         FAMILY_FRIENDLY + FREEHOLD, \n                       data=condo_resale.sp, \n                       bw=bw.fixed, \n                       kernel = 'gaussian', \n                       longlat = FALSE)\n\ngwr.fixed\n\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2023-03-12 00:41:55 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  < 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  < 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  < 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  < 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: < 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.3405 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3600e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7425e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5000e+06 -1.5970e+05  3.1971e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8073e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112793548\n   AREA_SQM                 21575\n   AGE                     434201\n   PROX_CBD               2704596\n   PROX_CHILDCARE         1654087\n   PROX_ELDERLYCARE      38867814\n   PROX_URA_GROWTH_AREA  78515730\n   PROX_MRT               3124316\n   PROX_PARK             18122425\n   PROX_PRIMARY_SCH       4637503\n   PROX_SHOPPING_MALL     1529952\n   PROX_BUS_STOP         11342182\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720744\n   FREEHOLD               6073636\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3804 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6196 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.53407e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430417 \n\n   ***********************************************************************\n   Program stops at: 2023-03-12 00:41:56 \n\n\nThe model shows that the AICc of the GWR is 42263.61 which is significantly smaller than the global multiple linear regression model of 42967.1.\n\n\n8.2 Building Adaptive Bandwidth GWR Model\n\n\nShow code\n# take note that the adaptive argument is true\nbw.adaptive <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + \n                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + \n                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + \n                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                      data=condo_resale.sp, \n                      approach=\"CV\", \n                      kernel=\"gaussian\", \n                      adaptive=TRUE, \n                      longlat=FALSE)\n\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\nShow code\ngwr.adaptive <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + \n                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                          data=condo_resale.sp, bw=bw.adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE, \n                          longlat = FALSE)\n\ngwr.adaptive\n\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2023-03-12 00:42:03 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  < 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  < 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  < 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  < 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: < 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2023-03-12 00:42:04 \n\n\nThe report shows that the AICc of the adaptive distance GWR is 41982.22 which is even smaller than the AICc of the fixed distance gwr of 42263.61."
  },
  {
    "objectID": "hands-on_ex/hands-on_ex07/hands-on_ex07.html#visualising-gwr-output",
    "href": "hands-on_ex/hands-on_ex07/hands-on_ex07.html#visualising-gwr-output",
    "title": "Hands-On Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "9 Visualising GWR Output",
    "text": "9 Visualising GWR Output\nIn addition to regression residuals, the output feature class table includes fields for observed and predicted y-values, condition number (Helps evaluate local collinearity. Results associated with condition numbers larger than 30 may be unreliable), local R2 (values from 0 to 1 - they indicate how well the local regression model fits observed y values), and explanatory variable coefficients and standard errors (Measures the reliability of each coefficient estimate. Confidence in those estimates are higher when standard errors are small in relation to the actual coefficient values. Large standard errors may indicate problems with local collinearity).\n\n\nShow code\n# convert sdf into sf data.frame\ncondo_resale.sf.adaptive <- st_as_sf(gwr.adaptive$SDF) %>%\n  st_transform(crs=3414)\n\ncondo_resale.sf.adaptive.svy21 <- st_transform(condo_resale.sf.adaptive, 3414)\ncondo_resale.sf.adaptive.svy21  \n\n\nSimple feature collection with 1436 features and 51 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14940.85 ymin: 24765.67 xmax: 43352.45 ymax: 48382.81\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n    Intercept  AREA_SQM        AGE  PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n1   2050011.7  9561.892  -9514.634 -120681.9      319266.92       -393417.79\n2   1633128.2 16576.853 -58185.479 -149434.2      441102.18        325188.74\n3   3433608.2 13091.861 -26707.386 -259397.8     -120116.82        535855.81\n4    234358.9 20730.601 -93308.988 2426853.7      480825.28        314783.72\n5   2285804.9  6722.836 -17608.018 -316835.5       90764.78       -137384.61\n6  -3568877.4  6039.581 -26535.592  327306.1     -152531.19       -700392.85\n7  -2874842.4 16843.575 -59166.727 -983577.2     -177810.50       -122384.02\n8   2038086.0  6905.135 -17681.897 -285076.6       70259.40        -96012.78\n9   1718478.4  9580.703 -14401.128  105803.4     -657698.02       -123276.00\n10  3457054.0 14072.011 -31579.884 -234895.4       79961.45        548581.04\n   PROX_URA_GROWTH_AREA    PROX_MRT  PROX_PARK PROX_PRIMARY_SCH\n1            -159980.20  -299742.96 -172104.47        242668.03\n2            -142290.39 -2510522.23  523379.72       1106830.66\n3            -253621.21  -936853.28  209099.85        571462.33\n4           -2679297.89 -2039479.50 -759153.26       3127477.21\n5             303714.81   -44567.05  -10284.62         30413.56\n6             -28051.25   733566.47 1511488.92        320878.23\n7            1397676.38 -2745430.34  710114.74       1786570.95\n8             269368.71   -14552.99   73533.34         53359.73\n9            -361974.72  -476785.32 -132067.59        -40128.92\n10           -150024.38 -1503835.53  574155.47        108996.67\n   PROX_SHOPPING_MALL PROX_BUS_STOP  NO_Of_UNITS FAMILY_FRIENDLY  FREEHOLD\n1          300881.390     1210615.4  104.8290640       -9075.370  303955.6\n2          -87693.378     1843587.2 -288.3441183      310074.664  396221.3\n3         -126732.712     1411924.9   -9.5532945        5949.746  168821.7\n4          -29593.342     7225577.5 -161.3551620     1556178.531 1212515.6\n5           -7490.586      677577.0   42.2659674       58986.951  328175.2\n6          258583.881     1086012.6 -214.3671271      201992.641  471873.1\n7         -384251.210     5094060.5   -0.9212521      359659.512  408871.9\n8          -39634.902      735767.1   30.1741069       55602.506  347075.0\n9          276718.757     2815772.4  675.1615559      -30453.297  503872.8\n10        -454726.822     2123557.0  -21.3044311     -100935.586  213324.6\n         y    yhat    residual CV_Score Stud_residual Intercept_SE AREA_SQM_SE\n1  3000000 2886532   113468.16        0    0.38207013     516105.5    823.2860\n2  3880000 3466801   413198.52        0    1.01433140     488083.5    825.2380\n3  3325000 3616527  -291527.20        0   -0.83780678     963711.4    988.2240\n4  4250000 5435482 -1185481.63        0   -2.84614670     444185.5    617.4007\n5  1400000 1388166    11834.26        0    0.03404453    2119620.6   1376.2778\n6  1320000 1516702  -196701.94        0   -0.72065800   28572883.7   2348.0091\n7  3410000 3266881   143118.77        0    0.41291992     679546.6    893.5893\n8  1420000 1431955   -11955.27        0   -0.03033109    2217773.1   1415.2604\n9  2025000 1832799   192200.83        0    0.52018109     814281.8    943.8434\n10 2550000 2223364   326635.53        0    1.10559735    2410252.0   1271.4073\n      AGE_SE PROX_CBD_SE PROX_CHILDCARE_SE PROX_ELDERLYCARE_SE\n1   5889.782    37411.22          319111.1           120633.34\n2   6226.916    23615.06          299705.3            84546.69\n3   6510.236    56103.77          349128.5           129687.07\n4   6010.511   469337.41          304965.2           127150.69\n5   8180.361   410644.47          698720.6           327371.55\n6  14601.909  5272846.47         1141599.8          1653002.19\n7   8970.629   346164.20          530101.1           148598.71\n8   8661.309   438035.69          742532.8           399221.05\n9  11791.208    89148.35          704630.7           329683.30\n10  9941.980   173532.77          500976.2           281876.74\n   PROX_URA_GROWTH_AREA_SE PROX_MRT_SE PROX_PARK_SE PROX_PRIMARY_SCH_SE\n1                 56207.39    185181.3     205499.6            152400.7\n2                 76956.50    281133.9     229358.7            165150.7\n3                 95774.60    275483.7     314124.3            196662.6\n4                470762.12    279877.1     227249.4            240878.9\n5                474339.56    363830.0     364580.9            249087.7\n6               5496627.21    730453.2    1741712.0            683265.5\n7                371692.97    375511.9     297400.9            344602.8\n8                517977.91    423155.4     440984.4            261251.2\n9                153436.22    285325.4     304998.4            278258.5\n10               239182.57    571355.7     599131.8            331284.8\n   PROX_SHOPPING_MALL_SE PROX_BUS_STOP_SE NO_Of_UNITS_SE FAMILY_FRIENDLY_SE\n1               109268.8         600668.6       218.1258           131474.7\n2                98906.8         410222.1       208.9410           114989.1\n3               119913.3         464156.7       210.9828           146607.2\n4               177104.1         562810.8       361.7767           108726.6\n5               301032.9         740922.4       299.5034           160663.7\n6              2931208.6        1418333.3       602.5571           331727.0\n7               249969.5         821236.4       532.1978           129241.2\n8               351634.0         775038.4       338.6777           171895.1\n9               289872.7         850095.5       439.9037           220223.4\n10              265529.7         631399.2       259.0169           189125.5\n   FREEHOLD_SE Intercept_TV AREA_SQM_TV     AGE_TV PROX_CBD_TV\n1     115954.0    3.9720784   11.614302  -1.615447 -3.22582173\n2     130110.0    3.3460017   20.087361  -9.344188 -6.32792021\n3     141031.5    3.5629010   13.247868  -4.102368 -4.62353528\n4     138239.1    0.5276150   33.577223 -15.524302  5.17080808\n5     210641.1    1.0784029    4.884795  -2.152474 -0.77155660\n6     374347.3   -0.1249043    2.572214  -1.817269  0.06207388\n7     182216.9   -4.2305303   18.849348  -6.595605 -2.84136028\n8     216649.4    0.9189786    4.879056  -2.041481 -0.65080678\n9     220473.7    2.1104224   10.150733  -1.221345  1.18682383\n10    206346.2    1.4343123   11.068059  -3.176418 -1.35360852\n   PROX_CHILDCARE_TV PROX_ELDERLYCARE_TV PROX_URA_GROWTH_AREA_TV PROX_MRT_TV\n1         1.00048819          -3.2612693            -2.846248368 -1.61864578\n2         1.47178634           3.8462625            -1.848971738 -8.92998600\n3        -0.34404755           4.1319138            -2.648105057 -3.40075727\n4         1.57665606           2.4756745            -5.691404992 -7.28705261\n5         0.12990138          -0.4196596             0.640289855 -0.12249416\n6        -0.13361179          -0.4237096            -0.005103357  1.00426206\n7        -0.33542751          -0.8235874             3.760298131 -7.31116712\n8         0.09462126          -0.2405003             0.520038994 -0.03439159\n9        -0.93339393          -0.3739225            -2.359121712 -1.67102293\n10        0.15961128           1.9461735            -0.627237944 -2.63204802\n   PROX_PARK_TV PROX_PRIMARY_SCH_TV PROX_SHOPPING_MALL_TV PROX_BUS_STOP_TV\n1   -0.83749312           1.5923022            2.75358842        2.0154464\n2    2.28192684           6.7019454           -0.88662640        4.4941192\n3    0.66565951           2.9058009           -1.05686949        3.0419145\n4   -3.34061770          12.9836105           -0.16709578       12.8383775\n5   -0.02820944           0.1220998           -0.02488294        0.9145046\n6    0.86781794           0.4696245            0.08821750        0.7656963\n7    2.38773567           5.1844351           -1.53719231        6.2029165\n8    0.16674816           0.2042469           -0.11271635        0.9493299\n9   -0.43301073          -0.1442145            0.95462153        3.3123012\n10   0.95831249           0.3290120           -1.71252687        3.3632555\n   NO_Of_UNITS_TV FAMILY_FRIENDLY_TV FREEHOLD_TV  Local_R2\n1     0.480589953        -0.06902748    2.621347 0.8846744\n2    -1.380026395         2.69655779    3.045280 0.8899773\n3    -0.045279967         0.04058290    1.197050 0.8947007\n4    -0.446007570        14.31276425    8.771149 0.9073605\n5     0.141120178         0.36714544    1.557983 0.9510057\n6    -0.355762335         0.60891234    1.260522 0.9247586\n7    -0.001731033         2.78285441    2.243875 0.8310458\n8     0.089093858         0.32346758    1.602012 0.9463936\n9     1.534793921        -0.13828365    2.285410 0.8380365\n10   -0.082251138        -0.53369623    1.033819 0.9080753\n                    geometry\n1  POINT (22085.12 29951.54)\n2   POINT (25656.84 34546.2)\n3   POINT (23963.99 32890.8)\n4  POINT (27044.28 32319.77)\n5  POINT (41042.56 33743.64)\n6   POINT (39717.04 32943.1)\n7   POINT (28419.1 33513.37)\n8  POINT (40763.57 33879.61)\n9  POINT (23595.63 28884.78)\n10 POINT (24586.56 33194.31)\n\n\nShow code\ngwr.adaptive.output <- as.data.frame(gwr.adaptive$SDF)\ncondo_resale.sf.adaptive <- cbind(condo_resale.res.sf, as.matrix(gwr.adaptive.output))\n\nglimpse(condo_resale.sf.adaptive)\n\n\nRows: 1,436\nColumns: 77\n$ POSTCODE                <dbl> 118635, 288420, 267833, 258380, 467169, 466472…\n$ SELLING_PRICE           <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ AREA_SQM                <dbl> 309, 290, 248, 127, 145, 139, 218, 141, 165, 1…\n$ AGE                     <dbl> 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22,…\n$ PROX_CBD                <dbl> 7.941259, 6.609797, 6.898000, 4.038861, 11.783…\n$ PROX_CHILDCARE          <dbl> 0.16597932, 0.28027246, 0.42922669, 0.39473543…\n$ PROX_ELDERLYCARE        <dbl> 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.…\n$ PROX_URA_GROWTH_AREA    <dbl> 6.618741, 7.505109, 6.463887, 4.906512, 6.4106…\n$ PROX_HAWKER_MARKET      <dbl> 1.76542207, 0.54507614, 0.37789301, 1.68259969…\n$ PROX_KINDERGARTEN       <dbl> 0.05835552, 0.61592412, 0.14120309, 0.38200076…\n$ PROX_MRT                <dbl> 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.…\n$ PROX_PARK               <dbl> 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.…\n$ PROX_PRIMARY_SCH        <dbl> 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.…\n$ PROX_TOP_PRIMARY_SCH    <dbl> 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.…\n$ PROX_SHOPPING_MALL      <dbl> 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.…\n$ PROX_SUPERMARKET        <dbl> 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.…\n$ PROX_BUS_STOP           <dbl> 0.10336166, 0.28673408, 0.28504777, 0.29872340…\n$ NO_Of_UNITS             <dbl> 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34…\n$ FAMILY_FRIENDLY         <dbl> 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD                <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ LOG_SELLING_PRICE       <dbl> 14.91412, 15.17135, 15.01698, 15.26243, 14.151…\n$ MLR_RES                 <dbl> -1489099.55, 415494.57, 194129.69, 1088992.71,…\n$ Intercept               <dbl> 2050011.67, 1633128.24, 3433608.17, 234358.91,…\n$ AREA_SQM.1              <dbl> 9561.892, 16576.853, 13091.861, 20730.601, 672…\n$ AGE.1                   <dbl> -9514.634, -58185.479, -26707.386, -93308.988,…\n$ PROX_CBD.1              <dbl> -120681.94, -149434.22, -259397.77, 2426853.66…\n$ PROX_CHILDCARE.1        <dbl> 319266.925, 441102.177, -120116.816, 480825.28…\n$ PROX_ELDERLYCARE.1      <dbl> -393417.795, 325188.741, 535855.806, 314783.72…\n$ PROX_URA_GROWTH_AREA.1  <dbl> -159980.203, -142290.389, -253621.206, -267929…\n$ PROX_MRT.1              <dbl> -299742.96, -2510522.23, -936853.28, -2039479.…\n$ PROX_PARK.1             <dbl> -172104.47, 523379.72, 209099.85, -759153.26, …\n$ PROX_PRIMARY_SCH.1      <dbl> 242668.03, 1106830.66, 571462.33, 3127477.21, …\n$ PROX_SHOPPING_MALL.1    <dbl> 300881.390, -87693.378, -126732.712, -29593.34…\n$ PROX_BUS_STOP.1         <dbl> 1210615.44, 1843587.22, 1411924.90, 7225577.51…\n$ NO_Of_UNITS.1           <dbl> 104.8290640, -288.3441183, -9.5532945, -161.35…\n$ FAMILY_FRIENDLY.1       <dbl> -9075.370, 310074.664, 5949.746, 1556178.531, …\n$ FREEHOLD.1              <dbl> 303955.61, 396221.27, 168821.75, 1212515.58, 3…\n$ y                       <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ yhat                    <dbl> 2886531.8, 3466801.5, 3616527.2, 5435481.6, 13…\n$ residual                <dbl> 113468.16, 413198.52, -291527.20, -1185481.63,…\n$ CV_Score                <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Stud_residual           <dbl> 0.38207013, 1.01433140, -0.83780678, -2.846146…\n$ Intercept_SE            <dbl> 516105.5, 488083.5, 963711.4, 444185.5, 211962…\n$ AREA_SQM_SE             <dbl> 823.2860, 825.2380, 988.2240, 617.4007, 1376.2…\n$ AGE_SE                  <dbl> 5889.782, 6226.916, 6510.236, 6010.511, 8180.3…\n$ PROX_CBD_SE             <dbl> 37411.22, 23615.06, 56103.77, 469337.41, 41064…\n$ PROX_CHILDCARE_SE       <dbl> 319111.1, 299705.3, 349128.5, 304965.2, 698720…\n$ PROX_ELDERLYCARE_SE     <dbl> 120633.34, 84546.69, 129687.07, 127150.69, 327…\n$ PROX_URA_GROWTH_AREA_SE <dbl> 56207.39, 76956.50, 95774.60, 470762.12, 47433…\n$ PROX_MRT_SE             <dbl> 185181.3, 281133.9, 275483.7, 279877.1, 363830…\n$ PROX_PARK_SE            <dbl> 205499.6, 229358.7, 314124.3, 227249.4, 364580…\n$ PROX_PRIMARY_SCH_SE     <dbl> 152400.7, 165150.7, 196662.6, 240878.9, 249087…\n$ PROX_SHOPPING_MALL_SE   <dbl> 109268.8, 98906.8, 119913.3, 177104.1, 301032.…\n$ PROX_BUS_STOP_SE        <dbl> 600668.6, 410222.1, 464156.7, 562810.8, 740922…\n$ NO_Of_UNITS_SE          <dbl> 218.1258, 208.9410, 210.9828, 361.7767, 299.50…\n$ FAMILY_FRIENDLY_SE      <dbl> 131474.73, 114989.07, 146607.22, 108726.62, 16…\n$ FREEHOLD_SE             <dbl> 115954.0, 130110.0, 141031.5, 138239.1, 210641…\n$ Intercept_TV            <dbl> 3.9720784, 3.3460017, 3.5629010, 0.5276150, 1.…\n$ AREA_SQM_TV             <dbl> 11.614302, 20.087361, 13.247868, 33.577223, 4.…\n$ AGE_TV                  <dbl> -1.6154474, -9.3441881, -4.1023685, -15.524301…\n$ PROX_CBD_TV             <dbl> -3.22582173, -6.32792021, -4.62353528, 5.17080…\n$ PROX_CHILDCARE_TV       <dbl> 1.000488185, 1.471786337, -0.344047555, 1.5766…\n$ PROX_ELDERLYCARE_TV     <dbl> -3.26126929, 3.84626245, 4.13191383, 2.4756745…\n$ PROX_URA_GROWTH_AREA_TV <dbl> -2.846248368, -1.848971738, -2.648105057, -5.6…\n$ PROX_MRT_TV             <dbl> -1.61864578, -8.92998600, -3.40075727, -7.2870…\n$ PROX_PARK_TV            <dbl> -0.83749312, 2.28192684, 0.66565951, -3.340617…\n$ PROX_PRIMARY_SCH_TV     <dbl> 1.59230221, 6.70194543, 2.90580089, 12.9836104…\n$ PROX_SHOPPING_MALL_TV   <dbl> 2.753588422, -0.886626400, -1.056869486, -0.16…\n$ PROX_BUS_STOP_TV        <dbl> 2.0154464, 4.4941192, 3.0419145, 12.8383775, 0…\n$ NO_Of_UNITS_TV          <dbl> 0.480589953, -1.380026395, -0.045279967, -0.44…\n$ FAMILY_FRIENDLY_TV      <dbl> -0.06902748, 2.69655779, 0.04058290, 14.312764…\n$ FREEHOLD_TV             <dbl> 2.6213469, 3.0452799, 1.1970499, 8.7711485, 1.…\n$ Local_R2                <dbl> 0.8846744, 0.8899773, 0.8947007, 0.9073605, 0.…\n$ coords.x1               <dbl> 22085.12, 25656.84, 23963.99, 27044.28, 41042.…\n$ coords.x2               <dbl> 29951.54, 34546.20, 32890.80, 32319.77, 33743.…\n$ geometry                <POINT [m]> POINT (22085.12 29951.54), POINT (25656.…\n\n\n\n\nShow code\n# see the summary stats of the predicted/estimated values of the model\nsummary(gwr.adaptive$SDF$yhat)\n\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n  171347  1102001  1385528  1751842  1982307 13887901 \n\n\nVisualising R2\n\n\nShow code\n# create interactive point symbol map\ntmap_mode(\"view\")\ntm_shape(mpsz)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"Local_R2\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\n\n\nShow code\ntmap_mode(\"plot\")\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhy visualise R^2?\n\n\n\nVisualising coefficient estimates\n\n\nShow code\ntmap_mode(\"view\")\nAREA_SQM_SE <- tm_shape(mpsz)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_SE\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\nAREA_SQM_TV <- tm_shape(mpsz)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_TV\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\ntmap_arrange(AREA_SQM_SE, AREA_SQM_TV, \n             asp=1, ncol=2,\n             sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\n# visualise by URA Planning Region\ntm_shape(mpsz[mpsz$REGION_N==\"CENTRAL REGION\", ])+\n  tm_polygons()+\ntm_shape(condo_resale.sf.adaptive) + \n  tm_bubbles(col = \"Local_R2\",\n           size = 0.15,\n           border.col = \"gray60\",\n           border.lwd = 1)"
  },
  {
    "objectID": "in-class_ex/in-class_ex02/in-class_ex02.html",
    "href": "in-class_ex/in-class_ex02/in-class_ex02.html",
    "title": "In-Class Exercise 2: Geospatial Data Wrangling",
    "section": "",
    "text": "Geospatial analytics hold tremendous potential to address complex problems facing society. In this study, you are tasked to apply appropriate geospatial data wrangling methods to prepare the data for water point mapping study. For the purpose of this study, Nigeria will be used as the study country."
  },
  {
    "objectID": "in-class_ex/in-class_ex02/in-class_ex02.html#import-sf-tidyverse-and-funmodeling",
    "href": "in-class_ex/in-class_ex02/in-class_ex02.html#import-sf-tidyverse-and-funmodeling",
    "title": "In-Class Exercise 2: Geospatial Data Wrangling",
    "section": "Import sf, tidyverse, and funModeling",
    "text": "Import sf, tidyverse, and funModeling\n\npacman::p_load(sf, tidyverse, funModeling)"
  },
  {
    "objectID": "in-class_ex/in-class_ex02/in-class_ex02.html#import-geospatial-data",
    "href": "in-class_ex/in-class_ex02/in-class_ex02.html#import-geospatial-data",
    "title": "In-Class Exercise 2: Geospatial Data Wrangling",
    "section": "Import Geospatial Data",
    "text": "Import Geospatial Data\n\ngeoBoundaries\n\ngeoBoundaries = st_read(dsn = \"data/geospatial\", \n                  layer = \"geoBoundaries-NGA-ADM2\")\n\nReading layer `geoBoundaries-NGA-ADM2' from data source \n  `C:\\guga-nesh\\IS415-GAA\\in-class_ex\\in-class_ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n# should use st_transform(crs=26392) -> convert it from degrees to meters\n\n\n\nNGA\n\nnga = st_read(dsn = \"data/geospatial\", \n                  layer = \"nga_admbnda_adm2_osgof_20190417\")\n\nReading layer `nga_admbnda_adm2_osgof_20190417' from data source \n  `C:\\guga-nesh\\IS415-GAA\\in-class_ex\\in-class_ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n# should use st_transform(crs=26392) -> convert it from degrees to meters"
  },
  {
    "objectID": "in-class_ex/in-class_ex02/in-class_ex02.html#import-aspatial-data",
    "href": "in-class_ex/in-class_ex02/in-class_ex02.html#import-aspatial-data",
    "title": "In-Class Exercise 2: Geospatial Data Wrangling",
    "section": "Import Aspatial Data",
    "text": "Import Aspatial Data\nFirst we need more information about the data set so I used spec()\n\nwp_nga <- read_csv(\"data/aspatial/WPDX.csv\") %>%\n  filter(`#clean_country_name` == \"Nigeria\")\n\n# use ` for variables with spaces\n# use \" for attributes\n\n\nwp_nga\n\n# A tibble: 95,008 × 70\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n    <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429068 GRID3             7.98    5.12 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2 222071 Federal Minis…    6.96    3.60 08/16/… Yes     Boreho… Well    Mechan…\n 3 160612 WaterAid          6.49    7.93 12/04/… Yes     Boreho… Well    Hand P…\n 4 160669 WaterAid          6.73    7.65 12/04/… Yes     Boreho… Well    <NA>   \n 5 160642 WaterAid          6.78    7.66 12/04/… Yes     Boreho… Well    Hand P…\n 6 160628 WaterAid          6.96    7.78 12/04/… Yes     Boreho… Well    Hand P…\n 7 160632 WaterAid          7.02    7.84 12/04/… Yes     Boreho… Well    Hand P…\n 8 642747 Living Water …    7.33    8.98 10/03/… Yes     Boreho… Well    Mechan…\n 9 642456 Living Water …    7.17    9.11 10/03/… Yes     Boreho… Well    Hand P…\n10 641347 Living Water …    7.20    9.22 03/28/… Yes     Boreho… Well    Hand P…\n# … with 94,998 more rows, 61 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …"
  },
  {
    "objectID": "in-class_ex/in-class_ex02/in-class_ex02.html#converting-aspatial-data-into-geospatial",
    "href": "in-class_ex/in-class_ex02/in-class_ex02.html#converting-aspatial-data-into-geospatial",
    "title": "In-Class Exercise 2: Geospatial Data Wrangling",
    "section": "Converting Aspatial Data into Geospatial",
    "text": "Converting Aspatial Data into Geospatial\nWe can create a new column called geometry. Using st_as_sfc() we can convert a foreign geometry object into an sfc (simple feature geometry list column) object.\n\nwp_nga$geometry = st_as_sfc(wp_nga$`New Georeferenced Column`)\nwp_nga$geometry\n\nGeometry set for 95008 features \nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 2.707441 ymin: 4.301812 xmax: 14.21828 ymax: 13.86568\nCRS:           NA\nFirst 5 geometries:\n\n\nOr we can simply use the st_sf() function…\n\n# EPSG 4326 is wgs84 GCS\nwp_sf <- st_sf(wp_nga, crs=4326)\nwp_sf\n\nSimple feature collection with 95008 features and 70 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 2.707441 ymin: 4.301812 xmax: 14.21828 ymax: 13.86568\nGeodetic CRS:  WGS 84\n# A tibble: 95,008 × 71\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n *  <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429068 GRID3             7.98    5.12 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2 222071 Federal Minis…    6.96    3.60 08/16/… Yes     Boreho… Well    Mechan…\n 3 160612 WaterAid          6.49    7.93 12/04/… Yes     Boreho… Well    Hand P…\n 4 160669 WaterAid          6.73    7.65 12/04/… Yes     Boreho… Well    <NA>   \n 5 160642 WaterAid          6.78    7.66 12/04/… Yes     Boreho… Well    Hand P…\n 6 160628 WaterAid          6.96    7.78 12/04/… Yes     Boreho… Well    Hand P…\n 7 160632 WaterAid          7.02    7.84 12/04/… Yes     Boreho… Well    Hand P…\n 8 642747 Living Water …    7.33    8.98 10/03/… Yes     Boreho… Well    Mechan…\n 9 642456 Living Water …    7.17    9.11 10/03/… Yes     Boreho… Well    Hand P…\n10 641347 Living Water …    7.20    9.22 03/28/… Yes     Boreho… Well    Hand P…\n# … with 94,998 more rows, 62 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …"
  },
  {
    "objectID": "in-class_ex/in-class_ex02/in-class_ex02.html#excluding-redundant-fields",
    "href": "in-class_ex/in-class_ex02/in-class_ex02.html#excluding-redundant-fields",
    "title": "In-Class Exercise 2: Geospatial Data Wrangling",
    "section": "Excluding redundant fields",
    "text": "Excluding redundant fields\n\nnga <- nga %>%\n  select(c(3:4, 8:9))\n\n\n# checking for duplicate name\nnga$ADM2_EN[duplicated(nga$ADM2_EN)==TRUE]\n\n[1] \"Bassa\"    \"Ifelodun\" \"Irepodun\" \"Nasarawa\" \"Obi\"      \"Surulere\"\n\n\n\nwp_sf_nga <- wp_sf %>%\n  rename(status_clean = '#status_clean') %>%\n  select(status_clean) %>%\n  mutate(status_clean = replace_na(\n    status_clean, \"unknown\"))\n\n\nwp_functional <- wp_sf_nga %>%\n  filter(status_clean %in%\n           c(\"Functional\",\n             \"Functional but not in use\",\n             \"Functional but needs repair\"))\n\n\nwp_nonfunctional <- wp_sf_nga %>%\n  filter(status_clean %in%\n           c(\"Abandoned/Decommissioned\",\n             \"Abandoned\",\n             \"Non-Functional due to dry season\",\n             \"Non-Functional\",\n             \"Non functional due to dry season\"))\n\n\nwp_unknown <- wp_sf_nga %>%\n  filter(status_clean %in% c(\"unknown\"))\n\n\nNGA_wp <- nga %>%   mutate(`total_wp` = lengths(     st_intersects(nga, wp_sf_nga))) %>%   mutate(`wp_functional` = lengths(     st_intersects(nga, wp_functional))) %>%   mutate(`wp_nonfunctional` = lengths(     st_intersects(nga, wp_nonfunctional))) %>%   mutate(`wp_unknown` = lengths(     st_intersects(nga, wp_unknown)))"
  },
  {
    "objectID": "in-class_ex/in-class_ex02/in-class_ex02.html#projection-transformation",
    "href": "in-class_ex/in-class_ex02/in-class_ex02.html#projection-transformation",
    "title": "In-Class Exercise 2: Geospatial Data Wrangling",
    "section": "Projection transformation",
    "text": "Projection transformation\nWe can find the appropriate PCS of Nigeria from epsg.io\n\n\n# Previously we used the wgs84 for original data...\n# Now we are transforming it to the Nigerian projection.\n\nwp_sf <- wp_sf %>%\n  st_transform(crs = 26392)\nst_crs(wp_sf)\n\nCoordinate Reference System:\n  User input: EPSG:26392 \n  wkt:\nPROJCRS[\"Minna / Nigeria Mid Belt\",\n    BASEGEOGCRS[\"Minna\",\n        DATUM[\"Minna\",\n            ELLIPSOID[\"Clarke 1880 (RGS)\",6378249.145,293.465,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4263]],\n    CONVERSION[\"Nigeria Mid Belt\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",4,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",8.5,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.99975,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",670553.98,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Engineering survey, topographic mapping.\"],\n        AREA[\"Nigeria between 6°30'E and 10°30'E, onshore and offshore shelf.\"],\n        BBOX[3.57,6.5,13.53,10.51]],\n    ID[\"EPSG\",26392]]"
  },
  {
    "objectID": "in-class_ex/in-class_ex03/in-class_ex03.html",
    "href": "in-class_ex/in-class_ex03/in-class_ex03.html",
    "title": "In-Class Exercise 3: Analytical Mapping",
    "section": "",
    "text": "0.1 Overview\n…\n\n\n0.2 Installing and loading packages\n\npacman::p_load(tmap, tidyverse, sf)\n\nThe tmap package documentation can be found here.\n\n\n0.3 Importing data\n\nNGA_wp <- read_rds(\"data/rds/NGA_wp.rds\")\n\n\n\n0.4 Visualizing distribution of functional and non-functional water point using Choropleth Maps\n\np1 <- tm_shape(NGA_wp) + \n  tm_fill(\"wp_functional\",\n          n = 10,\n          \n          #style is used for data classification method\n          style = \"equal\",\n          \n          #colour palettes are always plural\n          palette = \"Blues\") +  \n  \n  # line width\n  tm_borders(lwd = 0.1,\n             \n             # opacity\n             alpha = 1) + \n  \n  # main.title places the title outside the plot\n  tm_layout(main.title = \"Distribution of functional water point\",\n            \n            # legend.outside puts legends in- or outside of your plot\n            legend.outside = FALSE)\n\n# things to take note: tm_fill() and tm_borders() combined is tm_polygon()\n\np1\n\n\n\n\n\np1 <- tm_shape(NGA_wp) + \n  tm_fill(\"wp_functional\",\n          n = 10,\n          \n          #style is used for data classification method\n          style = \"equal\",\n          \n          #colour palettes are always plural\n          palette = \"Blues\") +  \n  \n  # line width\n  tm_borders(lwd = 0.1,\n             \n             # opacity\n             alpha = 1) + \n  \n  # main.title places the title outside the plot\n  tm_layout(main.title = \"Distribution of functional water points by LGAs\",\n            \n            # legend.outside puts legends in- or outside of your plot\n            legend.outside = FALSE)\n\n# things to take note: tm_fill() and tm_borders() combined is tm_polygon()\n\n# p1 is a map object\np1\n\n\n\n\n\np2 <- tm_shape(NGA_wp) + \n  tm_fill(\"total_wp\",\n          n = 10,\n          \n          #style is used for data classification method\n          style = \"equal\",\n          \n          #colour palettes are always plural\n          palette = \"Blues\") +  \n  \n  # line width\n  tm_borders(lwd = 0.1,\n             \n             # opacity\n             alpha = 1) + \n  \n  # main.title places the title outside the plot\n  tm_layout(main.title = \"Distribution of total water points by LGAs\",\n            \n            # legend.outside puts legends in- or outside of your plot\n            legend.outside = FALSE)\n\np2\n\n\n\n\n\n# show both together on one row\ntmap_arrange(p2, p1, nrow=1)\n\n\n\n\n\n# You can even show both maps as one by using Rates: usually we do this to see if both categories tell the same story\nNGA_wp <- NGA_wp %>%\n  \n  # use mutate() to calc % (i.e., rate) of functional and non-functional water points\n  mutate(pct_functional = wp_functional/total_wp) %>%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)\n\n\ntm_shape(NGA_wp) + \n  tm_fill(\"pct_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\",\n          legend.hist = TRUE) +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Rate map of functional water points by LGAs\",\n            legend.outside = TRUE)\n\n\n\n\n\n\n0.5 Visualization using a Percentile Map\nTells you which areas are the top 10%. The six specific categories are: 0-1%, 1-10%, 10-50%, 50-90%, 90-99%, and 99-100%.\n\n# Data Preparation\n  # Exclude NA values\nNGA_wp <- NGA_wp %>%\n  drop_na()\n\n  # create customised classification and extract values\npercent <- c(0, .01, .1, .5, .9, .99, 1)\nvar <- NGA_wp[\"pct_functional\"] %>%\n  \n  # \n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\n0.5.1 Writing functions to do the same functionality for specific data sets…\n\n# R function to extract a variable (i.e., wp_nonfunctional as a vector out of an sf data.frame)\nget.var <- function(vname, df) {\n  v <- df[vname] %>%\n    st_set_geometry(NULL)\n    v <- unname(v[,1])\n    \n  # return vector with values (without a col name)\n  return(v)\n}\n\n\n# percentile mapping function\npercentmap <- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent <- c(0,.01,.1,.5,.9,.99,1)\n  var <- get.var(vnam, df)\n  bperc <- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"< 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"> 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\n\n\n# test the function\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\n\n\n\n0.6 Visualizing using a Box Plot\n\n# boxplot is as augmented quartile map with an additional lower and upper category.\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) + \n  geom_boxplot()\n\n\n\n\n\n# creating a boxbreaks function\n# arguments - v: vector with observations, mult: multiplier for IQR (default 1.5)\n# returns - bb: vector with 7 breakpoints compute quartile and fences\n\nboxbreaks <- function(v,mult=1.5) {\n  qv <- unname(quantile(v))\n  iqr <- qv[4] - qv[2]\n  upfence <- qv[4] + mult * iqr\n  lofence <- qv[2] - mult * iqr\n  # initialize break points vector\n  bb <- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence < qv[1]) {  # no lower outliers\n    bb[1] <- lofence\n    bb[2] <- floor(qv[1])\n  } else {\n    bb[2] <- lofence\n    bb[1] <- qv[1]\n  }\n  if (upfence > qv[5]) { # no upper outliers\n    bb[7] <- upfence\n    bb[6] <- ceiling(qv[5])\n  } else {\n    bb[6] <- upfence\n    bb[7] <- qv[5]\n  }\n  bb[3:5] <- qv[2:4]\n  return(bb)\n}\n\n\n# creating the get.var function\n# arguments - vname: variable name (in quotes), df: name of sf data.frame\n# returns - v: vector with values (without col name)\nget.var <- function(vname,df) {\n  v <- df[vname] %>% st_set_geometry(NULL)\n  v <- unname(v[,1])\n  return(v)\n}\n\n\n# test function\nvar <- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n0.6.1 Boxmap function\n\nboxmap <- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var <- get.var(vnam,df)\n  bb <- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Set3\",\n          labels = c(\"lower outlier\", \n                     \"< 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"> 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\n\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)\n\n\n\n\n\n\n\n0.7 Recode to zero\nThis code chunk is used to recode LGAs with zero total water points into NA.\n\nNGA_wp <- NGA_wp %>%\n  mutate(wp_functional = na_if(\n    total_wp, total_wp < 0))"
  },
  {
    "objectID": "in-class_ex/in-class_ex04/in-class_ex04.html",
    "href": "in-class_ex/in-class_ex04/in-class_ex04.html",
    "title": "In-Class Exercise 4: 2nd Order Spatial Point Patterns Analysis",
    "section": "",
    "text": "Spatial point processes of childcare centers in Singapore using 2nd order spatial point pattern analysis methods.\n\npacman::p_load(maptools, sf, raster, spatstat, tmap)\n\nImporting spatial data - use sfpackage\n\n# point feature data providing both location and attribute info of childcare centres\nchildcare_sf <- st_read(\"data/child-care-services-geojson.geojson\") %>%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\guga-nesh\\IS415-GAA\\in-class_ex\\in-class_ex04\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n# polygon feature data showing the national boundary of Singapore\nsg_sf <- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\guga-nesh\\IS415-GAA\\in-class_ex\\in-class_ex04\\data' using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n# polygon feature data providing info of URA 2014 MasterPlan Planning Subzone boundary data\nmpsz_sf <- st_read(dsn = \"data\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\guga-nesh\\IS415-GAA\\in-class_ex\\in-class_ex04\\data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n# Dataframe with geometric properties\n  # this is spatial data in the sf form\n  # while this is fine with most functions (tidyverse family) that work well with tibble dataframe\n  # but do take note will you need to drop the geometric properties for other methods...\n\nPlotting the map of childcare centers:\n\n# tmap_mode(\"plot\") #view\n# tm_shape(childcare_sf)+\n#   tm_dots(alph=0.5, # transparency (intensity of colour based on value)\n#           size=0.01)+\n#   tm_view(set.zoom.limits=c(11,24)) # zoom-out value, zoom-in value\n\n\n# tm_shape(sg_sf) +\n#   tm_polygons() +\n# tm_shape(mpsz_sf) +\n#   tm_polygons() +\n# tm_shape(childcare_sf)+\n#   tm_dots()\n\nConverting sf dataframe into SpatialPointsDataFrame.\n\n# because we want to use spatstat which requires analytical data in ppp object form we need to convert the data \nchildcare <- as_Spatial(childcare_sf)\nmpsz <- as_Spatial(mpsz_sf)\nsg <- as_Spatial(sg_sf)\n\nDisplay the information of these 3 Spatial classes\n\nchildcare #Geometry type = POINT\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>018989</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>08F73931F4A691F4</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center> \nmax values  : kml_999,                  <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>829646</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>RAFFLES KIDZ @ PUNGGOL PTE LTD</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>379D017BF244B0FA</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center> \n\n\n\nmpsz # Spatial Polygons DataFrame\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\n\nsg # Spatial Polygons DataFrame\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND \n\n\nConverting SpatialPointsDataFrame into Formal Class SpatialPoints\n\nchildcare_sp <- as(childcare, \"SpatialPoints\")\nsg_sp <- as(sg, \"SpatialPolygons\")\n\nConverting them into ppp format to be understood by spatstat\n\nchildcare_ppp = as(childcare_sp, \"ppp\")\n\nHandling duplicated point events\n\n# check whether there is any duplicate points and push the datapoints slightly through jittering to avoid duplication.\nchildcare_ppp_jit <- rjitter(childcare_ppp,\n                             retry=TRUE,\n                             nsim=1,\n                             drop=TRUE)\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE\n\n\n\nsummary(childcare_ppp_jit)\n\nPlanar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\nCreating an owin object to confine the analysis within a geographical area (in this case, Singapore boundary)\n\nsg_owin <- as(sg_sp, \"owin\")\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\nplot(childcareSG_ppp)\n\n\n\nsummary(childcareSG_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 2.063463e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: polygonal boundary\n60 separate polygons (no holes)\n            vertices        area relative.area\npolygon 1         38 1.56140e+04      2.09e-05\npolygon 2        735 4.69093e+06      6.27e-03\npolygon 3         49 1.66986e+04      2.23e-05\npolygon 4         76 3.12332e+05      4.17e-04\npolygon 5       5141 6.36179e+08      8.50e-01\npolygon 6         42 5.58317e+04      7.46e-05\npolygon 7         67 1.31354e+06      1.75e-03\npolygon 8         15 4.46420e+03      5.96e-06\npolygon 9         14 5.46674e+03      7.30e-06\npolygon 10        37 5.26194e+03      7.03e-06\npolygon 11        53 3.44003e+04      4.59e-05\npolygon 12        74 5.82234e+04      7.78e-05\npolygon 13        69 5.63134e+04      7.52e-05\npolygon 14       143 1.45139e+05      1.94e-04\npolygon 15       165 3.38736e+05      4.52e-04\npolygon 16       130 9.40465e+04      1.26e-04\npolygon 17        19 1.80977e+03      2.42e-06\npolygon 18        16 2.01046e+03      2.69e-06\npolygon 19        93 4.30642e+05      5.75e-04\npolygon 20        90 4.15092e+05      5.54e-04\npolygon 21       721 1.92795e+06      2.57e-03\npolygon 22       330 1.11896e+06      1.49e-03\npolygon 23       115 9.28394e+05      1.24e-03\npolygon 24        37 1.01705e+04      1.36e-05\npolygon 25        25 1.66227e+04      2.22e-05\npolygon 26        10 2.14507e+03      2.86e-06\npolygon 27       190 2.02489e+05      2.70e-04\npolygon 28       175 9.25904e+05      1.24e-03\npolygon 29      1993 9.99217e+06      1.33e-02\npolygon 30        38 2.42492e+04      3.24e-05\npolygon 31        24 6.35239e+03      8.48e-06\npolygon 32        53 6.35791e+05      8.49e-04\npolygon 33        41 1.60161e+04      2.14e-05\npolygon 34        22 2.54368e+03      3.40e-06\npolygon 35        30 1.08382e+04      1.45e-05\npolygon 36       327 2.16921e+06      2.90e-03\npolygon 37       111 6.62927e+05      8.85e-04\npolygon 38        90 1.15991e+05      1.55e-04\npolygon 39        98 6.26829e+04      8.37e-05\npolygon 40       415 3.25384e+06      4.35e-03\npolygon 41       222 1.51142e+06      2.02e-03\npolygon 42       107 6.33039e+05      8.45e-04\npolygon 43         7 2.48299e+03      3.32e-06\npolygon 44        17 3.28303e+04      4.38e-05\npolygon 45        26 8.34758e+03      1.11e-05\npolygon 46       177 4.67446e+05      6.24e-04\npolygon 47        16 3.19460e+03      4.27e-06\npolygon 48        15 4.87296e+03      6.51e-06\npolygon 49        66 1.61841e+04      2.16e-05\npolygon 50       149 5.63430e+06      7.53e-03\npolygon 51       609 2.62570e+07      3.51e-02\npolygon 52         8 7.82256e+03      1.04e-05\npolygon 53       976 2.33447e+07      3.12e-02\npolygon 54        55 8.25379e+04      1.10e-04\npolygon 55       976 2.33447e+07      3.12e-02\npolygon 56        61 3.33449e+05      4.45e-04\npolygon 57         6 1.68410e+04      2.25e-05\npolygon 58         4 9.45963e+03      1.26e-05\npolygon 59        46 6.99702e+05      9.35e-04\npolygon 60        13 7.00873e+04      9.36e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 748741000 square units\nFraction of frame area: 0.414\n\n\n\n\n\nderiving kernel density estimation (KDE) layer for visualising and exploring the intensity of point processes\n\nCalculating KDE using fixed bandwidth\n\n# bw.diggle() automatic bandwidth selection method\n# spatial interpolation is gaussian\n# intensity estimate is correct for edge bias\n\n# rescalling to convert unit of measurement from m to km\n# makes it easier to comprehend the KDE\n  # Look at the scale, 0-5 childcare centers within a search radius of 1km\nchildcareSG_ppp.km = rescale(childcareSG_ppp, 1000, \"km\")\n\n# computing KDE using fixed bandwidth\nkde_childcareSG_bw <- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\nplot(kde_childcareSG_bw)\n\n\n\n# please note that there are other bandwidth calculation methods other than bw.diggle\n  # bw.CvL\n  # bw.scott\n  # bw.ppl\n\nThere are two ways to compute KDE using adaptive bandwidth:\n\ndensityVoronoi\ndensityAdaptiveKernal\n\n\nkde_childcareSG_adaptive <- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\nThis KDE map shown above is an image file. It does not have any coordinates and we don’t know exactly where the location is. So we need to convert the image into Grid Object.\n\ngridded_kde_childcareSG_bw <- as.SpatialGridDataFrame.im(kde_childcareSG_bw)\nspplot(gridded_kde_childcareSG_bw)\n\n\n\n\n\n# then we create a rasterlayer\nkde_childcareSG_bw_raster <- raster(gridded_kde_childcareSG_bw)\n# but the crs property will be NA - so we will add the appropriate crs\nprojection(kde_childcareSG_bw_raster) <- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 417.0614, 264.7348  (x, y)\nextent     : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs        : +init=EPSG:3414 \nsource     : memory\nnames      : v \nvalues     : -9.998042e-21, 2.851831e-05  (min, max)\n\n\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"v\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\n\n\n\n\nperforming confirmatory spatial point patterns analysis by using nearest neighbour statistics\n\n\n\n\n\n# extract study area\npg = mpsz[mpsz@data$PLN_AREA_N == \"PUNGGOL\",]\ntm = mpsz[mpsz@data$PLN_AREA_N == \"TAMPINES\",]\nck = mpsz[mpsz@data$PLN_AREA_N == \"CHOA CHU KANG\",]\njw = mpsz[mpsz@data$PLN_AREA_N == \"JURONG WEST\",]\n\n# convert the spatial polygons dataframe into generic spatialpolygon layers\npg_sp = as(pg, \"SpatialPolygons\")\ntm_sp = as(tm, \"SpatialPolygons\")\nck_sp = as(ck, \"SpatialPolygons\")\njw_sp = as(jw, \"SpatialPolygons\")\n\n# creating owin object\npg_owin = as(pg_sp, \"owin\")\ntm_owin = as(tm_sp, \"owin\")\nck_owin = as(ck_sp, \"owin\")\njw_owin = as(jw_sp, \"owin\")\n\n# combining childcare points and study area\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\n# rescale() to km\nchildcare_pg_ppp.km = rescale(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale(childcare_jw_ppp, 1000, \"km\")\n\n# plot all study areas\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\n\n\n\n\nG-function - measures the distribution of the distances from an arbitrary event to its nearest event.\n\n\n# Gest() is used to compute the G-function estimation\n# envelope() is used to perform monte carlo simulation\n\nG_CK = Gest(childcare_ck_ppp, correction = \"border\")\nplot(G_CK, xlim=c(0,500))\n\n\n\n\n\n# H0: the distribution of childcare services at CCK are randomly distributed\n# H1: the distribution of childcare services at CCK are not randomly distributed\n# Null hypothesis is rejected if p-value is smaller than alpha value of 0.001\n  # 49 - 95%, 99 - 99%, 999 - 99.9%\nG_CK.csr <- envelope(childcare_ck_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60........\n.70.........80.........90.........100.........110.........120.........130......\n...140.........150.........160.........170.........180.........190.........200....\n.....210.........220.........230.........240.........250.........260.........270..\n.......280.........290.........300.........310.........320.........330.........340\n.........350.........360.........370.........380.........390.........400........\n.410.........420.........430.........440.........450.........460.........470......\n...480.........490.........500.........510.........520.........530.........540....\n.....550.........560.........570.........580.........590.........600.........610..\n.......620.........630.........640.........650.........660.........670.........680\n.........690.........700.........710.........720.........730.........740........\n.750.........760.........770.........780.........790.........800.........810......\n...820.........830.........840.........850.........860.........870.........880....\n.....890.........900.........910.........920.........930.........940.........950..\n.......960.........970.........980.........990........ 999.\n\nDone.\n\n\n\nplot(G_CK.csr)\n\n\n\n\nHow to analyse the above-mentioned graph:\nThere is insufficient statistical evidence to reject the null hypothesis that the distribution is random.\nHow to read the graph:\nAnything below the red line is regular pattern, anything above shows clustering. Inside the grey area, cannot reject the null hypothesis, outside grey area = statistically significant to reject.\n\nF-function\n\n\nF_CK = Fest(childcare_ck_ppp) # can do correction = \"best\"\nplot(F_CK)\n\n\n\n\n\nF_CK.csr <- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60........\n.70.........80.........90.........100.........110.........120.........130......\n...140.........150.........160.........170.........180.........190.........200....\n.....210.........220.........230.........240.........250.........260.........270..\n.......280.........290.........300.........310.........320.........330.........340\n.........350.........360.........370.........380.........390.........400........\n.410.........420.........430.........440.........450.........460.........470......\n...480.........490.........500.........510.........520.........530.........540....\n.....550.........560.........570.........580.........590.........600.........610..\n.......620.........630.........640.........650.........660.........670.........680\n.........690.........700.........710.........720.........730.........740........\n.750.........760.........770.........780.........790.........800.........810......\n...820.........830.........840.........850.........860.........870.........880....\n.....890.........900.........910.........920.........930.........940.........950..\n.......960.........970.........980.........990........ 999.\n\nDone.\n\n\n\nplot(F_CK.csr)\n\n\n\n\n\nK-function\n\n\nK_ck = Kest(childcare_ck_ppp, correction = \"Ripley\")\nplot(K_ck, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\nK_ck.csr <- envelope(childcare_ck_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98,  99.\n\nDone.\n\n\n\nplot(K_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n\nL-function\n\n\nL_ck = Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_ck, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\nL_ck.csr <- envelope(childcare_ck_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98,  99.\n\nDone.\n\n\n\nplot(L_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")"
  },
  {
    "objectID": "in-class_ex/in-class_ex05/data/stores.html",
    "href": "in-class_ex/in-class_ex05/data/stores.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>     \n\n\n        0 0     false"
  },
  {
    "objectID": "in-class_ex/in-class_ex05/data/study_area.html",
    "href": "in-class_ex/in-class_ex05/data/study_area.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "in-class_ex/in-class_ex05/in-class_ex05.html",
    "href": "in-class_ex/in-class_ex05/in-class_ex05.html",
    "title": "In-Class Exercise 5: 2nd Order Spatial Point Patterns Analysis",
    "section": "",
    "text": "1 Install relevant packages\n\npacman::p_load(tidyverse, tmap, sf, sfdep)\n\nWe only focus on local colocation quotient of the sfdep package\n\n\n2 Import studyArea\n\nstudyArea <- st_read(dsn = \"data\",\n                     layer = \"study_area\") %>%\n  st_transform(crs = 3829)#National Projection System of Taiwan\n\nReading layer `study_area' from data source \n  `C:\\guga-nesh\\IS415-GAA\\in-class_ex\\in-class_ex05\\data' using driver `ESRI Shapefile'\nSimple feature collection with 7 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 121.4836 ymin: 25.00776 xmax: 121.592 ymax: 25.09288\nGeodetic CRS:  TWD97\n\n\n\n\n3 Import stores data\n\nstores <- st_read(dsn = \"data\",\n                  layer = \"stores\") %>%\n  st_transform(crs = 3829)\n\nReading layer `stores' from data source \n  `C:\\guga-nesh\\IS415-GAA\\in-class_ex\\in-class_ex05\\data' using driver `ESRI Shapefile'\nSimple feature collection with 1409 features and 4 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 121.4902 ymin: 25.01257 xmax: 121.5874 ymax: 25.08557\nGeodetic CRS:  TWD97\n\n\n\n\n4 Plot the values imported\n\n# plotting functional and non-functional points in the area of study\ntmap_mode(\"view\")\ntm_shape(studyArea) +  #always display the polygon first\n  tm_polygons() +\ntm_shape(stores) + \n  tm_dots(col = \"Name\", #colour coded for 7-Elevent and Family Mart\n          size = 0.01,\n          border.col = \"black\",\n          border.lwd = 0.5) +\n  tm_view(set.zoom.limits = c(12, 16))\n\n\n\n\n\n\n\n\n5 Perform LCLQ calculation\n\n# neighbourhood list\nnb <- include_self(\n  st_knn(st_geometry(stores), 6)) # i want it to search for the 6 nearest neighbours - stay with even number you will never have a balance of neighbours\n\n# weight\nwt <- st_kernel_weights(nb, # calculate weight metrics using adaptive and gaussian mtd\n                        stores,\n                        \"gaussian\",\n                        adaptive = TRUE)\n\nFamilyMart <- stores %>%\n  filter(Name == \"Family Mart\")\nA <- FamilyMart$Name # variable is a vector to be used in local_colocation()\n\nSevenEleven <- stores %>%\n  filter(Name == \"7-Eleven\")\nB <- SevenEleven$Name\n\n\n# A = target\n# B = neighbour to find out if colocate or not\n# once you take nsim it will take the p-value automatically\nLCLQ <- local_colocation(A, B, nb, wt, 49) # this is a data table with 2 columns in order to map it we need to combine it back with the stores. NA means cannot find colocation or isolation (not significant)\nLCLQ_stores <- cbind(stores, LCLQ) # only works if you don't sort the LCLQ it binds by the same table order from the orginal stores data\n\nLCLQ_stores\n\nSimple feature collection with 1409 features and 6 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 346837.2 ymin: 2767381 xmax: 356661.3 ymax: 2775447\nProjected CRS: Hu Tzu Shan 1950 / UTM zone 51N\nFirst 10 features:\n          Name  CompNum      lat      lng X7.Eleven p_sim_7.Eleven\n1  Family Mart 16080660 25.04065 121.5022  0.998818           0.08\n2  Family Mart 16082885 25.04251 121.5768  0.998818           0.04\n3  Family Mart 16090111 25.05628 121.5407        NA             NA\n4  Family Mart 16093150 25.03333 121.5548        NA             NA\n5  Family Mart 16095713 25.02866 121.5392        NA             NA\n6  Family Mart 16098747 25.05705 121.5255        NA             NA\n7  Family Mart 16434609 25.03642 121.5016        NA             NA\n8  Family Mart 16435369 25.04579 121.5717        NA             NA\n9  Family Mart 16435564 25.06487 121.5228        NA             NA\n10 Family Mart 16438035 25.04535 121.5756        NA             NA\n                   geometry\n1  POINT (348063.3 2770528)\n2    POINT (355596 2770652)\n3    POINT (351962 2772217)\n4  POINT (353358.8 2769660)\n5  POINT (351784.6 2769159)\n6  POINT (350433.4 2772319)\n7  POINT (347995.4 2770060)\n8  POINT (355076.8 2771021)\n9  POINT (350166.9 2773188)\n10 POINT (355472.4 2770968)\n\n\n\n# see which points are colocated and their corresponding p-value\ntmap_mode(\"view\")\ntm_shape(studyArea) + \n  tm_polygons() + \ntm_shape(LCLQ_stores) + \n  tm_dots(col = \"X7.Eleven\",\n          size = 0.01,\n          border.col = \"black\",\n          border.lwd = 0.5) +\n  tm_view(set.zoom.limits = c(12, 16))"
  },
  {
    "objectID": "in-class_ex/in-class_ex06/in-class_ex06.html",
    "href": "in-class_ex/in-class_ex06/in-class_ex06.html",
    "title": "In-Class Exercise 6: Spatial Weights - sfdep method",
    "section": "",
    "text": "pacman::p_load(sf, sfdep, tidyverse, tmap)"
  },
  {
    "objectID": "in-class_ex/in-class_ex06/in-class_ex06.html#importing-geospatial-data",
    "href": "in-class_ex/in-class_ex06/in-class_ex06.html#importing-geospatial-data",
    "title": "In-Class Exercise 6: Spatial Weights - sfdep method",
    "section": "2.1 Importing geospatial data",
    "text": "2.1 Importing geospatial data\nImport the data as an sf format.\n\nhunan <- st_read(dsn=\"data/geospatial\",\n                 layer=\"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\guga-nesh\\IS415-GAA\\in-class_ex\\in-class_ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n# geographic coordinate system is not good for distance-based metrics, but if you're going for contiguity its ok"
  },
  {
    "objectID": "in-class_ex/in-class_ex06/in-class_ex06.html#importing-attribute-table",
    "href": "in-class_ex/in-class_ex06/in-class_ex06.html#importing-attribute-table",
    "title": "In-Class Exercise 6: Spatial Weights - sfdep method",
    "section": "2.2 Importing attribute table",
    "text": "2.2 Importing attribute table\nImport the data as a tibble data frame.\n\nhunan_2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nhunan_2012\n\n# A tibble: 88 × 29\n   County    City     avg_w…¹ depos…²    FAI Gov_Rev Gov_Exp    GDP GDPPC    GIO\n   <chr>     <chr>      <dbl>   <dbl>  <dbl>   <dbl>   <dbl>  <dbl> <dbl>  <dbl>\n 1 Anhua     Yiyang     30544  10967   6832.    457.   2703  13225  14567  9277.\n 2 Anren     Chenzhou   28058   4599.  6386.    221.   1455.  4941. 12761  4189.\n 3 Anxiang   Changde    31935   5517.  3541     244.   1780. 12482  23667  5109.\n 4 Baojing   Hunan W…   30843   2250   1005.    193.   1379.  4088. 14563  3624.\n 5 Chaling   Zhuzhou    31251   8241.  6508.    620.   1947  11585  20078  9158.\n 6 Changning Hengyang   28518  10860   7920     770.   2632. 19886  24418 37392 \n 7 Changsha  Changsha   54540  24332  33624    5350    7886. 88009  88656 51361 \n 8 Chengbu   Shaoyang   28597   2581.  1922.    161.   1192.  2570. 10132  1681.\n 9 Chenxi    Huaihua    33580   4990   5818.    460.   1724.  7755. 17026  6644.\n10 Cili      Zhangji…   33099   8117.  4498.    500.   2306. 11378  18714  5843.\n# … with 78 more rows, 19 more variables: Loan <dbl>, NIPCR <dbl>, Bed <dbl>,\n#   Emp <dbl>, EmpR <dbl>, EmpRT <dbl>, Pri_Stu <dbl>, Sec_Stu <dbl>,\n#   Household <dbl>, Household_R <dbl>, NOIP <dbl>, Pop_R <dbl>, RSCG <dbl>,\n#   Pop_T <dbl>, Agri <dbl>, Service <dbl>, Disp_Inc <dbl>, RORP <dbl>,\n#   ROREmp <dbl>, and abbreviated variable names ¹​avg_wage, ²​deposite"
  },
  {
    "objectID": "in-class_ex/in-class_ex06/in-class_ex06.html#combining-both-data-frames-using-left-join",
    "href": "in-class_ex/in-class_ex06/in-class_ex06.html#combining-both-data-frames-using-left-join",
    "title": "In-Class Exercise 6: Spatial Weights - sfdep method",
    "section": "2.3 Combining both data frames using left join",
    "text": "2.3 Combining both data frames using left join\nCombine the spatial and aspatial data. Since one is the tibble data frame and he other is an sf object, to retain geospatial properties, the left data frame must be sf (i.e., hunan)\n\n# left_join() keeps all observations in x\n# in this case, we did not mention the common identifier - by default uses common field\n# after they have been joined, I want only columns 1-4, 7, and 15 (basically I just want the GDPPC from the hunan_2012)\n\nhunan_GDPPC <- left_join(hunan, hunan_2012) %>%\n  select(1:4, 7, 15)\n\nhunan_GDPPC\n\nSimple feature collection with 88 features and 6 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n     NAME_2  ID_3    NAME_3   ENGTYPE_3    County GDPPC\n1   Changde 21098   Anxiang      County   Anxiang 23667\n2   Changde 21100   Hanshou      County   Hanshou 20981\n3   Changde 21101    Jinshi County City    Jinshi 34592\n4   Changde 21102        Li      County        Li 24473\n5   Changde 21103     Linli      County     Linli 25554\n6   Changde 21104    Shimen      County    Shimen 27137\n7  Changsha 21109   Liuyang County City   Liuyang 63118\n8  Changsha 21110 Ningxiang      County Ningxiang 62202\n9  Changsha 21111 Wangcheng      County Wangcheng 70666\n10 Chenzhou 21112     Anren      County     Anren 12761\n                         geometry\n1  POLYGON ((112.0625 29.75523...\n2  POLYGON ((112.2288 29.11684...\n3  POLYGON ((111.8927 29.6013,...\n4  POLYGON ((111.3731 29.94649...\n5  POLYGON ((111.6324 29.76288...\n6  POLYGON ((110.8825 30.11675...\n7  POLYGON ((113.9905 28.5682,...\n8  POLYGON ((112.7181 28.38299...\n9  POLYGON ((112.7914 28.52688...\n10 POLYGON ((113.1757 26.82734..."
  },
  {
    "objectID": "in-class_ex/in-class_ex06/in-class_ex06.html#plotting-choropleth-map",
    "href": "in-class_ex/in-class_ex06/in-class_ex06.html#plotting-choropleth-map",
    "title": "In-Class Exercise 6: Spatial Weights - sfdep method",
    "section": "2.4 Plotting Choropleth Map",
    "text": "2.4 Plotting Choropleth Map\n\ntmap_mode(\"plot\")\n\ntm_shape(hunan_GDPPC)+\n  tm_fill(\"GDPPC\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"GDPPC\") +\n  tm_layout(main.title = \"Distribution of GDP per capita by district, Hunan Province\",\n            main.title.position = \"center\",\n            main.title.size = 0.8,\n            legend.height = 0.35, \n            legend.width = 0.25,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 1) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)\n\n\n\n# remember tm_fill and tm_borders will give you the tm_polygon, we do it like this to have a higher level of control on the visuals\n\n# always output the map first to see where you can place the map components like scale bar, compass, etc.\n\n# Classification Method: if you are designing for a regional economic study then you might want to use \"equal interval\" classification method. It depends on the purpose of our study."
  },
  {
    "objectID": "in-class_ex/in-class_ex06/in-class_ex06.html#identify-contiguity-neighbours-queens-method",
    "href": "in-class_ex/in-class_ex06/in-class_ex06.html#identify-contiguity-neighbours-queens-method",
    "title": "In-Class Exercise 6: Spatial Weights - sfdep method",
    "section": "3.1 Identify contiguity neighbours: Queen’s method",
    "text": "3.1 Identify contiguity neighbours: Queen’s method\nBefore the spatial weight matrix can be derived, the neighbours need to be identified first.\nst_contiguity() is used to derive contiguity neighbour list using Queen’s method. Documentation can be found here. Some key information:\n\nIt only works for sf geometry type POLYGON or MULTIPOLYGON.\nBy default, it uses queen (i.e., spdep::poly2nb).\n\n\ncn_queen <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry),\n         .before=1)\n\n# use dplyr::mutate() to create new field that stores st_contiguity() on the geometry field\n# .before = 1 basically puts the newly created field in the first column\n\nThe code chunk below is used to print the summary of the first lag neighbour list (i.e., nb).\n\nsummary(cn_queen$nb)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe output above shows that there are 88 area units in Hunan province. The most connected area has 11 neighbours. There are two units with only 1 neighbour.\nLet’s view the table\n\ncn_queen\n\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                               nb   NAME_2  ID_3    NAME_3   ENGTYPE_3\n1                 2, 3, 4, 57, 85  Changde 21098   Anxiang      County\n2               1, 57, 58, 78, 85  Changde 21100   Hanshou      County\n3                     1, 4, 5, 85  Changde 21101    Jinshi County City\n4                      1, 3, 5, 6  Changde 21102        Li      County\n5                     3, 4, 6, 85  Changde 21103     Linli      County\n6                4, 5, 69, 75, 85  Changde 21104    Shimen      County\n7                  67, 71, 74, 84 Changsha 21109   Liuyang County City\n8       9, 46, 47, 56, 78, 80, 86 Changsha 21110 Ningxiang      County\n9           8, 66, 68, 78, 84, 86 Changsha 21111 Wangcheng      County\n10 16, 17, 19, 20, 22, 70, 72, 73 Chenzhou 21112     Anren      County\n      County GDPPC                       geometry\n1    Anxiang 23667 POLYGON ((112.0625 29.75523...\n2    Hanshou 20981 POLYGON ((112.2288 29.11684...\n3     Jinshi 34592 POLYGON ((111.8927 29.6013,...\n4         Li 24473 POLYGON ((111.3731 29.94649...\n5      Linli 25554 POLYGON ((111.6324 29.76288...\n6     Shimen 27137 POLYGON ((110.8825 30.11675...\n7    Liuyang 63118 POLYGON ((113.9905 28.5682,...\n8  Ningxiang 62202 POLYGON ((112.7181 28.38299...\n9  Wangcheng 70666 POLYGON ((112.7914 28.52688...\n10     Anren 12761 POLYGON ((113.1757 26.82734...\n\n\nThe above output shows that polygon 1 has 5 neighbours: 2, 3, 4, 57, and 85. We can reveal the country name of the neighbours by using the code chunk below.\n\ncn_queen$County[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\""
  },
  {
    "objectID": "in-class_ex/in-class_ex06/in-class_ex06.html#identify-contiguity-neighbours-rooks-method",
    "href": "in-class_ex/in-class_ex06/in-class_ex06.html#identify-contiguity-neighbours-rooks-method",
    "title": "In-Class Exercise 6: Spatial Weights - sfdep method",
    "section": "3.2 Identify contiguity neighbours: Rook’s method",
    "text": "3.2 Identify contiguity neighbours: Rook’s method\n\ncn_rook <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry, \n                            queen=FALSE),\n         .before=1)"
  },
  {
    "objectID": "in-class_ex/in-class_ex06/in-class_ex06.html#identifying-higher-order-neighbours",
    "href": "in-class_ex/in-class_ex06/in-class_ex06.html#identifying-higher-order-neighbours",
    "title": "In-Class Exercise 6: Spatial Weights - sfdep method",
    "section": "3.3 Identifying higher order neighbours",
    "text": "3.3 Identifying higher order neighbours\nSometimes we need to identify high order contiguity neighbours. “High order” refers to the number of dimensions involved in the space. For instance, “first-order” contiguity neighbours are the immediate neighbours of a given point, while the “second-order” contiguity neighbours are the neighbours of the immediate neighbours.\nTo accomplish the task, st_nb_lg_cumul() should be used as shown in the code chunk below.\n\ncn2_queen <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry),\n         nb2 = st_nb_lag_cumul(nb, 2),\n         .before = 1)\n\nNote that if the order is 2, the result contains both 1st and 2nd order neighbours as shown on the print below.\n\ncn2_queen\n\nSimple feature collection with 88 features and 8 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                               nb\n1                 2, 3, 4, 57, 85\n2               1, 57, 58, 78, 85\n3                     1, 4, 5, 85\n4                      1, 3, 5, 6\n5                     3, 4, 6, 85\n6                4, 5, 69, 75, 85\n7                  67, 71, 74, 84\n8       9, 46, 47, 56, 78, 80, 86\n9           8, 66, 68, 78, 84, 86\n10 16, 17, 19, 20, 22, 70, 72, 73\n                                                                                        nb2\n1                                     2, 3, 4, 5, 6, 32, 56, 57, 58, 64, 69, 75, 76, 78, 85\n2                           1, 3, 4, 5, 6, 8, 9, 32, 56, 57, 58, 64, 68, 69, 75, 76, 78, 85\n3                                                 1, 2, 4, 5, 6, 32, 56, 57, 69, 75, 78, 85\n4                                                             1, 2, 3, 5, 6, 57, 69, 75, 85\n5                                                 1, 2, 3, 4, 6, 32, 56, 57, 69, 75, 78, 85\n6                                         1, 2, 3, 4, 5, 32, 53, 55, 56, 57, 69, 75, 78, 85\n7                                                     9, 19, 66, 67, 71, 73, 74, 76, 84, 86\n8  2, 9, 19, 21, 31, 32, 34, 35, 36, 41, 45, 46, 47, 56, 58, 66, 68, 74, 78, 80, 84, 85, 86\n9               2, 7, 8, 19, 21, 35, 46, 47, 56, 58, 66, 67, 68, 74, 76, 78, 80, 84, 85, 86\n10               11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 70, 71, 72, 73, 74, 82, 83, 86\n     NAME_2  ID_3    NAME_3   ENGTYPE_3    County GDPPC\n1   Changde 21098   Anxiang      County   Anxiang 23667\n2   Changde 21100   Hanshou      County   Hanshou 20981\n3   Changde 21101    Jinshi County City    Jinshi 34592\n4   Changde 21102        Li      County        Li 24473\n5   Changde 21103     Linli      County     Linli 25554\n6   Changde 21104    Shimen      County    Shimen 27137\n7  Changsha 21109   Liuyang County City   Liuyang 63118\n8  Changsha 21110 Ningxiang      County Ningxiang 62202\n9  Changsha 21111 Wangcheng      County Wangcheng 70666\n10 Chenzhou 21112     Anren      County     Anren 12761\n                         geometry\n1  POLYGON ((112.0625 29.75523...\n2  POLYGON ((112.2288 29.11684...\n3  POLYGON ((111.8927 29.6013,...\n4  POLYGON ((111.3731 29.94649...\n5  POLYGON ((111.6324 29.76288...\n6  POLYGON ((110.8825 30.11675...\n7  POLYGON ((113.9905 28.5682,...\n8  POLYGON ((112.7181 28.38299...\n9  POLYGON ((112.7914 28.52688...\n10 POLYGON ((113.1757 26.82734..."
  },
  {
    "objectID": "in-class_ex/in-class_ex06/in-class_ex06.html#deriving-contiguity-weights-queens-method",
    "href": "in-class_ex/in-class_ex06/in-class_ex06.html#deriving-contiguity-weights-queens-method",
    "title": "In-Class Exercise 6: Spatial Weights - sfdep method",
    "section": "3.4 Deriving contiguity weights: Queen’s method",
    "text": "3.4 Deriving contiguity weights: Queen’s method\nNow, we are ready to compute the contiguity weights by using st_weights() of sfdep package.\nIn the code chunk below, queen method is used to derive the contiguity weights.\n\ncw_queen <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb,\n                         style=\"W\"),\n         .before = 1)\n\nNote that st_weights() provides 3 arguments:\n\nnb: A neighbour list object created by st_contiguity()\nstyle: Default “W” for row standardized weights (sum over all links to n). Other options include “B”, “C”, “U”, “minmax”, “S”. B is the basic binary coding, C is globally standardised (sums over all links to n), U is equal to C / number of neighbours (sum over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\nallow_zero: if TRUE, assigns zero as lagged value to zone without neighbours.\n\n\ncw_queen\n\nSimple feature collection with 88 features and 8 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                               nb\n1                 2, 3, 4, 57, 85\n2               1, 57, 58, 78, 85\n3                     1, 4, 5, 85\n4                      1, 3, 5, 6\n5                     3, 4, 6, 85\n6                4, 5, 69, 75, 85\n7                  67, 71, 74, 84\n8       9, 46, 47, 56, 78, 80, 86\n9           8, 66, 68, 78, 84, 86\n10 16, 17, 19, 20, 22, 70, 72, 73\n                                                                            wt\n1                                                      0.2, 0.2, 0.2, 0.2, 0.2\n2                                                      0.2, 0.2, 0.2, 0.2, 0.2\n3                                                       0.25, 0.25, 0.25, 0.25\n4                                                       0.25, 0.25, 0.25, 0.25\n5                                                       0.25, 0.25, 0.25, 0.25\n6                                                      0.2, 0.2, 0.2, 0.2, 0.2\n7                                                       0.25, 0.25, 0.25, 0.25\n8  0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571\n9             0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667\n10                      0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125\n     NAME_2  ID_3    NAME_3   ENGTYPE_3    County GDPPC\n1   Changde 21098   Anxiang      County   Anxiang 23667\n2   Changde 21100   Hanshou      County   Hanshou 20981\n3   Changde 21101    Jinshi County City    Jinshi 34592\n4   Changde 21102        Li      County        Li 24473\n5   Changde 21103     Linli      County     Linli 25554\n6   Changde 21104    Shimen      County    Shimen 27137\n7  Changsha 21109   Liuyang County City   Liuyang 63118\n8  Changsha 21110 Ningxiang      County Ningxiang 62202\n9  Changsha 21111 Wangcheng      County Wangcheng 70666\n10 Chenzhou 21112     Anren      County     Anren 12761\n                         geometry\n1  POLYGON ((112.0625 29.75523...\n2  POLYGON ((112.2288 29.11684...\n3  POLYGON ((111.8927 29.6013,...\n4  POLYGON ((111.3731 29.94649...\n5  POLYGON ((111.6324 29.76288...\n6  POLYGON ((110.8825 30.11675...\n7  POLYGON ((113.9905 28.5682,...\n8  POLYGON ((112.7181 28.38299...\n9  POLYGON ((112.7914 28.52688...\n10 POLYGON ((113.1757 26.82734..."
  },
  {
    "objectID": "in-class_ex/in-class_ex06/in-class_ex06.html#deriving-contiguity-weights-rooks-method",
    "href": "in-class_ex/in-class_ex06/in-class_ex06.html#deriving-contiguity-weights-rooks-method",
    "title": "In-Class Exercise 6: Spatial Weights - sfdep method",
    "section": "3.5 Deriving contiguity weights: Rook’s method",
    "text": "3.5 Deriving contiguity weights: Rook’s method\n\n# is it supposed to be hunan_GDPPC\ncw_rooks <- hunan %>%\n  mutate(nb = st_contiguity(geometry,\n                            queen = FALSE),\n         wt = st_weights(nb),\n         .before = 1)"
  },
  {
    "objectID": "in-class_ex/in-class_ex06/in-class_ex06.html#deriving-fixed-distance-weights",
    "href": "in-class_ex/in-class_ex06/in-class_ex06.html#deriving-fixed-distance-weights",
    "title": "In-Class Exercise 6: Spatial Weights - sfdep method",
    "section": "4.1 Deriving fixed distance weights",
    "text": "4.1 Deriving fixed distance weights\nBefore we can derive the fixed distance weights, we need to determine the upper limit for distance band by using the steps below:\n\ngeo <- sf::st_geometry(hunan_GDPPC)\n\n# st_geometry() used to get geometry from an sf object\n\nnb <- st_knn(geo, longlat = TRUE)\n\n# st_knn() identifies the k nearest neighbours for given point geometry. The longlat argument is to tell if point coordinates are long-lat decimal degrees (measures in km).\n\ndists <- unlist(st_nb_dists(geo, nb))\n\n# st_nb_dists() of sfdep is used to calculate the nearest neighbour distance. The output is a list of distances for each observation's neighbour list.\n\n# unlist() of Base R is used to return the output as a vector so the summary statistics of the nearest neighbour distances can be derived.\n\nNow we can derive the summary statistics of the nearest neighbour distances vector (i.e., dists) by using the code chunk below.\n\nsummary(dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  21.56   29.11   36.89   37.34   43.21   65.80 \n\n\nFrom the output above we know that the maximum nearest neighbour distance is 65.80km. By using a threshold value of 66km we will ensure that each area will have at least one neighbour.\nLet’s compute the fixed distance weights by using the code chunk below.\n\ndw_fd <- hunan_GDPPC %>%\n  mutate(nb = st_dist_band(geometry,\n                           upper = 66),\n         wt = st_weights(nb),\n         .before=1)\n\n# st_dists_band() of sfdep is used to identify neighbours based on a distance band (i.e., 66km). The output is a list of neighbours (i.e., nb).\n\n# st_weights() is then used to calculate polygon spatial weights of the nb list.\n  # The default style argument is set to \"W\"\n  # the default allow_zero arg. is set to TRUE, assigns ZERO as lagged value to zone without neighbours."
  },
  {
    "objectID": "in-class_ex/in-class_ex06/in-class_ex06.html#deriving-adaptive-distance-weights",
    "href": "in-class_ex/in-class_ex06/in-class_ex06.html#deriving-adaptive-distance-weights",
    "title": "In-Class Exercise 6: Spatial Weights - sfdep method",
    "section": "4.2 Deriving adaptive distance weights",
    "text": "4.2 Deriving adaptive distance weights\n\ndw_ad <- hunan_GDPPC %>% \n  mutate(nb = st_knn(geometry,\n                     k=8),\n         wt = st_weights(nb),\n               .before = 1)\n\n# st_knn() of sfdep is used to identify neighbours based on k (i.e., k=8 indicates the nearest eight neighbours). The output is a list of neighbours (i.e., nb)"
  },
  {
    "objectID": "in-class_ex/in-class_ex06/in-class_ex06.html#calculating-inverse-distance-weights",
    "href": "in-class_ex/in-class_ex06/in-class_ex06.html#calculating-inverse-distance-weights",
    "title": "In-Class Exercise 6: Spatial Weights - sfdep method",
    "section": "4.3 Calculating inverse distance weights",
    "text": "4.3 Calculating inverse distance weights\n\ndw_idw <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n\n# st_inverse_distance() is used to calculate inverse distance weights of neighbours on the nb list."
  },
  {
    "objectID": "in-class_ex/in-class_ex07/in-class_ex07.html",
    "href": "in-class_ex/in-class_ex07/in-class_ex07.html",
    "title": "In-Class Exercise 7: Global and Local Measures of Spatial Association + Emerging Hot Spot Analysis (sfdep methods)",
    "section": "",
    "text": "pacman::p_load(sf, tmap, sfdep, tidyverse)\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nName\nFormat\nDescription\n\n\n\n\nGeospatial\nHunan Province Administrative Boundary\n.shp\nData is at the County level.\n\n\nAspatial\nHunan_2012\n.xlsx\nSelected Hunan’s local development indicators in 2012.\n\n\n\n\n\n\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\guga-nesh\\IS415-GAA\\in-class_ex\\in-class_ex07\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nst_read() of sf package is used to import shapefile into R as a simple features object. Please refer to the documentation here.\n\n\n\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")"
  },
  {
    "objectID": "in-class_ex/in-class_ex07/in-class_ex07.html#performing-relational-join",
    "href": "in-class_ex/in-class_ex07/in-class_ex07.html#performing-relational-join",
    "title": "In-Class Exercise 7: Global and Local Measures of Spatial Association + Emerging Hot Spot Analysis (sfdep methods)",
    "section": "2.1 Performing relational join",
    "text": "2.1 Performing relational join\n\nhunan <- left_join(hunan,hunan2012) %>%\n  select(1:4, 7, 15)\n\n# auto takes the columns that exist in both objects\n\n\n\n\n\n\n\nNote\n\n\n\nThe above code chunk will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute field of hunan2012 dataframe. This is performed by using left_join() of dplyr package."
  },
  {
    "objectID": "in-class_ex/in-class_ex07/in-class_ex07.html#basic-esda",
    "href": "in-class_ex/in-class_ex07/in-class_ex07.html#basic-esda",
    "title": "In-Class Exercise 7: Global and Local Measures of Spatial Association + Emerging Hot Spot Analysis (sfdep methods)",
    "section": "3.1 Basic ESDA",
    "text": "3.1 Basic ESDA\n\n3.1.1 Visualising Regional Development Indicator\nWe will prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\ntmap_mode(\"plot\")\n\ntm_shape(hunan)+\n  tm_fill(\"GDPPC\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"GDPPC\") +\n  tm_layout(main.title = \"Distribution of GDP per capita by district, Hunan Province\",\n            main.title.position = \"center\",\n            main.title.size = 0.8,\n            legend.height = 0.35, \n            legend.width = 0.25,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 1) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)\n\n\n\n# remember tm_fill and tm_borders will give you the tm_polygon, we do it like this to have a higher level of control on the visuals\n\n# always output the map first to see where you can place the map components like scale bar, compass, etc.\n\n# Classification Method: if you are designing for a regional economic study then you might want to use \"equal interval\" classification method. It depends on the purpose of our study."
  },
  {
    "objectID": "in-class_ex/in-class_ex07/in-class_ex07.html#global-spatial-autocorrelation",
    "href": "in-class_ex/in-class_ex07/in-class_ex07.html#global-spatial-autocorrelation",
    "title": "In-Class Exercise 7: Global and Local Measures of Spatial Association + Emerging Hot Spot Analysis (sfdep methods)",
    "section": "3.2 Global Spatial Autocorrelation",
    "text": "3.2 Global Spatial Autocorrelation\nIn this section, we will compute the global spatial autocorrelation statistics and to perform spatial complete randomness test for global spatial autocorrelation.\n\n3.2.1 Computing Contiguity Spatial Weights\nBefore we can compute the global spatial autocorrelation statistics, we need to construct the spatial weights of the study area (to define the neighbourhood relationships between the counties in the study area).\n\n3.2.1.1 Deriving contiguity weights: Queen’s method\nWe will compute the contiguity weights by using st_weights() of sfdep package.\nIn the code chunk below, queen method is used to derive the contiguity weights.\n\ncw_queen <- hunan %>%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb,\n                         style=\"W\"),\n         .before = 1)\n\nNote that st_weights() provides 3 arguments:\n\nnb: A neighbour list object created by st_contiguity()\nstyle: Default “W” for row standardized weights (sum over all links to n). Other options include “B”, “C”, “U”, “minmax”, “S”.\n\nB is the basic binary coding,\nC is globally standardised (sums over all links to n),\nU is equal to C / number of neighbours (sum over all links to unity),\nwhile S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\n\nallow_zero: if TRUE, assigns zero as lagged value to zone without neighbours.\n\n\n\n\n\n\n\nNote\n\n\n\nTake note that nb and weight matrix are stored as a list. If you want to use them (we’ll do this later) you need to use unlist()\n\n\n\n\n\n3.2.2 Computing Global Moran’s I\n\nmoranI <- global_moran(cw_queen$GDPPC,\n                       cw_queen$nb,\n                       cw_queen$wt)\n\n\n\n\n\n\n\nNote\n\n\n\nmoranI is a tibble dataframe with two values. Normally, we don’t compute the Global Moran’s I we just perform the Global Moran’s I test (since it includes test result and test statistic). See below code chunk.\n\n\n\n\n3.2.3 Performing Global Moran’s I test\n\nglobal_moran_test(cw_queen$GDPPC,\n                  cw_queen$nb,\n                  cw_queen$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\n\n\n\n\n\nNote\n\n\n\nThe global Moran’s I test gives us the p-value allows you to know if you have enough statistical evidence to reject the null hypothesis or not. In this case, we have 0.000001095 which is < alpha value of 0.05. Hence, we have sufficient statistical evidence to reject the null hypothesis that the observed GDPPC is spatially independent.\nIn fact, the Moran’s I statistic is positive which shows us that there is positive autocorrelation (i..e., clustering)…\n\n\n\n\n3.2.4 Performing Global Moran’s I permutation test\n\n# this is done to ensure the code is reproducible - if involves simulations, please do this.\nset.seed(1234)\n\nglobal_moran_perm(cw_queen$GDPPC,\n                  cw_queen$nb,\n                  cw_queen$wt,\n                  nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value < 2.2e-16\nalternative hypothesis: two.sided\n\n# in this case, we are running 100 simulations\n\n\n\n\n\n\n\nNote\n\n\n\nWe can see that the significance level changes (p-value is smaller)\n\n\n\n\n3.2.5 Computing local Moran’s I\n\nlisa <- cw_queen %>%\n  mutate(local_moran = local_moran(\n    GDPPC, nb, wt, nsim = 99),\n    .before = 1) %>%\n  unnest(local_moran)\n\nlisa\n\nSimple feature collection with 88 features and 20 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 21\n         ii        eii   var_ii    z_ii    p_ii p_ii_…¹ p_fol…² skewn…³ kurtosis\n      <dbl>      <dbl>    <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>    <dbl>\n 1 -0.00147  0.00177    4.18e-4 -0.158  0.874      0.82    0.41  -0.812  0.652  \n 2  0.0259   0.00641    1.05e-2  0.190  0.849      0.96    0.48  -1.09   1.89   \n 3 -0.0120  -0.0374     1.02e-1  0.0796 0.937      0.76    0.38   0.824  0.0461 \n 4  0.00102 -0.0000349  4.37e-6  0.506  0.613      0.64    0.32   1.04   1.61   \n 5  0.0148  -0.00340    1.65e-3  0.449  0.654      0.5     0.25   1.64   3.96   \n 6 -0.0388  -0.00339    5.45e-3 -0.480  0.631      0.82    0.41   0.614 -0.264  \n 7  3.37    -0.198      1.41e+0  3.00   0.00266    0.08    0.04   1.46   2.74   \n 8  1.56    -0.265      8.04e-1  2.04   0.0417     0.08    0.04   0.459 -0.519  \n 9  4.42     0.0450     1.79e+0  3.27   0.00108    0.02    0.01   0.746 -0.00582\n10 -0.399   -0.0505     8.59e-2 -1.19   0.234      0.28    0.14  -0.685  0.134  \n# … with 78 more rows, 12 more variables: mean <fct>, median <fct>,\n#   pysal <fct>, nb <nb>, wt <list>, NAME_2 <chr>, ID_3 <int>, NAME_3 <chr>,\n#   ENGTYPE_3 <chr>, County <chr>, GDPPC <dbl>, geometry <POLYGON [°]>, and\n#   abbreviated variable names ¹​p_ii_sim, ²​p_folded_sim, ³​skewness\n\n\n\n\n\n\n\n\nNote\n\n\n\nHere are what the different columns mean:\nii - Moran’s I value\ne_ii - Expected value of Moran’s I\nvar_ii - Variance of Moran’s I\nz_ii - Standardisation of Moran’s I\np_ii - Moran’s I derived after simulation\nBtw, for Take-Home please use mean of lisa. The reasoning will be that it follows a somewhat Normal Distribution.\n\n\n\n\n3.2.6 Visualising local Moran’s I\n\ntmap_mode(\"plot\")\n\ntm_shape(lisa) + \n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8))\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n+ve values = positive autocorrelation\n-ve values = negative autocorrelation\n\n\n\n\n\n3.2.7 Visualising p-value of Moran’s I\n\ntmap_mode(\"plot\")\n\ntm_shape(lisa) + \n  tm_fill(\"p_ii_sim\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8))\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nUse p_ii_sim to be more accurate. You always want to use the one that has several trials.\n\n\n\n\n3.2.8 Visualising local Moran’s I\n\nlisa_sig <- lisa %>%\n  filter(p_ii_sim < 0.05)\n\ntmap_mode(\"plot\")\n\ntm_shape(lisa) +\n  tm_polygons() + \n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) + \n  tm_fill(\"mean\") +\n  tm_borders(alpha = 0.4)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nProf. Kam has mentioned that this way to do it is quite messy... We should use the hands-on method where we have both together (and not separate layers) and have a legend for insignificant counties as well."
  },
  {
    "objectID": "in-class_ex/in-class_ex07/in-class_ex07.html#hot-spot-and-cold-spot-area-analysis",
    "href": "in-class_ex/in-class_ex07/in-class_ex07.html#hot-spot-and-cold-spot-area-analysis",
    "title": "In-Class Exercise 7: Global and Local Measures of Spatial Association + Emerging Hot Spot Analysis (sfdep methods)",
    "section": "3.3 Hot Spot and Cold Spot Area Analysis",
    "text": "3.3 Hot Spot and Cold Spot Area Analysis\n\n3.3.1 Computing local Moran’s I\n\nHCSA <- cw_queen %>%\n  mutate(local_Gi = local_gstar_perm(\n    GDPPC, nb, wt, nsim = 99),\n    .before = 1) %>%\n  unnest(local_Gi)\n\nHCSA\n\nSimple feature collection with 88 features and 16 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 17\n   gi_star   e_gi     var_gi p_value   p_sim p_fol…¹ skewn…² kurto…³ nb    wt   \n     <dbl>  <dbl>      <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <nb>  <lis>\n 1  0.0416 0.0114 0.00000641  0.0493 9.61e-1    0.7     0.35   0.875 <int> <dbl>\n 2 -0.333  0.0106 0.00000384 -0.0941 9.25e-1    1       0.5    0.661 <int> <dbl>\n 3  0.281  0.0126 0.00000751 -0.151  8.80e-1    0.9     0.45   0.640 <int> <dbl>\n 4  0.411  0.0118 0.00000922  0.264  7.92e-1    0.6     0.3    0.853 <int> <dbl>\n 5  0.387  0.0115 0.00000956  0.339  7.34e-1    0.62    0.31   1.07  <int> <dbl>\n 6 -0.368  0.0118 0.00000591 -0.583  5.60e-1    0.72    0.36   0.594 <int> <dbl>\n 7  3.56   0.0151 0.00000731  2.61   9.01e-3    0.06    0.03   1.09  <int> <dbl>\n 8  2.52   0.0136 0.00000614  1.49   1.35e-1    0.2     0.1    1.12  <int> <dbl>\n 9  4.56   0.0144 0.00000584  3.53   4.17e-4    0.04    0.02   1.23  <int> <dbl>\n10  1.16   0.0104 0.00000370  1.82   6.86e-2    0.12    0.06   0.416 <int> <dbl>\n# … with 78 more rows, 7 more variables: NAME_2 <chr>, ID_3 <int>,\n#   NAME_3 <chr>, ENGTYPE_3 <chr>, County <chr>, GDPPC <dbl>,\n#   geometry <POLYGON [°]>, and abbreviated variable names ¹​p_folded_sim,\n#   ²​skewness, ³​kurtosis\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn general we use G* and not G. Furthermore, in this case, we use the local_gstar_perm() version.\n\n\n\n\n3.3.2 Visualising Gi*\n\ntmap_mode(\"plot\")\n\ntm_shape(HCSA) +\n  tm_fill(\"gi_star\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8))\n\n\n\n\n\n\n3.3.3 Visualising p-value of HCSA\n\ntmap_mode(\"plot\")\n\ntm_shape(HCSA) +\n  tm_fill(\"p_sim\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nMost of this are greater than 0.05. We should make some changes to only see the ones that have statistical significance."
  },
  {
    "objectID": "in-class_ex/in-class_ex08/in-class_ex08.html",
    "href": "in-class_ex/in-class_ex08/in-class_ex08.html",
    "title": "In-Class Exercise 8: Building Hedonic Price Model with GWR",
    "section": "",
    "text": "Show the code\n# do not load corrplot onto our memory using pacman\n\npacman::p_load(olsrr, ggupubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary)"
  },
  {
    "objectID": "in-class_ex/in-class_ex08/in-class_ex08.html#geospatial-data-wrangling",
    "href": "in-class_ex/in-class_ex08/in-class_ex08.html#geospatial-data-wrangling",
    "title": "In-Class Exercise 8: Building Hedonic Price Model with GWR",
    "section": "2 Geospatial Data Wrangling",
    "text": "2 Geospatial Data Wrangling\n\n2.1 Geospatial Data\n\n\nShow the code\n# import shapefile using st_read()\n# use st_transform() to update CRS information\n\nmpsz = st_read(dsn = \"data/geospatial\",\n               layer = \"MP14_SUBZONE_WEB_PL\") %>%\n  st_transform(crs = 3414)\n\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\guga-nesh\\IS415-GAA\\in-class_ex\\in-class_ex08\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n2.2 Aspatial Data\n\n\nShow the code\n# purpose of glimpse() is to know the data type\n\ncondo_resale = read_csv(\"data/aspatial/Condo_resale_2015.csv\")\nglimpse(condo_resale)\n\n\nRows: 1,436\nColumns: 23\n$ LATITUDE             <dbl> 1.287145, 1.328698, 1.313727, 1.308563, 1.321437,…\n$ LONGITUDE            <dbl> 103.7802, 103.8123, 103.7971, 103.8247, 103.9505,…\n$ POSTCODE             <dbl> 118635, 288420, 267833, 258380, 467169, 466472, 3…\n$ SELLING_PRICE        <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1320…\n$ AREA_SQM             <dbl> 309, 290, 248, 127, 145, 139, 218, 141, 165, 168,…\n$ AGE                  <dbl> 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22, 6,…\n$ PROX_CBD             <dbl> 7.941259, 6.609797, 6.898000, 4.038861, 11.783402…\n$ PROX_CHILDCARE       <dbl> 0.16597932, 0.28027246, 0.42922669, 0.39473543, 0…\n$ PROX_ELDERLYCARE     <dbl> 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.121…\n$ PROX_URA_GROWTH_AREA <dbl> 6.618741, 7.505109, 6.463887, 4.906512, 6.410632,…\n$ PROX_HAWKER_MARKET   <dbl> 1.76542207, 0.54507614, 0.37789301, 1.68259969, 0…\n$ PROX_KINDERGARTEN    <dbl> 0.05835552, 0.61592412, 0.14120309, 0.38200076, 0…\n$ PROX_MRT             <dbl> 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.528…\n$ PROX_PARK            <dbl> 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.116…\n$ PROX_PRIMARY_SCH     <dbl> 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.709…\n$ PROX_TOP_PRIMARY_SCH <dbl> 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.709…\n$ PROX_SHOPPING_MALL   <dbl> 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.307…\n$ PROX_SUPERMARKET     <dbl> 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.581…\n$ PROX_BUS_STOP        <dbl> 0.10336166, 0.28673408, 0.28504777, 0.29872340, 0…\n$ NO_Of_UNITS          <dbl> 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34, 3…\n$ FAMILY_FRIENDLY      <dbl> 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD             <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\n\n\nShow the code\n# for you to have a feel of whether your data have excessive 0s or missing data (normally ppl exclude them). Does it have a good spread?\n\nsummary(condo_resale)\n\n\n    LATITUDE       LONGITUDE        POSTCODE      SELLING_PRICE     \n Min.   :1.240   Min.   :103.7   Min.   : 18965   Min.   :  540000  \n 1st Qu.:1.309   1st Qu.:103.8   1st Qu.:259849   1st Qu.: 1100000  \n Median :1.328   Median :103.8   Median :469298   Median : 1383222  \n Mean   :1.334   Mean   :103.8   Mean   :440439   Mean   : 1751211  \n 3rd Qu.:1.357   3rd Qu.:103.9   3rd Qu.:589486   3rd Qu.: 1950000  \n Max.   :1.454   Max.   :104.0   Max.   :828833   Max.   :18000000  \n    AREA_SQM          AGE           PROX_CBD       PROX_CHILDCARE    \n Min.   : 34.0   Min.   : 0.00   Min.   : 0.3869   Min.   :0.004927  \n 1st Qu.:103.0   1st Qu.: 5.00   1st Qu.: 5.5574   1st Qu.:0.174481  \n Median :121.0   Median :11.00   Median : 9.3567   Median :0.258135  \n Mean   :136.5   Mean   :12.14   Mean   : 9.3254   Mean   :0.326313  \n 3rd Qu.:156.0   3rd Qu.:18.00   3rd Qu.:12.6661   3rd Qu.:0.368293  \n Max.   :619.0   Max.   :37.00   Max.   :19.1804   Max.   :3.465726  \n PROX_ELDERLYCARE  PROX_URA_GROWTH_AREA PROX_HAWKER_MARKET PROX_KINDERGARTEN \n Min.   :0.05451   Min.   :0.2145       Min.   :0.05182    Min.   :0.004927  \n 1st Qu.:0.61254   1st Qu.:3.1643       1st Qu.:0.55245    1st Qu.:0.276345  \n Median :0.94179   Median :4.6186       Median :0.90842    Median :0.413385  \n Mean   :1.05351   Mean   :4.5981       Mean   :1.27987    Mean   :0.458903  \n 3rd Qu.:1.35122   3rd Qu.:5.7550       3rd Qu.:1.68578    3rd Qu.:0.578474  \n Max.   :3.94916   Max.   :9.1554       Max.   :5.37435    Max.   :2.229045  \n    PROX_MRT         PROX_PARK       PROX_PRIMARY_SCH  PROX_TOP_PRIMARY_SCH\n Min.   :0.05278   Min.   :0.02906   Min.   :0.07711   Min.   :0.07711     \n 1st Qu.:0.34646   1st Qu.:0.26211   1st Qu.:0.44024   1st Qu.:1.34451     \n Median :0.57430   Median :0.39926   Median :0.63505   Median :1.88213     \n Mean   :0.67316   Mean   :0.49802   Mean   :0.75471   Mean   :2.27347     \n 3rd Qu.:0.84844   3rd Qu.:0.65592   3rd Qu.:0.95104   3rd Qu.:2.90954     \n Max.   :3.48037   Max.   :2.16105   Max.   :3.92899   Max.   :6.74819     \n PROX_SHOPPING_MALL PROX_SUPERMARKET PROX_BUS_STOP       NO_Of_UNITS    \n Min.   :0.0000     Min.   :0.0000   Min.   :0.001595   Min.   :  18.0  \n 1st Qu.:0.5258     1st Qu.:0.3695   1st Qu.:0.098356   1st Qu.: 188.8  \n Median :0.9357     Median :0.5687   Median :0.151710   Median : 360.0  \n Mean   :1.0455     Mean   :0.6141   Mean   :0.193974   Mean   : 409.2  \n 3rd Qu.:1.3994     3rd Qu.:0.7862   3rd Qu.:0.220466   3rd Qu.: 590.0  \n Max.   :3.4774     Max.   :2.2441   Max.   :2.476639   Max.   :1703.0  \n FAMILY_FRIENDLY     FREEHOLD      LEASEHOLD_99YR  \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.4868   Mean   :0.4227   Mean   :0.4882  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n\n\n\n\nShow the code\n# convert aspatial df into sf object\ncondo_resale.sf <- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs = 4326) %>%\n  st_transform(crs = 3414)\n\n\n\n\nShow the code\n# visualise variables to understand distribution, see outliers, whether categorical or not, etc.\n\nAREA_SQM <- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nAGE <- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CBD <- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CHILDCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_ELDERLYCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_URA_GROWTH_AREA <- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_HAWKER_MARKET <- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_KINDERGARTEN <- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_MRT <- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PARK <- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PRIMARY_SCH <- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_TOP_PRIMARY_SCH <- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nggpubr::ggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, \n          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,\n          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  \n          ncol = 3, nrow = 4)"
  },
  {
    "objectID": "in-class_ex/in-class_ex08/in-class_ex08.html#multiple-linear-regression-method",
    "href": "in-class_ex/in-class_ex08/in-class_ex08.html#multiple-linear-regression-method",
    "title": "In-Class Exercise 8: Building Hedonic Price Model with GWR",
    "section": "3 Multiple Linear Regression Method",
    "text": "3 Multiple Linear Regression Method\n\n3.1 Visualising the relationships of the independent variables\n\n\nShow the code\n# using corrplot to visualise correlations\ncorrplot::corrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = \"AOE\",\n         tl.pos = \"td\", tl.cex = 0.5, method = \"number\", type = \"upper\")\n\n\n\n\n\n\n\n3.2 Building Hedonic Pricing Model with MLR method\n\n\nShow the code\n# using lm() to calibrate MLR model\n# save the entire model into an lm object -> you can get your residuals, intercepts, etc. all from here.\n\ncondo.mlr <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + \n                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                data=condo_resale.sf)\n\nsummary(condo.mlr)\n\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(>|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  < 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  < 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  < 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  < 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "in-class_ex/in-class_ex08/in-class_ex08.html#preparing-reports",
    "href": "in-class_ex/in-class_ex08/in-class_ex08.html#preparing-reports",
    "title": "In-Class Exercise 8: Building Hedonic Price Model with GWR",
    "section": "4 Preparing Reports",
    "text": "4 Preparing Reports\n\n4.1 Method 1: Using OLSRR\n\n\nShow the code\n# look at Model Summary to see R, R^2\n# can see goodness of fit test under ANOVA\n\ncondo.mlr1 <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                   PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + \n                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL    + PROX_BUS_STOP + \n                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,\n                 data=condo_resale.sf)\nols_regress(condo.mlr1)\n\n\n                             Model Summary                               \n------------------------------------------------------------------------\nR                       0.807       RMSE                     755957.289 \nR-Squared               0.651       Coef. Var                    43.168 \nAdj. R-Squared          0.647       MSE                571471422208.591 \nPred R-Squared          0.638       MAE                      414819.628 \n------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.591                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n-----------------------------------------------------------------------------------------------------------------\n\n\n\n\n4.2 Method 2: gtsummary() method\n\n\nShow the code\n# a more nicer and tidy method - well formatted regression report\n# things to look at for our project\n# we can even append other report tables as shown below\ntbl_regression(condo.mlr1, \n               intercept = TRUE) %>% \n  add_glance_source_note(\n    label = list(sigma ~ \"\\U03C3\"),\n    include = c(r.squared, adj.r.squared, \n                AIC, statistic,\n                p.value, sigma))\n\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n<0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n<0.001\n    AGE\n-24,688\n-30,092, -19,284\n<0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n<0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n<0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n<0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n<0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n<0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n<0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n<0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n<0.001\n  \n  \n    \n      R² = 0.651; Adjusted R² = 0.647; AIC = 42,967; Statistic = 189; p-value = <0.001; σ = 755,957\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\n\n\nShow the code\n# to perform spatial autocorrelation test we need to convert sf into SpatialPointsDataFrame\n# take only the residuals\n\ncondo_resale.res.sf <- cbind(condo_resale.sf, \n                        condo.mlr1$residuals) %>%\nrename(`MLR_RES` = `condo.mlr1.residuals`)\n\ncondo_resale.sp <- as_Spatial(condo_resale.res.sf)\ncondo_resale.sp\n\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1436 \nextent      : 14940.85, 43352.45, 24765.67, 48382.81  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 22\nnames       : POSTCODE, SELLING_PRICE, AREA_SQM, AGE,    PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN,    PROX_MRT,   PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH, PROX_SHOPPING_MALL, ... \nmin values  :    18965,        540000,       34,   0, 0.386916393,    0.004927023,      0.054508623,          0.214539508,        0.051817113,       0.004927023, 0.052779424, 0.029064164,      0.077106132,          0.077106132,                  0, ... \nmax values  :   828833,       1.8e+07,      619,  37, 19.18042832,     3.46572633,      3.949157205,           9.15540001,        5.374348075,       2.229045366,  3.48037319,  2.16104919,      3.928989144,          6.748192062,        3.477433767, ..."
  },
  {
    "objectID": "in-class_ex/in-class_ex08/in-class_ex08.html#skipped-tests-for-multicolinearity-non-linearity-normality-assumption-spatial-autocorrelation",
    "href": "in-class_ex/in-class_ex08/in-class_ex08.html#skipped-tests-for-multicolinearity-non-linearity-normality-assumption-spatial-autocorrelation",
    "title": "In-Class Exercise 8: Building Hedonic Price Model with GWR",
    "section": "5 […] Skipped tests for multicolinearity, non-linearity, normality assumption, spatial autocorrelation",
    "text": "5 […] Skipped tests for multicolinearity, non-linearity, normality assumption, spatial autocorrelation"
  },
  {
    "objectID": "in-class_ex/in-class_ex08/in-class_ex08.html#building-hedonic-pricing-models-using-gwmodel",
    "href": "in-class_ex/in-class_ex08/in-class_ex08.html#building-hedonic-pricing-models-using-gwmodel",
    "title": "In-Class Exercise 8: Building Hedonic Price Model with GWR",
    "section": "6 Building Hedonic Pricing Models using GWmodel",
    "text": "6 Building Hedonic Pricing Models using GWmodel\n\n6.1 Computing fixed bandwidth\n\n\nShow the code\n# GWModel package used to determine the optimal fixed bandwidth - it also provides a variety of geographically weighted multi linear calibration methods\n# define stopping rule using approach argument (CV or AIC)\n# iterate thru and always give you the smallest bandwidth\n\nbw.fixed <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                     PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                     PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                     PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                     FAMILY_FRIENDLY + FREEHOLD, \n                   data=condo_resale.sp, \n                   approach=\"CV\", \n                   kernel=\"gaussian\", \n                   adaptive=FALSE, \n                   longlat=FALSE)\n\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.378294e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3408 CV score: 4.721292e+14 \nFixed bandwidth: 971.3403 CV score: 4.721292e+14 \nFixed bandwidth: 971.3406 CV score: 4.721292e+14 \nFixed bandwidth: 971.3404 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \n\n\n\n\n6.2 Computing Adaptive Bandwidth\n\n\nShow the code\n# similar to the fixed bandwidth computation with a few differences\nbw.adaptive <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + \n                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + \n                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + \n                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                      data=condo_resale.sp, \n                      approach=\"CV\", \n                      kernel=\"gaussian\", \n                      adaptive=TRUE, \n                      longlat=FALSE)\n\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14"
  },
  {
    "objectID": "in-class_ex/in-class_ex08/in-class_ex08.html#lesson-introduction",
    "href": "in-class_ex/in-class_ex08/in-class_ex08.html#lesson-introduction",
    "title": "In-Class Exercise 8: Building Hedonic Price Model with GWR",
    "section": "7 Lesson Introduction",
    "text": "7 Lesson Introduction\nFocus of lesson (Explanatory Models):\n\ntry to calibrate a model that allows us to explain the response/dependent variable\nidentify explanatory variables that best explain dependent variables\nneed to ensure statistical regress is important\n\nGoodness of fit: f-test statistic = where we want p-value < 0.05 (enough confidence to reject the H0 - where this model is better than average). Always describe your goodness of fit statistic first before talking about p-value. Take note of explanation for R^2 and all.\nIndividual parameter testing: t-test\nExistence of multicollinearity:\n\n\n\n\n\n\n\n\nNote\n\n\n\nExplanatory Models help us to explain the factors that affect a certain phenomenon (i.e., response/dependent variable - e.g., vaccination rate)\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor Predictive Models, we tend to focus on the accuracy of the models."
  },
  {
    "objectID": "in-class_ex/in-class_ex08/in-class_ex08.html#take-home-03-advice",
    "href": "in-class_ex/in-class_ex08/in-class_ex08.html#take-home-03-advice",
    "title": "In-Class Exercise 8: Building Hedonic Price Model with GWR",
    "section": "8 Take-Home 03 Advice",
    "text": "8 Take-Home 03 Advice\nGet Domain Knowledge\nUnderstand the ground conditions (what is happening in the study area) so you know which factors to choose. We need to choose variables that are relevant to the issue.\nCheck statistical significance\nExclude those that don’t meet and then only we re-calibrate the model and interpret it again. When you work with statistical methods, got assumptions to make into consideration.. If variables are correlated, please remove.\nCheck for assumptions\n(if you see the distribution, if normal dist also cannot)\nSpatial Non-stationary\nUse Moran’s I for regression residuals"
  },
  {
    "objectID": "in-class_ex/in-class_ex08/in-class_ex08.html#regression-analysis",
    "href": "in-class_ex/in-class_ex08/in-class_ex08.html#regression-analysis",
    "title": "In-Class Exercise 8: Building Hedonic Price Model with GWR",
    "section": "9 Regression Analysis",
    "text": "9 Regression Analysis\nOnce you have come up with your dependent variables, we can look at the statistical methods:\n\nStatistical Learning\n\nRegression Modeling - there are many types (e.g., Linear Regression Model)\n\nYour choice is based on the dependent variables (for instance, LRM is only useful if your dependent variable is continuous and approx. normally distributed). Additionally, the relationship should be linear –> we want to find the best fit line by minimising residuals (aka Least Square Method/OLS)\n\n\nIf slope (beta 0) is bigger (i.e., more steep) it has a relatively larger influence. If positive (directly related), else (inversely related).\n\nMultiple Linear Regression need continuous response variable and/or categorical explanatory variable. If you have many variables (to look at several plains)\n\n\n\nMachine Learning\n\n\n\n\n\n\n\nNote\n\n\n\nGWR: not just one model, you should expose as many models as you can so they can use it for different use case."
  },
  {
    "objectID": "in-class_ex/in-class_ex08/in-class_ex08.html#gwr",
    "href": "in-class_ex/in-class_ex08/in-class_ex08.html#gwr",
    "title": "In-Class Exercise 8: Building Hedonic Price Model with GWR",
    "section": "10 GWR",
    "text": "10 GWR\nWe need to provide x and y coordinate (depends on the spatial unit you’re working on).\nOnly use distance weight to calibrate. Don’t use proximity. If you’re using adaptive (it means distance changes, but number of data points fixed). What’s the cutoff for us to determine the best bandwidth and weights? -> use mathematical methods (use least AIC or least cross-validation)\nOutput:\n\noverall model performance\nlocalised result (localised R^2 - tells us which part of the study area you can better estimate the outcome) -> need visualise this"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "Hi everyone! Welcome to my IS415: Geospatial Analytics and Applications website. You can find all my course work here :)"
  },
  {
    "objectID": "proj-tests/proj-tests_01/proj-tests_01.html",
    "href": "proj-tests/proj-tests_01/proj-tests_01.html",
    "title": "proj-tests_01",
    "section": "",
    "text": "pacman::p_load(sf, sfdep, tidyverse, tmap, raster)\n\n\nstr_name<-'data/india/202206_Global_Pf_Parasite_Rate_IND_2020.tiff' \nimported_raster=raster(str_name)\n\nimported_raster\n\nclass      : RasterLayer \ndimensions : 690, 702, 484380  (nrow, ncol, ncell)\nresolution : 0.04166667, 0.04165069  (x, y)\nextent     : 68.16668, 97.41668, 6.767941, 35.50692  (xmin, xmax, ymin, ymax)\ncrs        : +proj=longlat +datum=WGS84 +no_defs \nsource     : 202206_Global_Pf_Parasite_Rate_IND_2020.tiff \nnames      : X202206_Global_Pf_Parasite_Rate_IND_2020 \n\n\n\nplot(imported_raster)\n\n\n\n\n\nindia <- st_read(dsn=\"data/india\",\n                 layer=\"geoBoundaries-IND-ADM2_simplified\")\n\nReading layer `geoBoundaries-IND-ADM2_simplified' from data source \n  `C:\\guga-nesh\\IS415-GAA\\proj-tests\\proj-tests_01\\data\\india' \n  using driver `ESRI Shapefile'\nSimple feature collection with 735 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 68.17939 ymin: 6.75649 xmax: 97.39744 ymax: 37.0773\nGeodetic CRS:  WGS 84\n\nindia\n\nSimple feature collection with 735 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 68.17939 ymin: 6.75649 xmax: 97.39744 ymax: 37.0773\nGeodetic CRS:  WGS 84\nFirst 10 features:\n   OBJECTID   shapeName Level Shape_Leng Shape_Area                    shapeID\n1         1  Ashoknagar  ADM2   3.925451  0.4216639 IND-ADM2-76128533B24212364\n2         2      Raisen  ADM2   7.526803  0.7487853 IND-ADM2-76128533B65758206\n3         3  Chhindwara  ADM2   7.724320  1.0331431 IND-ADM2-76128533B77651862\n4         4       Betul  ADM2   6.736091  0.8752108 IND-ADM2-76128533B14961718\n5         5 Hoshangabad  ADM2   5.467521  0.5869150 IND-ADM2-76128533B94465219\n6         6      Sehore  ADM2   8.302665  0.5773881 IND-ADM2-76128533B31086418\n7         7    Jabalpur  ADM2   5.572500  0.4490531 IND-ADM2-76128533B49275069\n8         8 Narsimhapur  ADM2   5.409966  0.4516033 IND-ADM2-76128533B87358694\n9         9       Panna  ADM2   7.224317  0.6265862 IND-ADM2-76128533B55384561\n10       10      Ujjain  ADM2   6.892465  0.5428983 IND-ADM2-76128533B34527011\n   shapeGroup shapeType                       geometry\n1         IND      ADM2 MULTIPOLYGON (((78.17491 24...\n2         IND      ADM2 MULTIPOLYGON (((77.38167 23...\n3         IND      ADM2 MULTIPOLYGON (((79.23988 22...\n4         IND      ADM2 MULTIPOLYGON (((78.27229 22...\n5         IND      ADM2 MULTIPOLYGON (((78.03027 22...\n6         IND      ADM2 MULTIPOLYGON (((77.38167 23...\n7         IND      ADM2 MULTIPOLYGON (((79.97956 23...\n8         IND      ADM2 MULTIPOLYGON (((78.44653 22...\n9         IND      ADM2 MULTIPOLYGON (((80.35654 23...\n10        IND      ADM2 MULTIPOLYGON (((75.89931 22...\n\n\n\nplot(india)\n\n\n\n\n\nindonesia <- st_read(dsn=\"data/idn_adm_bps_20200401_shp\",\n                 layer=\"idn_admbnda_adm4_bps_20200401\")\n\nReading layer `idn_admbnda_adm4_bps_20200401' from data source \n  `C:\\guga-nesh\\IS415-GAA\\proj-tests\\proj-tests_01\\data\\idn_adm_bps_20200401_shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 81912 features and 18 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 95.01079 ymin: -11.00762 xmax: 141.0194 ymax: 6.07693\nGeodetic CRS:  WGS 84\n\nindonesia\n\nSimple feature collection with 81912 features and 18 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 95.01079 ymin: -11.00762 xmax: 141.0194 ymax: 6.07693\nGeodetic CRS:  WGS 84\nFirst 10 features:\n   Shape_Leng   Shape_Area ADM4_EN   ADM4_PCODE ADM4_REF ADM4ALT1EN ADM4ALT2EN\n1  0.09638736 1.692560e-04  1 Ilir ID1671060006     <NA>       <NA>       <NA>\n2  0.01861086 1.697974e-05   1 Ulu ID1671020008     <NA>       <NA>       <NA>\n3  0.01872895 1.269222e-05 10 Ilir ID1671062001     <NA>       <NA>       <NA>\n4  0.01486820 6.250206e-06 11 Ilir ID1671062002     <NA>       <NA>       <NA>\n5  0.02827325 1.849024e-05  11 Ulu ID1671030014     <NA>       <NA>       <NA>\n6  0.01931659 1.520428e-05  12 Ulu ID1671030013     <NA>       <NA>       <NA>\n7  0.01953874 1.462618e-05 13 Ilir ID1671050003     <NA>       <NA>       <NA>\n8  0.04302044 6.127683e-05  13 Ulu ID1671030012     <NA>       <NA>       <NA>\n9  0.01253364 6.675545e-06 14 Ilir ID1671050004     <NA>       <NA>       <NA>\n10 0.04278841 8.140646e-05  14 Ulu ID1671030011     <NA>       <NA>       <NA>\n           ADM3_EN ADM3_PCODE        ADM2_EN ADM2_PCODE          ADM1_EN\n1    Ilir Timur II  ID1671060 Kota Palembang     ID1671 Sumatera Selatan\n2   Seberang Ulu I  ID1671020 Kota Palembang     ID1671 Sumatera Selatan\n3   Ilir Timur III  ID1671062 Kota Palembang     ID1671 Sumatera Selatan\n4   Ilir Timur III  ID1671062 Kota Palembang     ID1671 Sumatera Selatan\n5  Seberang Ulu II  ID1671030 Kota Palembang     ID1671 Sumatera Selatan\n6  Seberang Ulu II  ID1671030 Kota Palembang     ID1671 Sumatera Selatan\n7     Ilir Timur I  ID1671050 Kota Palembang     ID1671 Sumatera Selatan\n8  Seberang Ulu II  ID1671030 Kota Palembang     ID1671 Sumatera Selatan\n9     Ilir Timur I  ID1671050 Kota Palembang     ID1671 Sumatera Selatan\n10 Seberang Ulu II  ID1671030 Kota Palembang     ID1671 Sumatera Selatan\n   ADM1_PCODE   ADM0_EN ADM0_PCODE       date    validOn validTo\n1        ID16 Indonesia         ID 2019-12-20 2020-04-01    <NA>\n2        ID16 Indonesia         ID 2019-12-20 2020-04-01    <NA>\n3        ID16 Indonesia         ID 2019-12-20 2020-04-01    <NA>\n4        ID16 Indonesia         ID 2019-12-20 2020-04-01    <NA>\n5        ID16 Indonesia         ID 2019-12-20 2020-04-01    <NA>\n6        ID16 Indonesia         ID 2019-12-20 2020-04-01    <NA>\n7        ID16 Indonesia         ID 2019-12-20 2020-04-01    <NA>\n8        ID16 Indonesia         ID 2019-12-20 2020-04-01    <NA>\n9        ID16 Indonesia         ID 2019-12-20 2020-04-01    <NA>\n10       ID16 Indonesia         ID 2019-12-20 2020-04-01    <NA>\n                         geometry\n1  MULTIPOLYGON (((104.8225 -2...\n2  MULTIPOLYGON (((104.7552 -3...\n3  MULTIPOLYGON (((104.7708 -2...\n4  MULTIPOLYGON (((104.7708 -2...\n5  MULTIPOLYGON (((104.7732 -2...\n6  MULTIPOLYGON (((104.7697 -2...\n7  MULTIPOLYGON (((104.7662 -2...\n8  MULTIPOLYGON (((104.7741 -2...\n9  MULTIPOLYGON (((104.7656 -2...\n10 MULTIPOLYGON (((104.781 -2...."
  },
  {
    "objectID": "take-home_ex/take-home_ex01/take-home_ex01.html",
    "href": "take-home_ex/take-home_ex01/take-home_ex01.html",
    "title": "Take Home Exercise 01",
    "section": "",
    "text": "Access to clean water is a crucial issue in many developing countries, including Nigeria. Access to functional water points can improve quality of life and support economic development, while non-functional water points can lead to health problems and reduce access to clean water.\n\n\n\nOur goal is to apply appropriate spatial point patterns analysis methods to discover the distribution of functional and non-functional water points and their co-locations (if any) in Osun State, Nigeria. Our findings could help improve access to clean water in Osun State through the constitution of new water points and the rehabilitation of existing ones.\n\n\n\nHere are the three analytic tasks we have to perform to derive valuable insights from our data:\n\nExploratory Spatial Data Analysis (ESDA)\nSecond-order Spatial Point Patterns Analysis\nSpatial Correlation Analysis"
  },
  {
    "objectID": "take-home_ex/take-home_ex01/take-home_ex01.html#install-and-load-relevant-r-packages",
    "href": "take-home_ex/take-home_ex01/take-home_ex01.html#install-and-load-relevant-r-packages",
    "title": "Take Home Exercise 01",
    "section": "2.1 Install and load relevant R packages",
    "text": "2.1 Install and load relevant R packages\n\npacman::p_load(tmap, sf, tidyverse, maptools, raster, spatstat, funModeling, sfdep)"
  },
  {
    "objectID": "take-home_ex/take-home_ex01/take-home_ex01.html#importing-data",
    "href": "take-home_ex/take-home_ex01/take-home_ex01.html#importing-data",
    "title": "Take Home Exercise 01",
    "section": "2.2 Importing data",
    "text": "2.2 Importing data\n\n2.2.1 Geospatial Data\nSince the study will focus on Osun State, Nigeria, we have gotten the state boundary GIS data of Nigeria from The Humanitarian Data Exchange portal. We will be using the Administrative Level 2 (ADM2) data as it denotes the local government areas. In fact, ADM2 is used to divide the country into its 36 states (including Osun) and using this data allows for a more accurate representation of the distribution of functional and non-functional water points in each state instead of the aggregated data for the entire country. This level of detail is important for planning and decision making at the state level.\n\nNGA <- st_read(dsn = \"data/geospatial\",\n                          layer = \"nga_admbnda_adm2_osgof_20190417\")\n\nReading layer `nga_admbnda_adm2_osgof_20190417' from data source \n  `C:\\guga-nesh\\IS415-GAA\\take-home_ex\\take-home_ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n\n\n\n2.2.2 Aspatial Data\nFor the purpose of this assignment, we have been instructed to use data from the WPdx Global Data Repositories.\n\nwp <- read_csv(\"data/aspatial/WPDX.csv\")"
  },
  {
    "objectID": "take-home_ex/take-home_ex01/take-home_ex01.html#data-wrangling",
    "href": "take-home_ex/take-home_ex01/take-home_ex01.html#data-wrangling",
    "title": "Take Home Exercise 01",
    "section": "2.3 Data Wrangling",
    "text": "2.3 Data Wrangling\n\n2.3.1 Pre-processing NGA data\nFrom the results shown above, we can see that NGAis an sf dataframe with the MULTIPOLYGON data type. However, it is not using the Projected Coordinate System of Nigeria where crs = 26392. In addition, it includes the whole of Nigeria when we only want Osun. So let’s change this.\n\nNGA_26392 = st_transform(NGA, 26392)\nosun = subset(NGA_26392, ADM1_EN == \"Osun\")\n\nosun\n\nSimple feature collection with 30 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 176503.2 ymin: 331434.7 xmax: 291043.8 ymax: 454520.1\nProjected CRS: Minna / Nigeria Mid Belt\nFirst 10 features:\n    Shape_Leng  Shape_Area        ADM2_EN ADM2_PCODE       ADM2_REF ADM2ALT1EN\n28   1.7951405 0.062436080       Aiyedade   NG030001       Aiyedade       <NA>\n29   0.7101503 0.024818478       Aiyedire   NG030002       Aiyedire       <NA>\n70   0.9199564 0.038002894 Atakumosa East   NG030003 Atakumosa East       <NA>\n71   0.8502782 0.030445804 Atakumosa West   NG030004 Atakumosa West       <NA>\n120  0.5212768 0.012213340     Boluwaduro   NG030005     Boluwaduro       <NA>\n124  0.6088930 0.011827501         Boripe   NG030006         Boripe       <NA>\n172  0.4714403 0.008343638      Ede North   NG030007      Ede North       <NA>\n173  0.5660235 0.017623677      Ede South   NG030008      Ede South       <NA>\n179  0.8273123 0.022026327       Egbedore   NG030009       Egbedore       <NA>\n182  1.1304849 0.029791275         Ejigbo   NG030010         Ejigbo       <NA>\n    ADM2ALT2EN ADM1_EN ADM1_PCODE ADM0_EN ADM0_PCODE       date    validOn\n28        <NA>    Osun      NG030 Nigeria         NG 2016-11-29 2019-04-17\n29        <NA>    Osun      NG030 Nigeria         NG 2016-11-29 2019-04-17\n70        <NA>    Osun      NG030 Nigeria         NG 2016-11-29 2019-04-17\n71        <NA>    Osun      NG030 Nigeria         NG 2016-11-29 2019-04-17\n120       <NA>    Osun      NG030 Nigeria         NG 2016-11-29 2019-04-17\n124       <NA>    Osun      NG030 Nigeria         NG 2016-11-29 2019-04-17\n172       <NA>    Osun      NG030 Nigeria         NG 2016-11-29 2019-04-17\n173       <NA>    Osun      NG030 Nigeria         NG 2016-11-29 2019-04-17\n179       <NA>    Osun      NG030 Nigeria         NG 2016-11-29 2019-04-17\n182       <NA>    Osun      NG030 Nigeria         NG 2016-11-29 2019-04-17\n    validTo        SD_EN SD_PCODE                       geometry\n28     <NA>    Osun West  NG03003 MULTIPOLYGON (((213526.6 34...\n29     <NA>    Osun West  NG03003 MULTIPOLYGON (((212542.6 40...\n70     <NA>    Osun East  NG03002 MULTIPOLYGON (((265746.8 37...\n71     <NA>    Osun East  NG03002 MULTIPOLYGON (((248871.4 40...\n120    <NA> Osun Central  NG03001 MULTIPOLYGON (((266092.2 43...\n124    <NA> Osun Central  NG03001 MULTIPOLYGON (((255072.5 43...\n172    <NA>    Osun West  NG03003 MULTIPOLYGON (((236386.9 41...\n173    <NA>    Osun West  NG03003 MULTIPOLYGON (((236386.9 41...\n179    <NA>    Osun West  NG03003 MULTIPOLYGON (((220756 4317...\n182    <NA>    Osun West  NG03003 MULTIPOLYGON (((214422.1 42...\n\n\nosun has a lot of unnecessary variables that are not needed and it can be quite confusing. Since we will not be using it, let us remove it. This code chunk was referenced from our In-Class Exercise 2, Section 4.1.\n\nosun <- osun %>%\n  dplyr::select (c(3:4, 8:9))\n\n\n\n2.3.2 Pre-processing Water points data\nThe wp data is a tibble dataframe as seen in the picture below. It also contains data of other countries (please refer under column #clean_country_name).\n\nHence, we will need to convert the tibble dataframe into an sf object and filter out all the unneeded countries and states from the data set.\n\nwp_osun = filter(wp, `#clean_country_name` == \"Nigeria\")%>%\n  filter(`#clean_adm1` == \"Osun\")\n\nLet’s convert the tibble dataframe into a sf object. We need to start by converting the well-known text representation geometry (wkt) into an sfc field.\n\nwp_osun$geometry = st_as_sfc(wp_osun$`New Georeferenced Column`)\n\nwp_osun\n\n# A tibble: 5,745 × 75\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n    <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 225950 Federal Minis…    7.43    4.26 05/05/… Yes     Boreho… Well    Hand P…\n 2 225524 Federal Minis…    7.78    4.56 04/22/… Yes     Protec… Well    Hand P…\n 3 197014 Federal Minis…    7.49    4.53 04/30/… Yes     Boreho… Well    Mechan…\n 4 225173 Federal Minis…    7.93    4.73 05/02/… Yes     Boreho… Well    Hand P…\n 5 225843 Federal Minis…    7.74    4.44 05/08/… Yes     Boreho… Well    Hand P…\n 6 235508 Federal Minis…    7.15    4.64 04/27/… Yes     Protec… Well    Hand P…\n 7 197708 Federal Minis…    7.87    4.72 05/13/… Yes     Boreho… Well    Mechan…\n 8 195041 Federal Minis…    7.73    4.45 06/17/… Yes     Protec… Spring  <NA>   \n 9 225222 Federal Minis…    7.81    4.15 05/14/… Yes     Protec… Spring  Mechan…\n10 460770 GRID3             7.4     4.33 06/13/… Unknown Boreho… Well    <NA>   \n# … with 5,735 more rows, 66 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n\n\nThen, we need to transform the tibble data frame into an sf object using Nigeria’s Projected Coordinate System.\n\nwp_sf = st_sf(wp_osun, crs=4326)%>%\n  st_transform(crs=26392)\n\nwp_sf\n\nSimple feature collection with 5745 features and 74 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 177285.9 ymin: 340054.1 xmax: 291287.1 ymax: 450859.7\nProjected CRS: Minna / Nigeria Mid Belt\n# A tibble: 5,745 × 75\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n *  <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 225950 Federal Minis…    7.43    4.26 05/05/… Yes     Boreho… Well    Hand P…\n 2 225524 Federal Minis…    7.78    4.56 04/22/… Yes     Protec… Well    Hand P…\n 3 197014 Federal Minis…    7.49    4.53 04/30/… Yes     Boreho… Well    Mechan…\n 4 225173 Federal Minis…    7.93    4.73 05/02/… Yes     Boreho… Well    Hand P…\n 5 225843 Federal Minis…    7.74    4.44 05/08/… Yes     Boreho… Well    Hand P…\n 6 235508 Federal Minis…    7.15    4.64 04/27/… Yes     Protec… Well    Hand P…\n 7 197708 Federal Minis…    7.87    4.72 05/13/… Yes     Boreho… Well    Mechan…\n 8 195041 Federal Minis…    7.73    4.45 06/17/… Yes     Protec… Spring  <NA>   \n 9 225222 Federal Minis…    7.81    4.15 05/14/… Yes     Protec… Spring  Mechan…\n10 460770 GRID3             7.4     4.33 06/13/… Unknown Boreho… Well    <NA>   \n# … with 5,735 more rows, 66 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n\n\nThe code output above shows us that it has been converted into an sf object with the POINT geometry type and it is also using the correct crs.\n\n\n2.3.3 Extracting specific types of water points from data\nTo analyse the functional and non-functional water points, we first need to identify which points are functional and which are non-functional.\n\nA quick glance at the wp_sf variable (as shown above) tells us that we need to look at the #status_clean column to identify which points are functional and which aren’t.\n\nfreq(data = wp_sf,\n     input = '#status_clean')\n\n\n\n\n              #status_clean frequency percentage cumulative_perc\n1                Functional      2406      41.88           41.88\n2            Non-Functional      2086      36.31           78.19\n3                      <NA>       748      13.02           91.21\n4  Functional, needs repair       259       4.51           95.72\n5       Non-Functional, dry       159       2.77           98.49\n6    Functional, not in use        64       1.11           99.60\n7  Abandoned/Decommissioned        15       0.26           99.86\n8 Functional but not in use         8       0.14          100.00\n\n\nFrom the plot above, we can see that there are a total of 10 different statuses. In fact, 10.42% of the data is also “NA”. Hence, for easier analyses later on we group the statuses into Functional, Non-Functional, and those that are “NA”.\n\nwp_sf <- wp_sf %>%\n  mutate(`#status_clean` = replace_na(\n    `#status_clean`, \"unknown\"\n  ))\n\nwp_functional_sf <- wp_sf %>%\n  filter(`#status_clean` %in%\n           c(\"Functional\",\n             \"Functional, needs repair\",\n             \"Functional, not in use\",\n             \"Functional but not in use\",\n             \"Functional but needs repair\"))\n\nwp_nonfunctional_sf <- wp_sf %>%\n  filter(`#status_clean` %in%\n           c(\"Non-Functional\",\n             \"Non-Functional, dry\",\n             \"Abandoned/Decommissioned\",\n             \"Non-Functional due to dry season\"))\n\nwp_unknown_sf <- wp_sf %>%\n  filter (`#status_clean` %in% 'unknown')"
  },
  {
    "objectID": "take-home_ex/take-home_ex01/take-home_ex01.html#visualizing-the-data",
    "href": "take-home_ex/take-home_ex01/take-home_ex01.html#visualizing-the-data",
    "title": "Take Home Exercise 01",
    "section": "3.1 Visualizing the data",
    "text": "3.1 Visualizing the data\nBefore we can start analyzing the data proper, let’s visualize what we have so far.\n\n3.1.1 Distribution of water points\n\ndist_viz <- osun %>%\n  mutate(`functional_wp` = lengths(st_intersects(osun, wp_functional_sf))) %>%\n  mutate(`nonfunctional_wp` = lengths(st_intersects(osun, wp_nonfunctional_sf)))\n\n\nf_viz <- ggplot(data = dist_viz,\n       aes(x = functional_wp)) + \n  geom_histogram(bins=15,\n                 color=\"black\",\n                 fill=\"light blue\") +\n  geom_vline(aes(xintercept=mean(\n    functional_wp, na.rm=T)),\n             color=\"red\", \n             linetype=\"dashed\", \n             size=0.8) +\n  ggtitle(\"Distribution of functional water points by LGA\") +\n  xlab(\"No. of water points\") +\n  ylab(\"No. of\\nLGAs\") +\n  theme(axis.title.y=element_text(angle = 0))\n\nnf_viz <- ggplot(data = dist_viz,\n       aes(x = nonfunctional_wp)) + \n  geom_histogram(bins=15,\n                 color=\"black\",\n                 fill=\"light blue\") +\n  geom_vline(aes(xintercept=mean(\n    nonfunctional_wp, na.rm=T)),\n             color=\"red\", \n             linetype=\"dashed\", \n             size=0.8) +\n  ggtitle(\"Distribution of non-functional water points by LGA\") +\n  xlab(\"No. of water points\") +\n  ylab(\"No. of\\nLGAs\") +\n  theme(axis.title.y=element_text(angle = 0))\n\nplot(f_viz, main = \"Distribution of Functional Water points by LGA\")\n\n\n\nplot(nf_viz, main = \"Distribution of Non-functional Water points by LGA\")\n\n\n\n\nFrom the results above, we can see that the water points are not evenly distributed and the data is extremely skewed. Let’s view this on a map."
  },
  {
    "objectID": "take-home_ex/take-home_ex01/take-home_ex01.html#visualizing-water-points-on-the-map-of-osun",
    "href": "take-home_ex/take-home_ex01/take-home_ex01.html#visualizing-water-points-on-the-map-of-osun",
    "title": "Take Home Exercise 01",
    "section": "3.2 Visualizing water points on the map of Osun",
    "text": "3.2 Visualizing water points on the map of Osun\nLet’s try a more interactive view using tmaps. Here I am plotting the functional and non-functional water points in Osun State, Nigeria.\n\ntmap_mode(\"view\")\ntm_shape(osun) + \n  tm_polygons() + \ntm_shape(wp_functional_sf) + \n  tm_dots(col= \"green\") +\ntm_shape(wp_nonfunctional_sf) +\n  tm_dots (col = \"red\")\n\n\n\n\n\n\nAt a glance it seems like the water points (both functional and non-functional) are evenly spread out across the entire state. However, a closer look at the map tells us that there are small clusters of both types of water points throughout the state and there are more non-functional water points than functional water points in the Osun State of Nigeria."
  },
  {
    "objectID": "take-home_ex/take-home_ex01/take-home_ex01.html#converting-sf-dataframe-into-sps-spatial-class",
    "href": "take-home_ex/take-home_ex01/take-home_ex01.html#converting-sf-dataframe-into-sps-spatial-class",
    "title": "Take Home Exercise 01",
    "section": "3.3 Converting sf dataframe into sp’s Spatial* class",
    "text": "3.3 Converting sf dataframe into sp’s Spatial* class\nIn order to use the spatstat library which requires analytical data in ppp object form, we need to convert the data into the spatial class.\n\nosun_sp <- as_Spatial(osun)\n\nwp_functional_sp <- as_Spatial(wp_functional_sf)\n\nwp_nonfunctional_sp <- as_Spatial(wp_nonfunctional_sf)\n\nLet’s display these three variables:\n\nprint(osun_sp) # SpatialPolygons DataFrame\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 30 \nextent      : 176503.2, 291043.8, 331434.7, 454520.1  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs \nvariables   : 4\nnames       :  ADM2_EN, ADM2_PCODE, ADM1_EN, ADM1_PCODE \nmin values  : Aiyedade,   NG030001,    Osun,      NG030 \nmax values  :   Osogbo,   NG030030,    Osun,      NG030 \n\n\n\nprint(wp_functional_sp) #SpatialPoints DataFrame\n\nclass       : SpatialPointsDataFrame \nfeatures    : 2737 \nextent      : 177285.9, 290751, 343128.1, 450859.7  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs \nvariables   : 74\nnames       : row_id,                                     X.source, X.lat_deg, X.lon_deg,          X.report_date, X.status_id,    X.water_source_clean, X.water_source_category,      X.water_tech_clean, X.water_tech_category, X.facility_type, X.clean_country_name, X.clean_adm1, X.clean_adm2, X.clean_adm3, ... \nmin values  : 154218, Federal Ministry of Water Resources, Nigeria, 7.0890301, 4.0320038, 01/01/2010 12:00:00 AM,     Unknown,                Borehole,                  Spring,               Hand Pump,             Hand Pump,        Improved,              Nigeria,         Osun,     Aiyedade,           NA, ... \nmax values  : 683844,                                        GRID3, 8.0618983, 5.0550034, 09/16/2015 12:00:00 AM,         Yes, Undefined Hand Dug Well,                    Well, Mechanized Pump - Solar,       Mechanized Pump,        Improved,              Nigeria,         Osun,       Osogbo,           NA, ... \n\n\n\nprint(wp_nonfunctional_sp) #SpatialPoints DataFrame\n\nclass       : SpatialPointsDataFrame \nfeatures    : 2260 \nextent      : 180539, 290616, 340054.1, 450780.1  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs \nvariables   : 74\nnames       : row_id,                                     X.source, X.lat_deg, X.lon_deg,          X.report_date, X.status_id,    X.water_source_clean, X.water_source_category,      X.water_tech_clean, X.water_tech_category, X.facility_type, X.clean_country_name, X.clean_adm1, X.clean_adm2, X.clean_adm3, ... \nmin values  : 154880, Federal Ministry of Water Resources, Nigeria,  7.060309, 4.0618927, 01/10/2015 12:00:00 AM,          No,                Borehole,                  Spring,               Hand Pump,             Hand Pump,        Improved,              Nigeria,         Osun,     Aiyedade,           NA, ... \nmax values  : 475147,                                        GRID3, 8.0611733, 5.0537867, 09/16/2015 12:00:00 AM,     Unknown, Undefined Hand Dug Well,                    Well, Mechanized Pump - Solar,       Mechanized Pump,        Improved,              Nigeria,         Osun,       Osogbo,           NA, ..."
  },
  {
    "objectID": "take-home_ex/take-home_ex01/take-home_ex01.html#converting-spatial-class-into-formal-class",
    "href": "take-home_ex/take-home_ex01/take-home_ex01.html#converting-spatial-class-into-formal-class",
    "title": "Take Home Exercise 01",
    "section": "3.4 Converting Spatial class into Formal class",
    "text": "3.4 Converting Spatial class into Formal class\n\n# as we saw above, osun_boundary is a SpatialPolygon\n\nosun_sp <- as(osun_sp, \"SpatialPolygons\")\n\n# as we saw above, both waterpoint data are SpatialPoints\n\nwp_functional_sp <- as(wp_functional_sp, \"SpatialPoints\")\n\nwp_nonfunctional_sp <- as(wp_nonfunctional_sp, \"SpatialPoints\")"
  },
  {
    "objectID": "take-home_ex/take-home_ex01/take-home_ex01.html#converting-formal-class-into-ppp-format",
    "href": "take-home_ex/take-home_ex01/take-home_ex01.html#converting-formal-class-into-ppp-format",
    "title": "Take Home Exercise 01",
    "section": "3.5 Converting Formal class into ppp format",
    "text": "3.5 Converting Formal class into ppp format\n\nwp_functional_ppp <- as(wp_functional_sp, \"ppp\")\n\nwp_nonfunctional_ppp <- as(wp_nonfunctional_sp, \"ppp\")\n\nLet’s take a look at the ppp format.\n\nsummary(wp_functional_ppp)\n\nPlanar point pattern:  2737 points\nAverage intensity 2.23908e-07 points per square unit\n\nCoordinates are given to 2 decimal places\ni.e. rounded to the nearest multiple of 0.01 units\n\nWindow: rectangle = [177285.9, 290750.96] x [343128.1, 450859.7] units\n                    (113500 x 107700 units)\nWindow area = 12223800000 square units\n\nsummary(wp_nonfunctional_ppp)\n\nPlanar point pattern:  2260 points\nAverage intensity 1.854223e-07 points per square unit\n\nCoordinates are given to 2 decimal places\ni.e. rounded to the nearest multiple of 0.01 units\n\nWindow: rectangle = [180538.96, 290616] x [340054.1, 450780.1] units\n                    (110100 x 110700 units)\nWindow area = 12188400000 square units\n\n\nAs we can see there are no duplicates in the two variables above. Hence, we do not need to perform additional data cleaning to deal with duplicate data such as jittering. An example of jittering can be seen from one of our Hands-On exercises here. Just in case, let’s use the any() and duplicated() functions to check for duplicate data.\n\nprint(any(duplicated(wp_functional_ppp)))\n\n[1] FALSE\n\nprint(any(duplicated(wp_nonfunctional_ppp)))\n\n[1] FALSE"
  },
  {
    "objectID": "take-home_ex/take-home_ex01/take-home_ex01.html#create-an-owin-object-of-osun-state-combining-the-point-events-object-and-owin-object",
    "href": "take-home_ex/take-home_ex01/take-home_ex01.html#create-an-owin-object-of-osun-state-combining-the-point-events-object-and-owin-object",
    "title": "Take Home Exercise 01",
    "section": "3.6 Create an owin object of Osun State & Combining the point events object and owin object",
    "text": "3.6 Create an owin object of Osun State & Combining the point events object and owin object\nWe need to create an owin object to confine the analysis within a geographical area. This is the common practice.\n\nosun_owin <- as(osun_sp, \"owin\")\n\nCombining point event objects and owin object\n\nwp_functional_ppp_osun = wp_functional_ppp[osun_owin]\nwp_nonfunctional_ppp_osun = wp_nonfunctional_ppp[osun_owin]\n\nVisualization of ppp objects within Osun boundaries\n\npar(mfrow = c(1,2))\nplot(wp_nonfunctional_ppp_osun, main=\"Non Functional water points\")\nplot(wp_functional_ppp_osun, main=\"Functional water points\")\n\n\n\n\nAs we went through in Hands-On Exercise 5 we need to rescale() to transform the unit of measurement from meters to kilometers since EPSG: 26392 uses meters. More details can be found here. If we do not do this, the density value of our kernel density maps will be too small later on.\n\nwp_functional_ppp_osun_km <- rescale(wp_functional_ppp_osun, 1000, \"km\")\nwp_nonfunctional_ppp_osun_km <- rescale(wp_nonfunctional_ppp_osun, 1000, \"km\")"
  },
  {
    "objectID": "take-home_ex/take-home_ex01/take-home_ex01.html#computing-kernel-density-estimation",
    "href": "take-home_ex/take-home_ex01/take-home_ex01.html#computing-kernel-density-estimation",
    "title": "Take Home Exercise 01",
    "section": "3.7 Computing kernel density estimation",
    "text": "3.7 Computing kernel density estimation\nAs mentioned in our Lesson 4 slides, kernel density estimation can be calculated using either adaptive or fixed bandwidth. Since the fixed bandwidth method is very sensitive to highly skewed distribution of spatial point patterns over geographical units we use adaptive bandwidths instead. This is because from our initial visualizations, we have noticed that there is evidence of skewed data and clustering for both functional and non-functional water points.\n\nkde_wpfunctional_adaptive <- adaptive.density(wp_functional_ppp_osun_km, method = \"kernel\")\n\nkde_wpnonfunctional_adaptive <- adaptive.density(wp_nonfunctional_ppp_osun_km, method = \"kernel\")\n\npar(mfrow=c(1,2))\nplot(kde_wpfunctional_adaptive, main = \"Functional Waterpoints\")\nplot(kde_wpnonfunctional_adaptive, main = \"Non-functional Waterpoints\")"
  },
  {
    "objectID": "take-home_ex/take-home_ex01/take-home_ex01.html#displaying-kernel-density-maps-on-openstreetmap-of-osun-state-nigeria",
    "href": "take-home_ex/take-home_ex01/take-home_ex01.html#displaying-kernel-density-maps-on-openstreetmap-of-osun-state-nigeria",
    "title": "Take Home Exercise 01",
    "section": "3.8 Displaying Kernel Density Maps on OpenStreetMap of Osun State, Nigeria",
    "text": "3.8 Displaying Kernel Density Maps on OpenStreetMap of Osun State, Nigeria\nThe kernel density estimation maps shown above are image files that do not show exactly where the location is. So we need to convert the image into a Grid Object and then into a RasterLayer object.\n\nkde_wpfunctional_bw_raster <- kde_wpfunctional_adaptive %>%\n  as.SpatialGridDataFrame.im()%>%\n  raster()\n\nkde_wpnonfunctional_bw_raster <- kde_wpnonfunctional_adaptive %>%\n  as.SpatialGridDataFrame.im()%>%\n  raster()\n\n\n3.8.1 Assigning Projection Systems\nLet’s view the properties of the RasterLayers.\n\nkde_wpfunctional_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.8948485, 0.9616045  (x, y)\nextent     : 176.5032, 291.0438, 331.4347, 454.5201  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -1.394379e-15, 24.61848  (min, max)\n\n\n\nkde_wpnonfunctional_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.8948485, 0.9616045  (x, y)\nextent     : 176.5032, 291.0438, 331.4347, 454.5201  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -4.685572e-17, 21.27264  (min, max)\n\n\nWe can see that the crs property is NA. Let’s fix this.\n\nprojection(kde_wpfunctional_bw_raster) <- CRS(\"+init=EPSG:26392 +datum=WGS84 +units=km\")\nprojection(kde_wpnonfunctional_bw_raster) <- CRS(\"+init=EPSG:26392 +datum=WGS84 +units=km\")\n\n\n\n3.8.2 Visualizing the Functional water points in tmap\n\ntm_shape(kde_wpfunctional_bw_raster) + \n  tm_raster(\"v\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\n\n\n\n\n\n\n3.8.3 Visualizing the Non-Functional water points in tmap\n\ntm_shape(kde_wpnonfunctional_bw_raster) + \n  tm_raster(\"v\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)"
  },
  {
    "objectID": "take-home_ex/take-home_ex01/take-home_ex01.html#kernel-density-maps-analysis",
    "href": "take-home_ex/take-home_ex01/take-home_ex01.html#kernel-density-maps-analysis",
    "title": "Take Home Exercise 01",
    "section": "3.9 Kernel Density Maps Analysis",
    "text": "3.9 Kernel Density Maps Analysis\nWe have derived the kernel density maps of both functional and non-functional water points and we have displayed them on OpenStreetMap of the Osun State of Nigeria. Now, let us take a look at the spatial patterns being revealed by these maps…\nAs we can see from the maps above, most of the water points (functional and non-functional) are present in the central and northern regions of Osun. There are more functional water points in the northern region of Osun and non-functional water points in the central region of Osun.\nHowever, one rather important point to note is that only the densely populated areas in Osun have higher density of functional water points. For instance, two most populated cities in Osun being Osogbo and Ilesa with a population of roughly 800,000 and 390,000 people (macrotrends, 2020) seem to have denser functional water points. The map below shows where the bigger cities are. By comparing it with the maps we have generated we can see that these cities have access to functional water points but other states (like Ife) are of luck. So the government should start to focus on these states as well. From our analysis we see a large concentration of non-functional water points near Ife, the government could look to constructing the necessary infrastructure to use this water source as it will help Ife and other smaller cities (around the central-southern parts of Osun) as well.\n\n\n\n\n\nKernel Density Maps are highly advantageous as they help provide a smooth representation of the data which allows for easier visual representation and understanding of the underlying patterns. They also reduce overplotting, where there are many points in close proximity to one another, and the map becomes over cluttered. Let’s refer to the map we generated before:\n\nThe map looks heavily cluttered and it might seem as though there are lots of non-functional waterpoints all throughout Osun but when we take a closer look:\n\nWe see that that is not the case, in fact the water points are heavily clustered and each cluster is spread out quite far from each other."
  },
  {
    "objectID": "take-home_ex/take-home_ex01/take-home_ex01.html#performing-complete-spatial-randomness-test",
    "href": "take-home_ex/take-home_ex01/take-home_ex01.html#performing-complete-spatial-randomness-test",
    "title": "Take Home Exercise 01",
    "section": "4.1 Performing Complete Spatial Randomness Test",
    "text": "4.1 Performing Complete Spatial Randomness Test\nThe cross K-function is calculated by counting the number of points in a dataset that are within a given distance of a target point. It is used to determine whether the spatial distribution of points is clustered, dispersed, or random. From our Lesson 4 slides we know that the K-function uses more points and provides an estimation of spatial dependence over a wider range of scales based on the distances between events in the study area. This is perfect for this particular test.\nWe will be using the Cross-L Function which is a commonly used variation of the K-function. It standardizes the K-function into a straight line to make the visual assessment of deviation easier.\nAdditional Details:\n\nHo =\n\nThe distribution of functional waterpoints in Osun State, Nigeria are randomly distributed.\nThe distribution of non-functional waterpoints in Osun State, Nigeria are randomly distributed.\n\nH1=\n\nThe distribution of functional waterpoints in Osun State, Nigeria are not randomly distributed.\nThe distribution of non-functional waterpoints in Osun State, Nigeria are not randomly distributed.\n\nConfidence Level = 95%\n\nI have chosen this level of confidence as it strikes a balance between the level of precision and the level of certainty that is desired in the results. In fact, generally a confidence level of 99% is not commonly used in practice, given the inherent uncertainty in many research studies.\n\nSignificance Level = 0.05\n\nThe null hypothesis will be rejected if the p-value is smaller than alpha value of 0.05.\n\n4.1.1 Functional water point Cross-L Function\n\nL_osun.csr <- envelope(wp_functional_ppp_osun, Lest, nsim = 39, rank = 1, glocal=TRUE)\n\n\n\n\n\n\n\nImportant\n\n\n\nMy apologies, the output above cannot be seen as I accidentally deleted it.\n\n\n\nplot(L_osun.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\n4.1.2 Non-Functional water point Cross-L Function\n\nL_osun_nonfunctional <- envelope(wp_nonfunctional_ppp_osun, Lest, nsim = 39, rank = 1, glocal=TRUE)\n\n\nplot(L_osun_nonfunctional, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\n4.1.3 Interpreting the L functions\nWhen the observed L value is greater than its corresponding L (theo) (i.e., the red break line) and is above the upper confidence envelope, spatial clustering for that distance is statistically significant. As we see this for both functional and non-functional water points, we can reject the null hypothesis at the 95% level of significance that the water points (functional and non-functional) are randomly distributed. They are in fact, clustered. This matches with our Task 1: ESDA findings."
  },
  {
    "objectID": "take-home_ex/take-home_ex01/take-home_ex01.html#perform-lclq-calculation",
    "href": "take-home_ex/take-home_ex01/take-home_ex01.html#perform-lclq-calculation",
    "title": "Take Home Exercise 01",
    "section": "5.1 Perform LCLQ calculation",
    "text": "5.1 Perform LCLQ calculation\nTo perform the calculation, we will need certain data:\n\nThe study area, we will be using our previously generated osun variable\nThe water points, we will be using our previously generated wp_sf variable\n\n\n5.1.1 Study Area\n\nstudy_area = osun\n\n\n\n5.1.2 Water points data\n\nwaterpoints = wp_sf\n\n\n\n5.1.3 Plotting data\nLet’s first start by plotting the data points to visualize the distribution of water points.\n\n# plotting functional and non-functional points in the area of study\ntmap_mode(\"view\")\ntm_shape(study_area) +\n  tm_polygons() +\ntm_shape(waterpoints) + \n  tm_dots(col = \"#status_clean\",\n          size = 0.01,\n          border.col = \"black\",\n          border.lwd = 0.5)\n\n\n\n\n\n\n\n\n5.1.4 Data Wrangling\n\n5.1.4.1 Separate the #status_clean values into functional and non-functional\n\nfunctional_wps <- waterpoints %>%\n  filter(`#status_clean` %in%\n           c(\"Functional\",\n             \"Functional, needs repair\",\n             \"Functional, not in use\",\n             \"Functional but not in use\",\n             \"Functional but needs repair\"))\n\nnonfunctional_wps <- waterpoints %>%\n  filter(`#status_clean` %in%\n           c(\"Non-Functional\",\n             \"Non-Functional, dry\",\n             \"Abandoned/Decommissioned\",\n             \"Non-Functional due to dry season\"))\n\n\n\n5.1.4.2 Prepare vector lists to be used in local_colocation()\nAs Prof. Kam mentioned in class, the function takes factor vectors. We can also see that in this documentation. Let’s prepare these two vectors. Our Category A will be the functional water points, and B will be the non-functional water points.\n\nA <- functional_wps$`#status_clean`\nB <- nonfunctional_wps$`#status_clean`\n\n\n\n\n5.1.5 Calculation of LCLQ\n\n# neighbourhood list\nnb <- include_self(\n  st_knn(st_geometry(waterpoints), 6))\n\n# weight\nwt <- st_kernel_weights(nb,\n                        waterpoints,\n                        \"gaussian\",\n                        adaptive=TRUE)\n\n\nLCLQ <- local_colocation(A, B, nb, wt, 39)\n\n\nLCLQ_waterpoints <- cbind(waterpoints, LCLQ)\n\n\n# see which points are colocated and their corresponding p-value\ntmap_mode(\"view\")\ntm_shape(study_area) + \n  tm_polygons() + \ntm_shape(LCLQ_waterpoints) + \n  tm_dots(col = \"Non.Functional\",\n          size = 0.01,\n          border.col = \"black\",\n          border.lwd = 0.5) +\ntm_shape(LCLQ_waterpoints) +\n  tm_dots(col = \"p_sim_Non.Functional\")\n\n\n\n\n\n\n\n\n5.1.6 Analysis of LCLQ\nColocation quotient less than 1 indicates that the two point patterns being analyzed are negatively correlated. This means that the presence of points in one pattern tends to be associated with a lower probability of finding points in the other pattern in the same area. Additionally, since the p-value of is less than 0.05, we can reject the null hypothesis that the functional and non-functional water points are independent."
  },
  {
    "objectID": "take-home_ex/take-home_ex02/take-home_ex02.html",
    "href": "take-home_ex/take-home_ex02/take-home_ex02.html",
    "title": "Take Home Exercise 02: Spatio-temporal Analysis of COVID-19 Vaccination Trends at the Sub-district Level, DKI Jakarta",
    "section": "",
    "text": "In late December 2019, the COVID-19 outbreak was reported in Wuhan, China, which had subsequently affected 210 countries worldwide. COVID-19 can be deadly with a 2% case fatality rate.\nIn response to this, Indonesia commenced its COVID-19 vaccination program on 13 January 2021, and as of 5 February 2023, over 204 million people had received the first dose of the vaccine, and over 175 million people had been fully vaccinated, with Jakarta having the highest percentage of population fully vaccinated.\nHowever despite its compactness, the cumulative vaccination rate are not evenly distributed within DKI Jakarta. The question is where are the sub-districts with a relatively higher number of vaccination rate and how have they changed over time.\nThe assignment can be found here."
  },
  {
    "objectID": "take-home_ex/take-home_ex02/take-home_ex02.html#objectives",
    "href": "take-home_ex/take-home_ex02/take-home_ex02.html#objectives",
    "title": "Take Home Exercise 02: Spatio-temporal Analysis of COVID-19 Vaccination Trends at the Sub-district Level, DKI Jakarta",
    "section": "2 Objectives",
    "text": "2 Objectives\nExploratory Spatial Data Analysis (ESDA) holds tremendous potential to address complex problems facing society. In this study, we will need to use it to uncover the spatio-temporal trends of COVID-19 vaccination in DKI Jakarta namely:\n\nChoropleth Mapping and Analysis\nLocal Gi* Analysis\nEmerging Hot Spot Analysis (EHSA)"
  },
  {
    "objectID": "take-home_ex/take-home_ex02/take-home_ex02.html#setup",
    "href": "take-home_ex/take-home_ex02/take-home_ex02.html#setup",
    "title": "Take Home Exercise 02: Spatio-temporal Analysis of COVID-19 Vaccination Trends at the Sub-district Level, DKI Jakarta",
    "section": "3 Setup",
    "text": "3 Setup\n\n3.1 Packages used\nThese are the R packages that we’ll need for our analyses:\n\nsf - used for importing, managing, and processing geospatial data\nsfdep - an sf and tidyverse friendly interface to compute spatial dependence\ntidyverse - collection of packages for performing data science tasks such as importing, wrangling, and visualising data\ntmap - for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API\nreadxl - for reading .xlsx files. It is part of the tidyverse collection.\nhash - used to create a hash object. I have used this to convert the month spelling from Bahasa Indonesia to English. This is done so that when the data is visualised it is clear to all.\nmoments - used to call the skewness() function to calculate skewness of the data.\n\n\npacman::p_load(sf, sfdep, tidyverse, tmap, hash, moments, plyr, readxl)\n\n\n\n3.2 Datasets used\n\n\n\nType\nName\nFormat\nDescription\n\n\n\n\nGeospatial\nDKI Jakarta Provincial Village Boundary\n.shp\nDistrict level boundary in DKI Jakarta. Please take note that the data is from 2019.\n\n\nAspatial\nDistrict Based Vaccination History\n.xlsx\nDaily .csv files containing all vaccinations done at the sub-district level (i.e., kelurahan) in DKI Jakarta. The files consider the number of doses given to the following groups of people:\n\nMutual Cooperation Vaccination (Ages 18+)\nVaccination of Health Workers (Ages 18+)\nElderly Vaccination (Ages 18+)\nPublic Service Vaccination (Ages 18+)\nStage 3 Vaccination (General Community, Pre-Elderly, Vulnerable)\nYouth Vaccination (Ages 12-17)"
  },
  {
    "objectID": "take-home_ex/take-home_ex02/take-home_ex02.html#data-wrangling-geospatial-data",
    "href": "take-home_ex/take-home_ex02/take-home_ex02.html#data-wrangling-geospatial-data",
    "title": "Take Home Exercise 02: Spatio-temporal Analysis of COVID-19 Vaccination Trends at the Sub-district Level, DKI Jakarta",
    "section": "4 Data Wrangling: Geospatial Data",
    "text": "4 Data Wrangling: Geospatial Data\n\n4.1 Importing Geospatial Data\n\njakarta <- st_read(dsn=\"data/geospatial\",\n                   layer=\"BATAS_DESA_DESEMBER_2019_DUKCAPIL_DKI_JAKARTA\")\n\nReading layer `BATAS_DESA_DESEMBER_2019_DUKCAPIL_DKI_JAKARTA' from data source \n  `C:\\guga-nesh\\IS415-GAA\\take-home_ex\\take-home_ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 269 features and 161 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 106.3831 ymin: -6.370815 xmax: 106.9728 ymax: -5.184322\nGeodetic CRS:  WGS 84\n\n\nInformation gathered on jakarta :\n\nData Type: sf collection\nGeometry Type: Multipolygon\nShape: 269 features, 161 fields\nCRS: WGS 84 - ‘The World Geodetic System (WGS)’.\n\n\n\n\n\n\n\nNote\n\n\n\nThe assigned CRS does not seem appropriate. In fact, the assignment requires us to re-assign the CRS to DGN95. We’ll fix this in Section 4.2.3.\n\n\n\n\n4.2 Data pre-processing\nBefore we can visualise our data, we need to ensure that the data is validated by handling invalid geometries and missing values.\nThis section was done by referencing sample submissions done by two seniors, credit to:\n\nXiao Rong Wong’s ‘Detecting Spatio-Temporal Patterns of COVID-19 in Central Mexico’\nMegan Sim Tze Yen’s ‘Analysing and Visualising Spatio-temporal Patterns of COVID-19 in DKI Jakarta, Indonesia’\n\nAfterwards, we can work on doing the pre-processing on the jakarta data as per the requirements of the assignment.\n\n4.2.1 Handling invalid geometries\n\nlength(which(st_is_valid(jakarta) == FALSE))\n\n[1] 0\n\n\n\n\n\n\n\n\nNote\n\n\n\nst_is_valid() checks whether a geometry is valid. It returns a logical vector indicating for each geometries of jakarta whether it is valid. The documentation for this can be found here.\n\n\nFrom the above output, we can see that the geometry is valid 👍\n\n\n4.2.2 Handling missing values\n\njakarta[rowSums(is.na(jakarta))!=0,]\n\nSimple feature collection with 2 features and 161 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 106.8412 ymin: -6.154036 xmax: 106.8612 ymax: -6.144973\nGeodetic CRS:  WGS 84\n    OBJECT_ID KODE_DESA             DESA   KODE    PROVINSI KAB_KOTA KECAMATAN\n243     25645  31888888     DANAU SUNTER 318888 DKI JAKARTA     <NA>      <NA>\n244     25646  31888888 DANAU SUNTER DLL 318888 DKI JAKARTA     <NA>      <NA>\n    DESA_KELUR JUMLAH_PEN JUMLAH_KK LUAS_WILAY KEPADATAN PERPINDAHA JUMLAH_MEN\n243       <NA>          0         0          0         0          0          0\n244       <NA>          0         0          0         0          0          0\n    PERUBAHAN WAJIB_KTP SILAM KRISTEN KHATOLIK HINDU BUDHA KONGHUCU KEPERCAYAA\n243         0         0     0       0        0     0     0        0          0\n244         0         0     0       0        0     0     0        0          0\n    PRIA WANITA BELUM_KAWI KAWIN CERAI_HIDU CERAI_MATI U0 U5 U10 U15 U20 U25\n243    0      0          0     0          0          0  0  0   0   0   0   0\n244    0      0          0     0          0          0  0  0   0   0   0   0\n    U30 U35 U40 U45 U50 U55 U60 U65 U70 U75 TIDAK_BELU BELUM_TAMA TAMAT_SD SLTP\n243   0   0   0   0   0   0   0   0   0   0          0          0        0    0\n244   0   0   0   0   0   0   0   0   0   0          0          0        0    0\n    SLTA DIPLOMA_I DIPLOMA_II DIPLOMA_IV STRATA_II STRATA_III BELUM_TIDA\n243    0         0          0          0         0          0          0\n244    0         0          0          0         0          0          0\n    APARATUR_P TENAGA_PEN WIRASWASTA PERTANIAN NELAYAN AGAMA_DAN PELAJAR_MA\n243          0          0          0         0       0         0          0\n244          0          0          0         0       0         0          0\n    TENAGA_KES PENSIUNAN LAINNYA GENERATED KODE_DES_1 BELUM_ MENGUR_ PELAJAR_\n243          0         0       0      <NA>       <NA>      0       0        0\n244          0         0       0      <NA>       <NA>      0       0        0\n    PENSIUNA_1 PEGAWAI_ TENTARA KEPOLISIAN PERDAG_ PETANI PETERN_ NELAYAN_1\n243          0        0       0          0       0      0       0         0\n244          0        0       0          0       0      0       0         0\n    INDUSTR_ KONSTR_ TRANSP_ KARYAW_ KARYAW1 KARYAW1_1 KARYAW1_12 BURUH BURUH_\n243        0       0       0       0       0         0          0     0      0\n244        0       0       0       0       0         0          0     0      0\n    BURUH1 BURUH1_1 PEMBANT_ TUKANG TUKANG_1 TUKANG_12 TUKANG__13 TUKANG__14\n243      0        0        0      0        0         0          0          0\n244      0        0        0      0        0         0          0          0\n    TUKANG__15 TUKANG__16 TUKANG__17 PENATA PENATA_ PENATA1_1 MEKANIK SENIMAN_\n243          0          0          0      0       0         0       0        0\n244          0          0          0      0       0         0       0        0\n    TABIB PARAJI_ PERANCA_ PENTER_ IMAM_M PENDETA PASTOR WARTAWAN USTADZ JURU_M\n243     0       0        0       0      0       0      0        0      0      0\n244     0       0        0       0      0       0      0        0      0      0\n    PROMOT ANGGOTA_ ANGGOTA1 ANGGOTA1_1 PRESIDEN WAKIL_PRES ANGGOTA1_2\n243      0        0        0          0        0          0          0\n244      0        0        0          0        0          0          0\n    ANGGOTA1_3 DUTA_B GUBERNUR WAKIL_GUBE BUPATI WAKIL_BUPA WALIKOTA WAKIL_WALI\n243          0      0        0          0      0          0        0          0\n244          0      0        0          0      0          0        0          0\n    ANGGOTA1_4 ANGGOTA1_5 DOSEN GURU PILOT PENGACARA_ NOTARIS ARSITEK AKUNTA_\n243          0          0     0    0     0          0       0       0       0\n244          0          0     0    0     0          0       0       0       0\n    KONSUL_ DOKTER BIDAN PERAWAT APOTEK_ PSIKIATER PENYIA_ PENYIA1 PELAUT\n243       0      0     0       0       0         0       0       0      0\n244       0      0     0       0       0         0       0       0      0\n    PENELITI SOPIR PIALAN PARANORMAL PEDAGA_ PERANG_ KEPALA_ BIARAW_ WIRASWAST_\n243        0     0      0          0       0       0       0       0          0\n244        0     0      0          0       0       0       0       0          0\n    LAINNYA_12 LUAS_DESA KODE_DES_3 DESA_KEL_1 KODE_12\n243          0         0       <NA>       <NA>       0\n244          0         0       <NA>       <NA>       0\n                          geometry\n243 MULTIPOLYGON (((106.8612 -6...\n244 MULTIPOLYGON (((106.8504 -6...\n\n\n\n\n\n\n\n\nNote\n\n\n\nrowSums() method calculates the sum of each row of a data frame. Please refer to the documentation here.\nis.na() is a generic method that indicates which elements are missing. Please refer to the documentation here.\njakarta ‘wrapper’ prints rows that contain NA values.\n\n\nFrom the output shown above we can see that there are NA values 👎\nIn fact, there are two rows with missing values. However, it’s hard to tell which columns the NA values are in since the output is so long and messy. Let’s just retrieve the columns with missing values.\n\nnames(which(colSums(is.na(jakarta))>0))\n\n[1] \"KAB_KOTA\"   \"KECAMATAN\"  \"DESA_KELUR\" \"GENERATED\"  \"KODE_DES_1\"\n[6] \"KODE_DES_3\" \"DESA_KEL_1\"\n\n\n\n\n\n\n\n\nNote\n\n\n\ncolSum() helps form sum for data frame by column. Please refer to the documentation here.\nwhich() gives the TRUE indices of a logical object, allowing for array indices. Please refer to the documentation here.\nnames() is used to get or set the names of an object. Please refer to the documentation here.\n\n\nThere are two rows with missing values in the columns shown above. Let’s see what they mean… Google Translate tells us that: 🤔\n\n“KAB_KOTA” = REGENCY_CITY\n“KECAMATAN” = SUB-DISTRICT\n“DESA_KELUR” = VILLAGE_KELUR\n\nWe can remove all rows with missing values under the “DESA_KELUR” (i.e., VILLAGE level) column since we are only interested in the sub-district and potentially city level data.\n\n\n\n\n\n\nNote\n\n\n\nLater we find out that the definition of these columns by Google Translate are not 100% accurate. But it’s okay as this does not affect our analysis for now.\n\n\nNonetheless, it should be noted that in this particular case removing the missing values from any of the columns will yield the same result.\n\njakarta <- na.omit(jakarta, c(\"DESA_KELUR\"))\n\n\n\n\n\n\n\nNote\n\n\n\nna.omit() is used to handle missing values in objects. In this case, we input the object(must be an R object) and the target.colnames (a vector of names for the target columns to operate upon, if present in object. Please refer to the documentation here.\n\n\nLet’s check if we have removed the rows with missing values:\n\njakarta[rowSums(is.na(jakarta))!=0,]\n\nSimple feature collection with 0 features and 161 fields\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nGeodetic CRS:  WGS 84\n  [1] OBJECT_ID  KODE_DESA  DESA       KODE       PROVINSI   KAB_KOTA  \n  [7] KECAMATAN  DESA_KELUR JUMLAH_PEN JUMLAH_KK  LUAS_WILAY KEPADATAN \n [13] PERPINDAHA JUMLAH_MEN PERUBAHAN  WAJIB_KTP  SILAM      KRISTEN   \n [19] KHATOLIK   HINDU      BUDHA      KONGHUCU   KEPERCAYAA PRIA      \n [25] WANITA     BELUM_KAWI KAWIN      CERAI_HIDU CERAI_MATI U0        \n [31] U5         U10        U15        U20        U25        U30       \n [37] U35        U40        U45        U50        U55        U60       \n [43] U65        U70        U75        TIDAK_BELU BELUM_TAMA TAMAT_SD  \n [49] SLTP       SLTA       DIPLOMA_I  DIPLOMA_II DIPLOMA_IV STRATA_II \n [55] STRATA_III BELUM_TIDA APARATUR_P TENAGA_PEN WIRASWASTA PERTANIAN \n [61] NELAYAN    AGAMA_DAN  PELAJAR_MA TENAGA_KES PENSIUNAN  LAINNYA   \n [67] GENERATED  KODE_DES_1 BELUM_     MENGUR_    PELAJAR_   PENSIUNA_1\n [73] PEGAWAI_   TENTARA    KEPOLISIAN PERDAG_    PETANI     PETERN_   \n [79] NELAYAN_1  INDUSTR_   KONSTR_    TRANSP_    KARYAW_    KARYAW1   \n [85] KARYAW1_1  KARYAW1_12 BURUH      BURUH_     BURUH1     BURUH1_1  \n [91] PEMBANT_   TUKANG     TUKANG_1   TUKANG_12  TUKANG__13 TUKANG__14\n [97] TUKANG__15 TUKANG__16 TUKANG__17 PENATA     PENATA_    PENATA1_1 \n[103] MEKANIK    SENIMAN_   TABIB      PARAJI_    PERANCA_   PENTER_   \n[109] IMAM_M     PENDETA    PASTOR     WARTAWAN   USTADZ     JURU_M    \n[115] PROMOT     ANGGOTA_   ANGGOTA1   ANGGOTA1_1 PRESIDEN   WAKIL_PRES\n[121] ANGGOTA1_2 ANGGOTA1_3 DUTA_B     GUBERNUR   WAKIL_GUBE BUPATI    \n[127] WAKIL_BUPA WALIKOTA   WAKIL_WALI ANGGOTA1_4 ANGGOTA1_5 DOSEN     \n[133] GURU       PILOT      PENGACARA_ NOTARIS    ARSITEK    AKUNTA_   \n[139] KONSUL_    DOKTER     BIDAN      PERAWAT    APOTEK_    PSIKIATER \n[145] PENYIA_    PENYIA1    PELAUT     PENELITI   SOPIR      PIALAN    \n[151] PARANORMAL PEDAGA_    PERANG_    KEPALA_    BIARAW_    WIRASWAST_\n[157] LAINNYA_12 LUAS_DESA  KODE_DES_3 DESA_KEL_1 KODE_12    geometry  \n<0 rows> (or 0-length row.names)\n\n\nLooks good! 😎 But we still have 3 other pre-processing steps to do…\n\n\n4.2.3 Re-assign Coordinate Reference System (CRS)\nThe CRS of jakarta is WGS 84. The assignment requires us to use the national CRS of Indonesia ( DGN95 / Indonesia TM-3 zone 54.1) since our dataset is specific to Indonesia.\n\nst_crs(jakarta)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nLet’s re-assign using EPSG code 23845 and check the results.\n\njakarta <- st_transform(jakarta, 23845)\nst_crs(jakarta)\n\nCoordinate Reference System:\n  User input: EPSG:23845 \n  wkt:\nPROJCRS[\"DGN95 / Indonesia TM-3 zone 54.1\",\n    BASEGEOGCRS[\"DGN95\",\n        DATUM[\"Datum Geodesi Nasional 1995\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4755]],\n    CONVERSION[\"Indonesia TM-3 zone 54.1\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",139.5,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9999,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",200000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",1500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"easting (X)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"northing (Y)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre.\"],\n        AREA[\"Indonesia - onshore east of 138°E.\"],\n        BBOX[-9.19,138,-1.49,141.01]],\n    ID[\"EPSG\",23845]]\n\n\n\n\n\n\n\n\nNote\n\n\n\nst_transform() is used to transform or convert coordinates of a simple feature. Please refer to the documentation here.\nst_crs() is used to retrieve the coordinate reference system from an sf or sfc object. Please refer to the documentation here.\n\n\n\n\n4.2.4 Exclude all outer islands from jakarta\nThe assignment requires us to remove all outer islands from jakarta. Let’s plot the geometry of jakarta to see what we’re working with.\n\nplot(jakarta['geometry'])\n\n\n\n\nFrom the visualisation above, we can see that there are some outer islands scattered towards the north. Let’s remove them.\nIn Section 4.2.2, we saw that the data is grouped by KAB_KOTA (i.e., CITY), KECAMATAN (i.e., SUB-DISTRICT), and DESA_KELUR (i.e., “VILLAGE”). Let’s see the different cities we have in DKI Jakarta.\n\nunique(jakarta$KAB_KOTA)\n\n[1] \"JAKARTA BARAT\"    \"JAKARTA PUSAT\"    \"KEPULAUAN SERIBU\" \"JAKARTA UTARA\"   \n[5] \"JAKARTA TIMUR\"    \"JAKARTA SELATAN\" \n\n\nThe output shows us that there are 6 different cities in DKI Jakarta. 5 of them are prefixed with the string “JAKARTA” while one of them isn’t. Let’s plot this data to see if the one without the prefix represents the outer islands.\n\ntm_shape(jakarta) + \n  tm_polygons(\"KAB_KOTA\")\n\n\n\n\nIt seems our suspicions are correct, the outer islands are those cities without the “JAKARTA” prefix. In fact, according to Google Translate, “KEPULAUAN SEBIRU” can be directly translated to “Thousand Islands” in English. Let’s remove them and check the results.\n\njakarta <- jakarta %>% filter(grepl(\"JAKARTA\", KAB_KOTA))\n\nunique(jakarta$KAB_KOTA)\n\n[1] \"JAKARTA BARAT\"   \"JAKARTA PUSAT\"   \"JAKARTA UTARA\"   \"JAKARTA TIMUR\"  \n[5] \"JAKARTA SELATAN\"\n\n\n\n\n\n\n\n\nNote\n\n\n\ngrepl() is used to search for matches to argument pattern (in our case its “JAKARTA”) within each element of a character vector. Please find the documentation here.\n\n\n\nplot(jakarta$geometry)\n\n\n\n\nLooks good! 😎\n\n\n4.2.5 Retain first nine fields in jakarta\nThe assignment requires us to only retain the first 9 fields of the sf data frame. Let’s do this.\n\njakarta <- jakarta[,0:9]\n\njakarta\n\nSimple feature collection with 261 features and 9 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -3644275 ymin: 663887.8 xmax: -3606237 ymax: 701380.1\nProjected CRS: DGN95 / Indonesia TM-3 zone 54.1\nFirst 10 features:\n   OBJECT_ID  KODE_DESA               DESA   KODE    PROVINSI      KAB_KOTA\n1      25477 3173031006          KEAGUNGAN 317303 DKI JAKARTA JAKARTA BARAT\n2      25478 3173031007             GLODOK 317303 DKI JAKARTA JAKARTA BARAT\n3      25397 3171031003      HARAPAN MULIA 317103 DKI JAKARTA JAKARTA PUSAT\n4      25400 3171031006       CEMPAKA BARU 317103 DKI JAKARTA JAKARTA PUSAT\n5      25390 3171021001         PASAR BARU 317102 DKI JAKARTA JAKARTA PUSAT\n6      25391 3171021002       KARANG ANYAR 317102 DKI JAKARTA JAKARTA PUSAT\n7      25394 3171021005 MANGGA DUA SELATAN 317102 DKI JAKARTA JAKARTA PUSAT\n8      25386 3171011003       PETOJO UTARA 317101 DKI JAKARTA JAKARTA PUSAT\n9      25403 3171041001              SENEN 317104 DKI JAKARTA JAKARTA PUSAT\n10     25408 3171041006             BUNGUR 317104 DKI JAKARTA JAKARTA PUSAT\n     KECAMATAN         DESA_KELUR JUMLAH_PEN                       geometry\n1   TAMAN SARI          KEAGUNGAN      21609 MULTIPOLYGON (((-3626874 69...\n2   TAMAN SARI             GLODOK       9069 MULTIPOLYGON (((-3627130 69...\n3    KEMAYORAN      HARAPAN MULIA      29085 MULTIPOLYGON (((-3621251 68...\n4    KEMAYORAN       CEMPAKA BARU      41913 MULTIPOLYGON (((-3620608 69...\n5  SAWAH BESAR         PASAR BARU      15793 MULTIPOLYGON (((-3624097 69...\n6  SAWAH BESAR       KARANG ANYAR      33383 MULTIPOLYGON (((-3624785 69...\n7  SAWAH BESAR MANGGA DUA SELATAN      35906 MULTIPOLYGON (((-3624752 69...\n8       GAMBIR       PETOJO UTARA      21828 MULTIPOLYGON (((-3626121 69...\n9        SENEN              SENEN       8643 MULTIPOLYGON (((-3623189 69...\n10       SENEN             BUNGUR      23001 MULTIPOLYGON (((-3622451 69...\n\n\nFrom the assignment we know that the ninth field is “JUMLAH_PEN”. The output generated above matches this information.\n\n\n4.2.6 Rename Columns for better understanding\nFor better understanding of the data, let us rename the columns to their English translation. For this we will use the rename() function.\n\n\n\n\n\n\nNote\n\n\n\nSince Google Translate has been giving me contradicting answers 😓, I have decided to use this wiki page as a guide.\n\n\n\n# take note of the hierarchy of subdivisions of Indonesia\n\njakarta <- jakarta %>%\n  dplyr::rename(\n    object_id = OBJECT_ID,\n    village_code = KODE_DESA,\n    \n    # fifth level\n    village = DESA,\n    code = KODE,\n    \n    # first level\n    province = PROVINSI,\n    \n    # second level\n    city = KAB_KOTA,\n    \n    # third level\n    district = KECAMATAN,\n    \n    # fourth level - assumption made: KELUR = KELURAHAN\n    sub_district = DESA_KELUR,\n    total_population = JUMLAH_PEN\n  )\n\n\n\n\n\n\n\nNote\n\n\n\nrename() is a method under the dplyr library. It changes the names of individual variables using the new_name = old_name syntax.\nside note: rename_with() renames columns using a function. Please refer to the documentation here.\n\n\nWe have completed the data pre-processing steps for the geospatial data 🥳 Let’s move on to the aspatial data."
  },
  {
    "objectID": "take-home_ex/take-home_ex02/take-home_ex02.html#data-wrangling-aspatial-data",
    "href": "take-home_ex/take-home_ex02/take-home_ex02.html#data-wrangling-aspatial-data",
    "title": "Take Home Exercise 02: Spatio-temporal Analysis of COVID-19 Vaccination Trends at the Sub-district Level, DKI Jakarta",
    "section": "5 Data Wrangling: Aspatial Data",
    "text": "5 Data Wrangling: Aspatial Data\nIn this section, we’ll be importing and performing some basic pre-processing on the COVID-19 vaccination datasets.\n\n5.1 Importing Aspatial Data\nThe assignment requires us to compute the vaccination rate from July 2021 to June 2022 at the sub-district (i.e., kelurahan) level.\n\n\n\n\n\n\nImportant\n\n\n\nWe will be taking the data compiled on the last day of each month to retrieve the monthly records of COVID-19 vaccinations from the above-mentioned time period.\n\n\n\n5.1.1 Primary Data Exploration\nSince we will need to import 12 files (which is a lot), let’s look at the structure of one of them to figure what kind of data we have and how we can pre-process it moving forward.\n\njuly_2021 <- readxl::read_xlsx(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (31 Juli 2021).xlsx\")\n\nglimpse(july_2021)\n\nRows: 268\nColumns: 27\n$ `KODE KELURAHAN`                             <chr> NA, \"3172051003\", \"317304…\n$ `WILAYAH KOTA`                               <chr> NA, \"JAKARTA UTARA\", \"JAK…\n$ KECAMATAN                                    <chr> NA, \"PADEMANGAN\", \"TAMBOR…\n$ KELURAHAN                                    <chr> \"TOTAL\", \"ANCOL\", \"ANGKE\"…\n$ SASARAN                                      <dbl> 8941211, 23947, 29381, 29…\n$ `BELUM VAKSIN`                               <dbl> 4441501, 12333, 13875, 18…\n$ `JUMLAH\\r\\nDOSIS 1`                          <dbl> 4499710, 11614, 15506, 10…\n$ `JUMLAH\\r\\nDOSIS 2`                          <dbl> 1663218, 4181, 4798, 3658…\n$ `TOTAL VAKSIN\\r\\nDIBERIKAN`                  <dbl> 6162928, 15795, 20304, 14…\n$ `LANSIA\\r\\nDOSIS 1`                          <dbl> 502579, 1230, 2012, 865, …\n$ `LANSIA\\r\\nDOSIS 2`                          <dbl> 440910, 1069, 1729, 701, …\n$ `LANSIA TOTAL \\r\\nVAKSIN DIBERIKAN`          <dbl> 943489, 2299, 3741, 1566,…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 1`                  <dbl> 1052883, 3333, 2586, 2837…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 2`                  <dbl> 666009, 2158, 1374, 1761,…\n$ `PELAYAN PUBLIK TOTAL\\r\\nVAKSIN DIBERIKAN`   <dbl> 1718892, 5491, 3960, 4598…\n$ `GOTONG ROYONG\\r\\nDOSIS 1`                   <dbl> 56660, 78, 122, 174, 71, …\n$ `GOTONG ROYONG\\r\\nDOSIS 2`                   <dbl> 38496, 51, 84, 106, 57, 7…\n$ `GOTONG ROYONG TOTAL\\r\\nVAKSIN DIBERIKAN`    <dbl> 95156, 129, 206, 280, 128…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 1`                <dbl> 76397, 101, 90, 215, 73, …\n$ `TENAGA KESEHATAN\\r\\nDOSIS 2`                <dbl> 67484, 91, 82, 192, 67, 3…\n$ `TENAGA KESEHATAN TOTAL\\r\\nVAKSIN DIBERIKAN` <dbl> 143881, 192, 172, 407, 14…\n$ `TAHAPAN 3\\r\\nDOSIS 1`                       <dbl> 2279398, 5506, 9012, 5408…\n$ `TAHAPAN 3\\r\\nDOSIS 2`                       <dbl> 446028, 789, 1519, 897, 4…\n$ `TAHAPAN 3 TOTAL\\r\\nVAKSIN DIBERIKAN`        <dbl> 2725426, 6295, 10531, 630…\n$ `REMAJA\\r\\nDOSIS 1`                          <dbl> 531793, 1366, 1684, 1261,…\n$ `REMAJA\\r\\nDOSIS 2`                          <dbl> 4291, 23, 10, 1, 1, 8, 6,…\n$ `REMAJA TOTAL\\r\\nVAKSIN DIBERIKAN`           <dbl> 536084, 1389, 1694, 1262,…\n\n\n\n\n\n\n\n\nNote\n\n\n\nread_xlsx() reads data from a .xlsx file. This function is from the readxl library under the tidyverse collection.\nglimpse() makes it easier to see every column in a data frame. Please refer to the documentation here.\n\n\nInformation gathered on july_2021:\n\nData Type: tibble data frame\nShape: 268 entries, 27 columns\n\nThere seems to be a quite a few columns…🤔\nWe will only need to take the “KELURAHAN” (i.e., sub- district level) , “SASARAN” (i.e., target) and the “BELUM VAKSIN” (i.e., number of people who have not been vaccinated yet) columns to calculate the vaccination rate for each month. We will look at how we can calculate this in Section 5.1.2.\nI learnt that only these columns were necessary for our analysis after receiving some advice from Professor Kam Tin Seong. Thank you so much for your guidance prof! 😃\n\n\n5.1.2 Creating a function to process our Aspatial Data\nFirst, let us get all the file names for our aspatial data.\n\nsetwd(\"data/aspatial\")\nfile.list <- list.files(pattern = \"*.xlsx\")\nfile.list\n\n [1] \"Data Vaksinasi Berbasis Kelurahan (27 Februari 2022).xlsx\" \n [2] \"Data Vaksinasi Berbasis Kelurahan (30 April 2022).xlsx\"    \n [3] \"Data Vaksinasi Berbasis Kelurahan (30 Juni 2022).xlsx\"     \n [4] \"Data Vaksinasi Berbasis Kelurahan (30 November 2021).xlsx\" \n [5] \"Data Vaksinasi Berbasis Kelurahan (30 September 2021).xlsx\"\n [6] \"Data Vaksinasi Berbasis Kelurahan (31 Agustus 2021).xlsx\"  \n [7] \"Data Vaksinasi Berbasis Kelurahan (31 Desember 2021).xlsx\" \n [8] \"Data Vaksinasi Berbasis Kelurahan (31 Januari 2022).xlsx\"  \n [9] \"Data Vaksinasi Berbasis Kelurahan (31 Juli 2021).xlsx\"     \n[10] \"Data Vaksinasi Berbasis Kelurahan (31 Maret 2022).xlsx\"    \n[11] \"Data Vaksinasi Berbasis Kelurahan (31 Mei 2022).xlsx\"      \n[12] \"Data Vaksinasi Berbasis Kelurahan (31 Oktober 2021).xlsx\"  \n\n\n\n\n\n\n\n\nNote\n\n\n\nThe above code chunk was referenced from stackoverflow. Credit to Jaap for his detailed answer there.\nsetwd(\"dir\") is used to set the working directory to string “dir”. Please refer to the documentation here.\nlibrary() loads and attaches add-on packages. In this case, we need to use to read_excel() from readxl. Hence, we have loaded in that package. Please refer to the documentation here.\nlist.files() is used to generate a vector of file names in the specified directory (from setwd()) with the pattern (“*.xlsx”). Please refer to the documentation here.\n\n\nNow, we are ready to create a function that processes all the files and merges all the data into a single sf data frame. Our output after all the pre-processing should look something like this:\n\nWe will be using two functions to achieve the above-shown skeleton of the data frame:\n\nget_month_year() - this is used to get the English month and year of each file. The output will be put into the final data frame under the “MONTH.YEAR” column\naspatial_data_processing() - this is used to process the data. The following steps are done:\n\nKeep the necessary columns only (i.e., “KODE.KELURAHAN”, “KELURAHAN”, “SASARAN”, “BELUM.VAKSIN”). We need the “KODE.KELURAHAN” column to join the processed aspatial data with the processed geospatial data. We will look at how to do this in Section 6.1.\nRemove the first row of the tibble data frame as it is not needed (it contains the aggregate sum of the data)\nCheck for duplicates and remove them (while primary exploration of data did not show duplicates, we must still be careful as not all files have been manually checked and there is a still a chance that duplicates exist)\nCheck for invalid data (i.e., missing values/NA) and convert them to 0 for us to perform our calculations later on.\nCalculate “VACCINATION.RATE”\nCreate “DATE” column (i.e., date of data collected)\n\n\n\n\n\n\n\n\nImportant\n\n\n\nFormula for Vaccination Rate is as follows:\n\\(vaccination rate = (target - unvaccinated) / target\\)\n\n\n\nget_date <- function(filepath) {\n  # create hash object to map Bahasa Indonesian translation to English\n  h <- hash()\n  h[[\"Januari\"]] <- \"01\"\n  h[[\"Februari\"]] <- \"02\"\n  h[[\"Maret\"]] <- \"03\"\n  h[[\"April\"]] <- \"04\"\n  h[[\"Mei\"]] <- \"05\"\n  h[[\"Juni\"]] <- \"06\"\n  h[[\"Juli\"]] <- \"07\"\n  h[[\"Agustus\"]] <- \"08\"\n  h[[\"September\"]] <- \"09\"\n  h[[\"Oktober\"]] <- \"10\"\n  h[[\"November\"]] <- \"11\"\n  h[[\"Desember\"]] <- \"12\"\n  \n  # get components of filepath to get date\n  components = str_split(filepath, \" \")\n  month = h[[components[[1]][6]]]\n  year = gsub(\"[^0-9.-].\", \"\", components[[1]][7])\n  day = gsub(\"[^0-9.-]\", \"\", components[[1]][5])\n  date = as.Date(paste(year, month, day, sep = \"-\"))\n  \n  return (date)\n}\n\n\n\n\n\n\n\nNote\n\n\n\nThe hash library and method is used to create and work with has objects. Please refer to the documentation here.\nstr_split() takes a character vector and returns a list. In this case, I used it to split up the filepath of type <string> so that I could extract the month and year. Please refer to the documentation here.\ngsub() performs replacement of the values specified in regex with the value you have specified. In this case, I simply replaced all the non-numerical values with an empty string. Please refer to the documentation here.\n\n\n\naspatial_data_processing <- function(filepath) {\n  \n  vaccine_data = read_xlsx(filepath, .name_repair = \"universal\")\n  \n  # only keep the necessary columns\n  vaccine_data = vaccine_data[, c(\"KODE.KELURAHAN\", \"KELURAHAN\", \"SASARAN\", \"BELUM.VAKSIN\")]\n\n  # remove the first row which has the aggregate sum of vaccination numbers\n  vaccine_data = vaccine_data[-1, ]\n\n  # check for duplicates and remove them\n  vaccine_data <- vaccine_data%>%\n  distinct(KELURAHAN, .keep_all = TRUE)\n  \n  # check for invalid data (missing values or NA) and convert them to 0\n  vaccine_data[is.na(vaccine_data)] <- 0\n\n  \n  # calculate vaccination rate - (sasaran - belum vaksin)/sasaran\n  vaccine_data$VACCINATION.RATE = (vaccine_data$SASARAN - vaccine_data$BELUM.VAKSIN)/vaccine_data$SASARAN\n  \n  # create date column\n  date <- get_date(filepath)\n  vaccine_data$DATE <- date\n  \n  return(vaccine_data)\n}\n\n\n\n\n\n\n\nNote\n\n\n\nThe argument .name_repair of the read_xlsx() method is used to automatically change column names to a certain format. “universal” names are unique and syntactic. Please refer to the documentation here.\nTo remove duplicate values of a certain column, we can use the distinct() method. This only works for dplyr >= 0.5. Please refer to this stackoverflow link that explains more in-depth.\nI have used the is.na() method to convert all NA values to 0. The vaccine_data wrapper is used to make sure we transform the data inside that variable. Please refer to the documentation here.\n\n\n\n\n5.1.3 Running aspatial_data_processing() on Aspatial Data\n\nsetwd(\"data/aspatial\")\n\ndflist <- lapply(seq_along(file.list), function(x) aspatial_data_processing(file.list[x]))\n\n\n\n\n\n\n\nNote\n\n\n\nseq_along() is a built-in function in R that creates a vector that contains a sequence of numbers from 1 to the object’s length. You can find an in-depth explanation of this method here.\nWe used seq_along() to create a vector so we can use lapply() (which only works on lists or vectors) to apply the aspatial_data_processing() to all the files.\n\n\n\nprocessed_aspatial_data <- ldply(dflist, data.frame)\n\nglimpse(processed_aspatial_data)\n\nRows: 3,204\nColumns: 6\n$ KODE.KELURAHAN   <chr> \"3172051003\", \"3173041007\", \"3175041005\", \"3175031003…\n$ KELURAHAN        <chr> \"ANCOL\", \"ANGKE\", \"BALE KAMBANG\", \"BALI MESTER\", \"BAM…\n$ SASARAN          <dbl> 23947, 29381, 29074, 9752, 26285, 21566, 23886, 47898…\n$ BELUM.VAKSIN     <dbl> 4592, 5319, 5903, 1649, 4030, 3950, 3344, 9382, 3772,…\n$ VACCINATION.RATE <dbl> 0.8082432, 0.8189646, 0.7969664, 0.8309065, 0.8466806…\n$ DATE             <date> 2022-02-27, 2022-02-27, 2022-02-27, 2022-02-27, 2022…\n\n\n\n\n\n\n\n\nNote\n\n\n\nHere, we use the ldply() function from the plyr library to combine and return the results in a single data frame. Please refer to the documentation here.\n\n\n\n\n5.1.4 Rename Columns for better understanding\n\nprocessed_aspatial_data <- processed_aspatial_data %>%\n  dplyr::rename(\n    village_code = KODE.KELURAHAN,\n    sub_district = KELURAHAN,\n    target = SASARAN,\n    not_vaccinated = BELUM.VAKSIN,\n    vaccination_rate = VACCINATION.RATE,\n    date = DATE\n  )\n\nWith that we have completed the Data Wrangling processes for the Aspatial Data 😎\nNow, we can finally start analysing the data proper 📈"
  },
  {
    "objectID": "take-home_ex/take-home_ex02/take-home_ex02.html#choropleth-mapping-and-analysis-task-1",
    "href": "take-home_ex/take-home_ex02/take-home_ex02.html#choropleth-mapping-and-analysis-task-1",
    "title": "Take Home Exercise 02: Spatio-temporal Analysis of COVID-19 Vaccination Trends at the Sub-district Level, DKI Jakarta",
    "section": "6 Choropleth Mapping and Analysis (Task 1)",
    "text": "6 Choropleth Mapping and Analysis (Task 1)\nIn Section 2 we looked at the three main objectives of this assignment. Let’s start with the first one. Please take note that we have already calculated the monthly vaccination rate from July 2021 to June 2022 in section 5.1.2.\nBefore we can create the choropleth maps to analyse the data we will need to combine the Spatial and Aspatial data.\n\n6.1 Combining both data frames using left_join()\nWe would like to join the two data sets on the “village_code” column. Let’s take a look at the data to see if there are any discrepancies.\n\nsetdiff(processed_aspatial_data$village_code, jakarta$village_code)\n\n[1] \"3101011003\" \"3101011002\" \"3101011001\" \"3101021003\" \"3101021002\"\n[6] \"3101021001\"\n\n\n\n\n\n\n\n\nNote\n\n\n\nsetdiff() finds the (asymmetric) difference between two collections of objects. Please refer to the documentation here.\n\n\nHm… 🤔 while this might seem confusing at first we need to remember that we removed the outer islands from the Geospatial data in Section 4.2.4 but we didn’t do that for the Aspatial data. We don’t have to do this since left_join() helps us exclude these data automatically.\nIn fact, here are what these codes mean:\n\n“3101011003” - PULAU HARAPAN\n“3101011002” - PULAU KELAPA\n“3101011001” - PULAU PANGGANG\n“3101021003” - PULAU PARI\n“3101021002” - PULAU TIDUNG\n“3101021001” - PULAU UNTUNG JAWA\n\n\njakarta_vaccination_rate <- left_join(jakarta, processed_aspatial_data, by = \"village_code\")\n\n\n\n\n\n\n\nNote\n\n\n\nleft_join() is a function from the dplyr library that returns all rows from X (i.e., jakarta) and all columns from X and Y (i.e., processed_aspatial_data). Please refer to the documentation here.\n\n\n\n\n6.2 Mapping the Distribution of Vaccination Rate for DKI Jakarta over 12 months\n\n6.2.1 Choosing the Data Classification Method\nThere are many data classification methods but the Natural Breaks (or “Jenks”) method is useful as the class breaks are iteratively created in a way that best groups similar values together and maximises the differences between classes. However this classification is not recommended for data with low variances (source).\nWe can use the Coefficient of Variation (CV) to check whether or variance is large or small. As a rule of thumb a CV >= 1 indicates a relatively high variation, while CV < 1 can be considered low (source).\n\n# create a helper function to calculate CV for the different month_year(s)\nprint_variance <- function(data) {\n  different_time_periods = unique(data$date)\n  for (time_period in different_time_periods) {\n    temp = filter(data, `date` == time_period)\n    print(paste(time_period, '-', sd(temp$vaccination_rate)/mean(temp$vaccination_rate)))\n  }\n}\n\n\n\n\n\n\n\nNote\n\n\n\npaste() is used to concatenate vectors by converting them into characters. Here we have used it to print more than 1 variable. Please refer to the documentation here.\nsd() computes the standard deviation of the values in temp$vaccination_rate. Please refer to the documentation here.\nmean() computes the mean of the values in temp$vaccination_rate. Please refer to the documentation here.\n\n\n\n# call function created in the previous code chunk\nprint_variance(jakarta_vaccination_rate)\n\n[1] \"19050 - 0.0204124688455782\"\n[1] \"19112 - 0.0195280126426937\"\n[1] \"19173 - 0.019149038400642\"\n[1] \"18961 - 0.0256946444161707\"\n[1] \"18900 - 0.0329776110706792\"\n[1] \"18870 - 0.0450062768148874\"\n[1] \"18992 - 0.0225819104823015\"\n[1] \"19023 - 0.0207887827395515\"\n[1] \"18839 - 0.0981352771312773\"\n[1] \"19082 - 0.0198328772481761\"\n[1] \"19143 - 0.0194085783913278\"\n[1] \"18931 - 0.0289456339694201\"\n\n\nFrom the above output, we can see that the CV for the vaccination_rate is pretty low. So maybe “Jenks” isn’t the best method.\nAnother data classification method is the “Equal Interval” method. As Professor Kam has mentioned in his slides, this method divides the vaccination_rate values into equally sized classes. However, we should avoid this method if the data is skewed to one end or if we have 1 or 2 really large outlier values.\nSo let’s check our data if it is skewed and if it has any outliers. For this, we will be using the skewness() and hist() methods to calculate the skewness and visualise the data respectively. Do note that as a rule of thumb if the skewness value is between -0.5 and 0.5 the data is relatively symmetrical.\n\n# create a helper function to calculate skewness for the different month_year(s)\nprint_skewness <- function(data) {\n  different_time_periods = unique(data$date)\n  for (time_period in different_time_periods) {\n    temp = filter(data, `date` == time_period)\n    print(paste(time_period, '-', moments::skewness(temp$vaccination_rate)))\n  }\n}\n\n\n\n\n\n\n\nNote\n\n\n\nskewness() computes the skewness of the data given (i.e., temp$vaccination_rate). Please refer to the documentation here.\n\n\n\n# call function created in the previous code chunk\nprint_skewness(jakarta_vaccination_rate)\n\n[1] \"19050 - -0.295699763720069\"\n[1] \"19112 - -0.265297167937898\"\n[1] \"19173 - -0.270797534250581\"\n[1] \"18961 - -0.486301892731201\"\n[1] \"18900 - -0.139155729188301\"\n[1] \"18870 - 0.0964932215434923\"\n[1] \"18992 - -0.392411450973568\"\n[1] \"19023 - -0.349709242169843\"\n[1] \"18839 - -0.0428275905167636\"\n[1] \"19082 - -0.256095796585012\"\n[1] \"19143 - -0.266302251476784\"\n[1] \"18931 - -0.378649334850257\"\n\n\nFrom the above output we can see that all the data is relatively symmetrical. 😌\nLet’s plot the histograms to check if outliers are present as well!\n\n# create a helper function to draw histogram for the different month_year(s)\nhist_plot <- function(df, time_period) {\nhist(filter(jakarta_vaccination_rate, `date` == time_period)$vaccination_rate, ylab=NULL, main=time_period, xlab=NULL)\n}\n\n\n\n\n\n\n\nNote\n\n\n\nhist() computes a histogram of the given values. Please refer to the documentation here.\nWe used this method as it is the easiest way to detect outliers (source). Especially if the dataset is quite small.\n\n\n\n\nCode\n# call function created in the previous code chunk\npar(mfrow = c(3,2))\nhist_plot(jakarta_vaccination_rate, as.Date(\"2021-07-31\"))\nhist_plot(jakarta_vaccination_rate, as.Date(\"2021-08-31\"))\nhist_plot(jakarta_vaccination_rate, as.Date(\"2021-09-30\"))\nhist_plot(jakarta_vaccination_rate, as.Date(\"2021-10-31\"))\nhist_plot(jakarta_vaccination_rate, as.Date(\"2021-11-30\"))\nhist_plot(jakarta_vaccination_rate, as.Date(\"2021-12-31\"))\n\n\n\n\n\n\n\nCode\n# call function created in the previous code chunk\npar(mfrow = c(3,2))\nhist_plot(jakarta_vaccination_rate, as.Date(\"2022-01-31\"))\nhist_plot(jakarta_vaccination_rate, as.Date(\"2022-02-27\"))\nhist_plot(jakarta_vaccination_rate, as.Date(\"2022-03-31\"))\nhist_plot(jakarta_vaccination_rate, as.Date(\"2022-04-30\"))\nhist_plot(jakarta_vaccination_rate, as.Date(\"2022-05-31\"))\nhist_plot(jakarta_vaccination_rate, as.Date(\"2022-06-30\"))\n\n\n\n\n\nFrom our findings, we can say that the data is not skewed and there are no major outliers that we need to worry about 🥳 Hence, the “Equal Interval” method will be perfect for our choropleth maps.\n\n\n6.2.2 Spatio-Temporal Mapping with custom breakpoints\nTo analyse the spatio-temporal change in vaccination rates over time we should use the same data classification method and use the same class intervals. This makes it easier for any comparisons to be made.\n\nThe Equal Interval data classification method will be utilised (as discussed in Section 6.2.1).\nWe will need to define our custom breaks to have a common classification scheme for the COVID-19 vaccination rates.\n\nLet’s take a look at the summary statistics for vaccination rates across the 12 months to determine the breakpoints:\n\n# summary stats for Vaccination Rates in July 2021\nsummary(filter(jakarta_vaccination_rate, `date` == as.Date(\"2021-07-31\"))$vaccination_rate)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.3701  0.4759  0.5134  0.5107  0.5419  0.6520 \n\n\n\n# summary stats for Vaccination Rates in November 2021\nsummary(filter(jakarta_vaccination_rate, `date` == as.Date(\"2021-11-30\"))$vaccination_rate)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7385  0.7980  0.8114  0.8094  0.8232  0.8750 \n\n\n\n# summary stats for Vaccination Rates in March 2022\nsummary(filter(jakarta_vaccination_rate, `date` == as.Date(\"2022-03-31\"))$vaccination_rate)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7766  0.8260  0.8354  0.8353  0.8453  0.8946 \n\n\n\n# summary stats for Vaccination Rates in June 2022\nsummary(filter(jakarta_vaccination_rate, `date` == as.Date(\"2022-06-30\"))$vaccination_rate)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7831  0.8318  0.8403  0.8408  0.8505  0.8978 \n\n\n\n\n\n\n\n\nNote\n\n\n\nsummary() is a generic function used to produce result summaries as shown above. Please refer to the documentation here. We used this here to find out the range of vaccination rates over the 12 months. We can see that the range is from 0.3701 to 0.8978.\n\n\nHence, breakpoints can be defined with intervals of 0.1 where values range from 0.3 to 0.9.\nSince we need to plot a map for each month let’s start by creating a generic helper function to do it.\n\n# create a helper function to plot the choropleth map\nchoropleth_plotting <- function(df, d) {\n  temp = filter(df, `date` == d)\n  tm_shape(temp)+\n  tm_fill(\"vaccination_rate\",\n          breaks = c(0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9),\n          palette = \"Blues\",\n          title = \"Vaccination Rate\",\n          legend.hist = TRUE) +\n  tm_layout(main.title = format(d, \"%b-%Y\"),\n            main.title.position = \"center\",\n            main.title.size = 0.8,\n            legend.height = 0.40, \n            legend.width = 0.25,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 1) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)\n}\n\n\n\nCode\n# call the functions for all the different months\ntmap_mode(\"plot\")\ntmap_arrange(choropleth_plotting(jakarta_vaccination_rate, as.Date(\"2021-07-31\")),\n             choropleth_plotting(jakarta_vaccination_rate, as.Date(\"2021-08-31\")))\n\n\n\n\n\n\n\nCode\n# call the functions for all the different months\ntmap_mode(\"plot\")\ntmap_arrange(choropleth_plotting(jakarta_vaccination_rate, as.Date(\"2021-09-30\")),\n             choropleth_plotting(jakarta_vaccination_rate, as.Date(\"2021-10-31\")))\n\n\n\n\n\n\n\nCode\ntmap_mode(\"plot\")\ntmap_arrange(choropleth_plotting(jakarta_vaccination_rate, as.Date(\"2021-11-30\")),\n           choropleth_plotting(jakarta_vaccination_rate, as.Date(\"2021-12-31\")))\n\n\n\n\n\n\n\nCode\ntmap_mode(\"plot\")\ntmap_arrange(choropleth_plotting(jakarta_vaccination_rate, as.Date(\"2022-01-31\")),\n             choropleth_plotting(jakarta_vaccination_rate, as.Date(\"2022-02-27\")))\n\n\n\n\n\n\n\nCode\ntmap_mode(\"plot\")\ntmap_arrange(choropleth_plotting(jakarta_vaccination_rate, as.Date(\"2022-03-31\")),\n             choropleth_plotting(jakarta_vaccination_rate, as.Date(\"2022-04-30\")))\n\n\n\n\n\n\n\nCode\ntmap_mode(\"plot\")\ntmap_arrange(choropleth_plotting(jakarta_vaccination_rate, as.Date(\"2022-05-31\")),\n             choropleth_plotting(jakarta_vaccination_rate, as.Date(\"2022-06-30\")))\n\n\n\n\n\n\n\n\n6.3 Observations from Choropleth Maps with Custom Equal Interval Breakpoints\n\n\n\nThe above gif was made by stitching the individual choropleths we created earlier on ezgif.\n\n\n\nThere was an increase in vaccination rate all over Jakarta. There doesn’t seem to be a single point from which it starts. However, it should be noted that top 3 sub-districts with the highest vaccination rates in July 2021 were Kamal Muara, Halim Perdana Kusuma, and Kelapa Gading Timur. While Halim Perdana Kusuma was still in the top 3 after a year, Kamal Muara and Kelapa Gading Timur were replaced by Srengseng Sawah and Mabggarai Selatan. Halim Perdana Kusuma remained one of the highest as it had a relatively low target of 28363.\nAfter a year, the lowest vaccination rate in a sub-district was 78%. With this, we can see that the generally the population of Jakarta was very receptive to the COVID-19 vaccines.\nAdditionally, the gif tells us that the receptiveness of the vaccine seem to spread “inwards” where the bigger sub-districts tend to reach a higher vaccination rate quicker and gaps between them (i.e., the smaller sub-districts) were “filled-in” later on. Therefore, unequal distribution of vaccination rates among the sub-districts could possibly be attributed to their size. The Indonesian government might have focused their efforts on the largely populated areas to attain herd immunity quicker.\n\nWith that, we have completed Task 1 of our Take-Home Exercise 🥳 Let’s move onto the next task."
  },
  {
    "objectID": "take-home_ex/take-home_ex02/take-home_ex02.html#local-gi-analysis-task-2",
    "href": "take-home_ex/take-home_ex02/take-home_ex02.html#local-gi-analysis-task-2",
    "title": "Take Home Exercise 02: Spatio-temporal Analysis of COVID-19 Vaccination Trends at the Sub-district Level, DKI Jakarta",
    "section": "7 Local Gi* Analysis (Task 2)",
    "text": "7 Local Gi* Analysis (Task 2)\nWhile choropleth maps are a useful visualisation tool for displaying spatial data, they have limitations when it comes to identifying clusters or hotspots of high and low vaccination rates. To do so, we can employ statistical methods such as the Local Getis-Ord G* statistic. It measures whether a particular region has values that are significantly higher or lower than its neighbouring regions.\nFirst we need to create a time-series cube using as_spacetime(). The spacetime class links a flat data set containing spatio-temporal information with the related geometry data (source).\n\n7.1 Create function to calculate Local Gi* values of the monthly vaccination rate\nTo calculate the Gi* statistic values of the vaccination rates, we need to construct the spatial weights of the study area. This is done to define the neighbourhood relationships between the sub-districts in DKI Jakarta.\nSince our study is focused on identifying clusters of high or low vaccination rates at a local scale, it is more appropriate to use an adjacency criterion. We will be defining our contiguity weights using the Queen’s (Kings) Case. Additionally, the Inverse Distance spatial weighting method will be used as it takes into account the spatial autocorrelation of the vaccination rates (source). This is to ensure the influence of neighbouring locations on a target location is accounted for.\nThen we will need to compute the local Gi* statistics using local_gstar_perm(). Our significance level will be set to 0.05.\n\ngi_values <- function (d) {\n  set.seed(1234)\n  \n  temp = filter(jakarta_vaccination_rate, `date` == d)\n  \n  # compute conguity weights\n  cw <- temp %>%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_inverse_distance(nb, geometry,\n                                  scale = 1,\n                                  alpha = 1))\n  \n  # compute Gi* values\n  HCSA <- cw %>%\n    mutate(local_Gi=local_gstar_perm(\n      vaccination_rate, nb, wt, nsim=99),\n      .before=1) %>%\n    unnest(local_Gi)\n  \n  return (HCSA)\n}\n\n\n# run the function for all the different dates\n\ndates = c(\"2021-07-31\", \"2021-08-31\", \"2021-09-30\", \"2021-10-31\", \"2021-11-30\", \"2021-12-31\", \"2022-01-31\", \"2022-02-27\", \"2022-03-31\", \"2022-04-30\", \"2022-05-31\", \"2022-06-30\")\n\ngi_output = list()\n\nfor (i in 1: 12) {\n  gi_output[[i]] = gi_values(dates[i])\n}\n\n# GI* values have been computed\n\n\n\n\n\n\n\nNote\n\n\n\nst_contiguity() is used to generate the neighbour list. Please refer to the documentation here.\nst_inverse_distance() helps calculate inverse distance weight from the neighbour list and geometry column. Please refer to the documentation here.\nlocal_gstar_perm() helps us calculate the local Gi* statistic value. Please refer to the documentation here.\nunnest() expands a list-column containing data frames into rows and columns. Please refer to the documentation here.\n\n\n\n\n7.2 Create a function to display Gi* maps\nAs requested, when creating the maps, we will need to exclude the insignificant data (i.e., p-sim < 0.05).\n\n# function to draw maps\ngi_map <- function(gi_output) {\n  tm_shape(gi_output) +\n  tm_polygons() +\n  tm_shape(gi_output %>% filter(p_sim < 0.05)) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = paste(\"Gi values of\", gi_output$date[1]),\n            main.title.size = 1)\n}\n\n\n\nCode\ntmap_mode(\"plot\")\ntmap_arrange(gi_map(gi_output[[1]]),\n             gi_map(gi_output[[2]]))\n\n\n\n\n\n\n\nCode\ntmap_mode(\"plot\")\ntmap_arrange(gi_map(gi_output[[3]]),\n             gi_map(gi_output[[4]]))\n\n\n\n\n\n\n\nCode\ntmap_mode(\"plot\")\ntmap_arrange(gi_map(gi_output[[5]]),\n             gi_map(gi_output[[6]]))\n\n\n\n\n\n\n\nCode\ntmap_mode(\"plot\")\ntmap_arrange(gi_map(gi_output[[7]]),\n             gi_map(gi_output[[8]]))\n\n\n\n\n\n\n\nCode\ntmap_mode(\"plot\")\ntmap_arrange(gi_map(gi_output[[9]]),\n             gi_map(gi_output[[10]]))\n\n\n\n\n\n\n\nCode\ntmap_mode(\"plot\")\ntmap_arrange(gi_map(gi_output[[11]]),\n             gi_map(gi_output[[12]]))\n\n\n\n\n\n\n\n7.3 Observations on Gi* Maps of monthly vaccination rate\nAs we have learnt in class, if the Gi* value is significant and positive, the location is associated with relatively high values of the surrounding locations and the opposite is true. With this information, we can make these observations:\n\nGenerally throughout the year the hot spots (green colour) seem to be more clustered compared to the cold spots (red colour). In fact, the cold spots appear to be more well spread out (with some exceptions which I will talk about in the next point). In addition, most of the hot spot sub-districts are larger than the cold spots sub-districts. In Section 6.3, I theorised that the Indonesian government might have focused their efforts on largely populated sub-districts to attain herd immunity quicker. These maps further support that point as it shows us that the higher values tend to cluster around the larger districts.\nAs mentioned, the cold spots appear to be less clustered and well spread out. However, we should note that the center of DKI, Jakarta seems to be an exception. Throughout the 12 months, the center shows a few cold spots. In Section 6.2, our maps show us that that region has the lowest vaccination rates. Hence, we can infer that there is some underlying process that is influencing the variable such as lack of quality health care systems in that area. The Indonesian government should look into this.\n\nWith that, we have completed Task 2 of our Take-Home Exercise 🥳 Let’s move onto the next task."
  },
  {
    "objectID": "take-home_ex/take-home_ex02/take-home_ex02.html#emerging-hot-spot-analysis-task-3",
    "href": "take-home_ex/take-home_ex02/take-home_ex02.html#emerging-hot-spot-analysis-task-3",
    "title": "Take Home Exercise 02: Spatio-temporal Analysis of COVID-19 Vaccination Trends at the Sub-district Level, DKI Jakarta",
    "section": "8 Emerging Hot Spot Analysis (Task 3)",
    "text": "8 Emerging Hot Spot Analysis (Task 3)\n\n8.1 Creating a Time Series Cube\nBefore we can perform our EHSA, we need to create a time series cube. The spacetime class links a flat data set containing spatio-temporal data with the related geometry. This allows us to examine changes in a variable over time while accounting for the spatial relationships between locations.\n\ntemp = select(jakarta_vaccination_rate, c(2, 8, 13, 14)) %>% st_drop_geometry()\n\n\nvr_st <- spacetime(temp, jakarta,\n                   .loc_col = \"village_code\",\n                   .time_col = \"date\")\n\nLet’s check if vr_st is a spacetime cube.\n\nis_spacetime_cube(vr_st)\n\n[1] TRUE\n\n\n\n\n\n\n\n\nNote\n\n\n\nspacetime() creates new spacetime objects. Please refer to the documentation here.\nis_spacetime_cube() determines if a spacetime object is a spatio-temporal full grid (i.e., spacetime cube). Please refer to the documentation here.\n\n\nWith the confirmation that vr_st is indeed a spacetime cube object, we can proceed with our analysis.\n\n\n8.2 Computing Gi*\n\n8.2.1 Deriving spatial weights\nWe will use the same method used in Section 7.1. We will be using the inverse distance method to identify neighbours and derive the spatial weights.\n\nvr_nb <- vr_st %>%\n  activate(\"geometry\") %>%\n  mutate(nb = include_self(st_contiguity(geometry)),\n         wt = st_inverse_distance(nb, geometry,\n                                  scale = 1,\n                                  alpha = 1),\n         .before = 1) %>%\n  set_wts(\"wt\") %>%\n  set_nbs(\"nb\")\n\n\nhead(vr_nb)\n\n   village_code sub_district.x vaccination_rate       date\n9    3173031006      KEAGUNGAN        0.5326393 2021-07-31\n21   3173031007         GLODOK        0.6164349 2021-07-31\n33   3171031003  HARAPAN MULIA        0.4973179 2021-07-31\n45   3171031006   CEMPAKA BARU        0.4671434 2021-07-31\n57   3171021001     PASAR BARU        0.5929373 2021-07-31\n69   3171021002   KARANG ANYAR        0.5224176 2021-07-31\n                                                                                                                             wt\n9                                                  0.000000000, 0.001071983, 0.001039284, 0.001417870, 0.001110612, 0.001297268\n21                             0.0010719832, 0.0000000000, 0.0015104128, 0.0009296520, 0.0017907632, 0.0007307585, 0.0008494813\n33                                           0.0000000000, 0.0008142118, 0.0009393129, 0.0013989989, 0.0012870298, 0.0006120168\n45                             0.0008142118, 0.0000000000, 0.0007692215, 0.0007293181, 0.0007540881, 0.0009920877, 0.0006784241\n57 0.0000000000, 0.0005532172, 0.0007069914, 0.0010234291, 0.0007360076, 0.0005753173, 0.0004691258, 0.0006728587, 0.0004157941\n69                             0.0005532172, 0.0000000000, 0.0006268231, 0.0018409190, 0.0014996188, 0.0008237842, 0.0007788561\n                                      nb\n9                1, 2, 39, 152, 158, 166\n21          1, 2, 39, 162, 163, 166, 171\n33               3, 4, 10, 110, 140, 141\n45          3, 4, 11, 110, 116, 118, 130\n57 5, 6, 9, 117, 119, 121, 122, 123, 158\n69           5, 6, 7, 121, 151, 158, 159\n\n\n\n\n8.2.2 Calculating the Gi* values\nWith the nb and wt columns created by the above code chunk we can calculate the Local Gi* for each location like so:\n\ngi_stars <- vr_nb %>% \n  group_by(`date`) %>% \n  mutate(gi_star = local_gstar_perm(\n    vaccination_rate, nb, wt)) %>% \n  tidyr::unnest(gi_star)\n\n\n\n\n8.3 Using Mann-Kendall Test to evaluate trends in each location\nThe Mann-Kendall statistical test is used to assess the trend of a set of data values and whether the trend (in any direction) is statistically signification (source). The test calculates a Kendall tau rank correlation coefficient (measures strength and direction of trend) and a p-value (indicates statistical significance of the trend).\nI have selected the following sub-districts as per the requirements of this assignment (I chose these sub-districts based off my analyses in Section 6.3:\n\nKOJA - 3172031001\nSRENGSENG SAWAH - 3174091002\nMANGGARAI SELATAN - 3174011006\n\n\nk <- gi_stars %>%\n  ungroup() %>%\n  filter(village_code == 3172031001) %>%\n  select(village_code, date, gi_star)\n\n\nss <- gi_stars %>%\n  ungroup() %>%\n  filter(village_code == 3174091002) %>%\n  select(village_code, date, gi_star)\n\n\nms <- gi_stars %>%\n  ungroup() %>%\n  filter(village_code == 3174011006) %>%\n  select(village_code, date, gi_star)\n\nMann-Kendall Test details:\n\nH0: There is no monotonic trend in the series.\nH1: There is a trend in the series.\nConfidence Level = 95%\n\nI have chosen this level of confidence as it strikes a balance between the level of precision and the level of certainty that is desired in the results. In fact, generally a confidence level of 99% is not commonly used in practice, given the inherent uncertainty in many research studies.\n\nSignificance Level = 0.05\n\n\nggplot(data = k,\n       aes(x = date,\n           y = gi_star)) +\n  geom_line() +\n  theme_light() +\n  ggtitle(\"KOJA\")\n\n\n\n\n\nk %>%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %>% \n  tidyr::unnest_wider(mk)\n\n# A tibble: 1 × 5\n    tau         sl     S     D  varS\n  <dbl>      <dbl> <dbl> <dbl> <dbl>\n1  1.00 0.00000834    66  66.0  213.\n\n\n\nggplot(data = ss, \n       aes(x = date, \n           y = gi_star)) +\n  geom_line() +\n  theme_light() + \n  ggtitle(\"SRENGSENG SAWAH\")\n\n\n\n\n\nss %>%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %>% \n  tidyr::unnest_wider(mk)\n\n# A tibble: 1 × 5\n    tau         sl     S     D  varS\n  <dbl>      <dbl> <dbl> <dbl> <dbl>\n1  1.00 0.00000834    66  66.0  213.\n\n\n\nggplot(data = ms, \n       aes(x = date, \n           y = gi_star)) +\n  geom_line() +\n  theme_light() + \n  ggtitle(\"MANGGARAI SELATAN\")\n\n\n\n\n\nms %>%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %>% \n  tidyr::unnest_wider(mk)\n\n# A tibble: 1 × 5\n    tau         sl     S     D  varS\n  <dbl>      <dbl> <dbl> <dbl> <dbl>\n1  1.00 0.00000834    66  66.0  213.\n\n\n\n\n8.4 Observations on Mann-Kendall Test for the 3 sub-districts selected\n\nKOJA: We see a sharp upwards trend in the first 4 months. However, after Oct 2021, we can see indications of a slowing rate of growth in the vaccination rate. Since the tau value is positive and very close to 1 we can see that there is a strong increasing trend. However, since the p-value is less than 0.05 which indicates that the trend is statistically significant and we can reject the null hypothesis that there is no trend.\nSRENGSENG SAWAH: Similar to Koja, we see a sharp upwards trend within the first 4 months. However, after Oct 2021, we can see indications of a plateauing raise. We should note that the plauteauing of the rate of increase in Srengseng Sawah seems to be worse than in Koja. The tau value is positive and close to 1 which shows a strong upwards trend. Since the p-value is below 0.05 we cannot reject the null hypothesis that there is no monotonic trend in the series.\nMANGGARAI SELATAN: Similar to Koja and Srengseng Sawah, we see a sharp upwards trend within the first 4 months. However, after Oct 2021, we can see indications that the growth in vaccination rate is tapering off. It should be notes that Manggarai Selatan has the most gradual decrease in vaccination rate increase when compares with Koja and Srengseng Sawah. We see a strong upwards trend since the tau value is positive and close to 1. Since the p-value is < 0.05 the trend is statistically significant and we can reject the null hypothesis.\nThese chart further supports our analysis done in Section 6.3 that vaccination rate increase seem to taper off over time. This is likely due to the different sub-districts meeting their vaccination targets and the relaxation of COVID-19 measures since the start of 2022 (source).\n\n\n8.4.1 Performing Emerging Hotspot Analysis\nBy using the below code, we can replicate the Mann-Kendall test on all the village_code(s) and even identify the significant ones.\nThe code used in this section was provided by Professor Kam Tin Seong in our In-Class Exercise here.\n\nehsa <- gi_stars %>%\n  group_by(village_code) %>%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %>%\n  tidyr::unnest_wider(mk)\n\n\nemerging <- ehsa %>% \n  arrange(sl, abs(tau))\n\nemerging\n\n# A tibble: 1 × 5\n    tau    sl      S       D       varS\n  <dbl> <dbl>  <dbl>   <dbl>      <dbl>\n1 0.153     0 749768 4903144 3415313408\n\n\n\n\n\n8.5 Prepare EHSA map of Gi* values of vaccination rate\nThis will be done using emerging_hotspot_analysis()\n\nset.seed (1234)\n\n\nehsa <- emerging_hotspot_analysis(\n  x = vr_st, \n  .var = \"vaccination_rate\", \n  k = 1, \n  nsim = 99\n)\n\n\nggplot(data = ehsa,\n       aes(x=classification)) +\n  geom_bar()\n\n\n\n\n\njakarta_ehsa <- jakarta %>%\n  left_join(ehsa,\n            by = join_by(village_code == location))\n\n\nehsa_sig <- jakarta_ehsa  %>%\n  filter(p_value < 0.05)\ntmap_mode(\"plot\")\ntm_shape(jakarta_ehsa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig) +\n  tm_fill(\"classification\") + \n  tm_borders(alpha = 0.4)\n\n\n\n\n\n\n8.6 Observations of Emerging Hot Spot Analysis\nThere is a large number of oscilating hotspots which indicates that most of the areas in DKI Jakarta is experiencing intermittent increases in COVID-19 vaccination. Do note that these areas tend to be the large sub-districts which further proves our points made in the earlier sections that more people have been getting vaccinated quickly in these states. This could be due to effective vaccine campaigns by the government or the population in these areas tend to be more wary of the spread of COVID-19 and have decided to get vaccinated as the vaccines are made available.\nThere is also a large number of sporadic coldspots which suggest that there is a statistically significant decrease in the vaccination rates. This means that these areas have lower vaccine uptake than in their surrounding areas. While the number of these sub-districts are lower it should still be a cause of concern as there are lower vaccination rates in these areas. Identifying and addressing these areas is important for public health officials to ensure that vaccine uptake is equitable and that vulnerable populations are not left behind in their vaccination efforts.\nIt seems that there are more sporadic coldspots clustered in the center of Jakarta while the oscilating hotspots are surrounding the these areas."
  },
  {
    "objectID": "take-home_ex/take-home_ex03/take-home_ex03.html",
    "href": "take-home_ex/take-home_ex03/take-home_ex03.html",
    "title": "Take Home Exercise 03: Predicting HDB Public Housing Resale Prices using Geographically Weighted Models",
    "section": "",
    "text": "Conventional predictive models for housing resale prices were built using the Ordinary Least Square (OLS) method, but this approach didn’t consider the presence of spatial autocorrelation and spatial heterogeneity in geographic data sets. The existence of spatial autocorrelation means that using OLS to estimate predictive housing resale pricing models could result in biased, inconsistent, or inefficient outcomes. Hence, we will be using Geographical Weighted Models (GWR) to calibrate a predictive model for housing resale prices."
  },
  {
    "objectID": "take-home_ex/take-home_ex03/take-home_ex03.html#understanding-singapores-housing-market",
    "href": "take-home_ex/take-home_ex03/take-home_ex03.html#understanding-singapores-housing-market",
    "title": "Take Home Exercise 03: Predicting HDB Public Housing Resale Prices using Geographically Weighted Models",
    "section": "2 Understanding Singapore’s Housing Market",
    "text": "2 Understanding Singapore’s Housing Market\nAfter reviewing existing literature on the Singapore Housing Market and looking through the recommendations by Professor Kam, I hypothesise that the following factors affect the price of HDB flats:\n\nStructuralLocational\n\n\n\nAge of unit\nFloor area of unit\nRemaining lease of unit\nFloor level of unit\n\n\n\n\nDistance to the nearest MRT (Mass Rapid Transit) station\nDistance to the Central Business District (CBD)\nDistance to the nearest Park\nDistance to the nearest Hospital\nDistance to the nearest Mall\nDistance to the Top Primary Schools\nDistance to nearest Hawker Centre\nNumber of Primary Schools within a 1000m radius\nNumber of clinics within a 500m radius\nNumber of childcare centres within a 350m radius\nNumber of bus stops within a 350m radius\nPercentage of Young in Planning Area\nPercentage of Working Adults in Planning Area\nPercentage of Elderly in Planning Area\n\n\n\n\n\n\n\n\n\n\nReferences for Feature Selection\n\n\n\n\n\n\nCao, Diao, M., & Wu, B. (2019). A Big Data-Based Geographically Weighted Regression Model for Public Housing Prices: A Case Study in Singapore. Annals of the American Association of Geographers, 109(1), 173–186. https://doi.org/10.1080/24694452.2018.1470925\nOng, M., Toh, D. X., & Lim, V. (2021) Econometric analysis on factors affecting HDB and private property resale prices through hedonic pricing models. SSS Student Reports (FYP/IA/PA/PI), https://hdl.handle.net/10356/147773\nPropertyGuru. (2022, June 23). 4 Reasons Your Singapore Dream Home is So Expensive (2023). PropertyGuru. Retrieved March 11, 2023, from https://www.propertyguru.com.sg/property-guides/pgf-singapore-house-prices-why-is-housing-in-singapore-so-expensive-66550\nNguyen, J. (2022, July 13). 4 Key Factors That Drive the Real Estate Market. Investopedia. Retrieved March 11, 2023, from https://www.investopedia.com/articles/mortages-real-estate/11/factors-affecting-real-estate-market.asp\nKam, T. S. (2023, February 10). Take-home exercise 3: Predicting HDB public housing resale prices using geographically weighted methods. IS415 AY2022-23T2. Retrieved March 11, 2023, from https://is415-ay2022-23t2.netlify.app/th_ex3.html"
  },
  {
    "objectID": "take-home_ex/take-home_ex03/take-home_ex03.html#data-source",
    "href": "take-home_ex/take-home_ex03/take-home_ex03.html#data-source",
    "title": "Take Home Exercise 03: Predicting HDB Public Housing Resale Prices using Geographically Weighted Models",
    "section": "3 Data Source",
    "text": "3 Data Source\n\nFig. 1: Datasets used\n\n\nType\nName\nFormat\nSource\n\n\n\n\nGeospatial\nMaster Plan 2014 Subzone Boundary (Web)\n.shp\nlink\n\n\nAspatial\nResale Flat Prices\n.csv\nlink\n\n\nGeospatial\nTrain Station\n.shp\nlink"
  },
  {
    "objectID": "take-home_ex/take-home_ex03/take-home_ex03.html#data-preparation",
    "href": "take-home_ex/take-home_ex03/take-home_ex03.html#data-preparation",
    "title": "Take Home Exercise 03: Predicting HDB Public Housing Resale Prices using Geographically Weighted Models",
    "section": "4 Data Preparation",
    "text": "4 Data Preparation\n\n4.1 Install R Packages\n\n\nCode for Package Installation\npacman::p_load(olsrr, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary, onemapsgapi, rvest)\n\n\n\n\n4.2 Prepare Geospatial Data\nWe will need to prepare the shapefiles (.shp) for most of the features we have selected. Here’s how I did it:\n\n\n\n\n\n\nMethods Used To Extract Data:\n\n\n\n\n\nOneMapSG API\nThe data was extracted by calling the OpenMapSG API. Most API endpoints in OneMapSG require a token. Please register for one here if you would like to perform some of the steps shown below.\nWebscrapped From Government Websites Using Rvest\nThe data was extracted from government websites using the rvest package. The OneMapSG API was then used on the names of the facilities extracted to get the longitude and latitude.\nShapefiles From LTA or data.gov.sg\nThe shapefiles were directly downloaded from LTA or data.gov.sg\n\n\n\n\nParksHospitalsMRT & LRT StationsPrimary SchoolsHawker CentresClinicsChildcare CentresBus Stops\n\n\n\n# search for themes related to \"parks\"\npark_themes = onemapsgapi::search_themes(token, \"parks\")\n\n# pick a suitable theme (i.e., \"Parks\") and use get_themes() to get the location\n# data using the queryname (i.e., \"nationalparks\")\nparks_tibble = onemapsgapi::get_theme(token, \"nationalparks\")\n\n# convert it into an sf object and take note that the data is using WGS84\nparks_sf = st_as_sf(parks_tibble, coords=c(\"Lng\", \"Lat\"), crs=4326)\n  \n  \n# since the API token is only valid for a few days, let's save this into a\n# shapefile for recurrent use\n# the sf library's st_write() helps us do this\nst_write(parks_sf, dsn=\"data/geospatial\", layer=\"parks\", driver= \"ESRI Shapefile\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n# search for themes related to \"hawker\"\nhawker_themes = onemapsgapi::search_themes(token, \"hawker\")\n\n# pick a suitable theme (i.e., \"Hawker Centres\") and use get_themes() to get the location\n# data using the queryname (i.e., \"hawkercentre\")\nhawker_tibble = onemapsgapi::get_theme(token, \"hawkercentre\")\n\n# convert it into an sf object and take note that the data is using WGS84\nhawker_sf = st_as_sf(hawker_tibble, coords=c(\"Lng\", \"Lat\"), crs=4326)\n  \n  \n# since the API token is only valid for a few days, let's save this into a\n# shapefile for recurrent use\n# the sf library's st_write() helps us do this\nst_write(hawker_sf, dsn=\"data/geospatial\", layer=\"hawker\", driver= \"ESRI Shapefile\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReferences for Geospatial Data Preparation\n\n\n\n\n\n\nMegan Sim Tze Yen’s ‘Take-Home Exercise 3: Hedonic Pricing Models for Resale Prices of Public Housing in Singapore’\nOneMapSGAPI by Jolene Lim\nWeb Scraping in R: The Complete Guide 2023\n\n\n\n\n\ntoken = onemapsgapi::get_token(\"guganesh99@gmail.com\", \"Happy1999*@!~#$%\")\n\n# search for themes related to \"hawker\"\nsch_themes = onemapsgapi::search_themes(token, \"education\", \"schools\", \"primary\")\n\n# pick a suitable theme (i.e., \"Hawker Centres\") and use get_themes() to get the location\n# data using the queryname (i.e., \"hawkercentre\")\n# hawker_tibble = onemapsgapi::get_theme(token, \"hawkercentre\")\n\n# convert it into an sf object and take note that the data is using WGS84\n#hawker_sf = st_as_sf(hawker_tibble, coords=c(\"Lng\", \"Lat\"), crs=4326)\n  \n  \n# since the API token is only valid for a few days, let's save this into a\n# shapefile for recurrent use\n# the sf library's st_write() helps us do this\n#st_write(hawker_sf, dsn=\"data/geospatial\", layer=\"hawker\", driver= \"ESRI Shapefile\")\n\n\n# hawker_sf = st_read(dsn = \"data/geospatial\", layer=\"hawker\")\n# tmap_mode(\"view\")\n# tm_shape(hawker_sf) +\n#   tm_dots(col=\"purple\")\n\n\n# clinic_themes = onemapsgapi::search_themes(token, \"health\")"
  },
  {
    "objectID": "in-class_ex/in-class_ex09/in-class_ex09.html",
    "href": "in-class_ex/in-class_ex09/in-class_ex09.html",
    "title": "In-Class Exercise 9",
    "section": "",
    "text": "Installing Packages in R\npacman::p_load(sf, spdep, GWmodel, SpatialML, tidyverse, \n               tmap, ggpubr, olsrr, devtools, tidymodels)"
  },
  {
    "objectID": "in-class_ex/in-class_ex09/data/geospatial/MPSZ-2019.html",
    "href": "in-class_ex/in-class_ex09/data/geospatial/MPSZ-2019.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "in-class_ex/in-class_ex09/in-class_ex09.html#datasets",
    "href": "in-class_ex/in-class_ex09/in-class_ex09.html#datasets",
    "title": "In-Class Exercise 9",
    "section": "2 Datasets",
    "text": "2 Datasets\nAspatial: .rds file - more compact and faster for retrieval\nGeospatial: .shp file - MP14_SUBZONE_WEB_PL and MPSZ-2019 (this is for take-home 3, it has most of the planning subzone information)"
  },
  {
    "objectID": "in-class_ex/in-class_ex09/in-class_ex09.html#preparing-data",
    "href": "in-class_ex/in-class_ex09/in-class_ex09.html#preparing-data",
    "title": "In-Class Exercise 9",
    "section": "3 Preparing Data",
    "text": "3 Preparing Data\n\n3.1 Reading rds data file to sf dataframe\n\n\nCode to read .rds file\n# you should keep your 'combined' dataset in .rds format (faster to retrieve)\nmdata <- read_rds(\"data/aspatial/mdata.rds\")\n\n\n\n\n3.2 Data Sampling\n\n\nCode for Data Sampling\n# set seed value to ensure procedure is reproducible\nset.seed(1234)\n\n# split the data into 65% training and 35% test\nresale_split <- initial_split(mdata,\n                              prop = 6.5/10,)\ntrain_data <- training(resale_split)\ntest_data <- testing(resale_split)\n\n\n\n\nCode for writing train and test into rds files\n# write the outputs into rds files - for easier access and data management\nwrite_rds(train_data, \"data/model/train_data.rds\")\nwrite_rds(test_data, \"data/model/test_data.rds\")"
  },
  {
    "objectID": "in-class_ex/in-class_ex09/in-class_ex09.html#building-a-non-spatial-multiple-linear-regression",
    "href": "in-class_ex/in-class_ex09/in-class_ex09.html#building-a-non-spatial-multiple-linear-regression",
    "title": "In-Class Exercise 9",
    "section": "4 Building a non spatial multiple linear regression",
    "text": "4 Building a non spatial multiple linear regression\n\n\nCode for building the OLS model\nprice_mlr <- lm(resale_price ~ floor_area_sqm +\n                    storey_order + remaining_lease_mths +\n                    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                    PROX_MRT + PROX_PARK + PROX_MALL +\n                    PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                    WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                    WITHIN_1KM_PRISCH,\n                  data = train_data)\n\nsummary(price_mlr)\n\n\n\nCall:\nlm(formula = resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths + \n    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK + \n    PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + \n    WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH, \n    data = train_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-205193  -39120   -1930   36545  472355 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(>|t|)    \n(Intercept)              107601.073  10601.261  10.150  < 2e-16 ***\nfloor_area_sqm             2780.698     90.579  30.699  < 2e-16 ***\nstorey_order              14299.298    339.115  42.167  < 2e-16 ***\nremaining_lease_mths        344.490      4.592  75.027  < 2e-16 ***\nPROX_CBD                 -16930.196    201.254 -84.124  < 2e-16 ***\nPROX_ELDERLYCARE         -14441.025    994.867 -14.516  < 2e-16 ***\nPROX_HAWKER              -19265.648   1273.597 -15.127  < 2e-16 ***\nPROX_MRT                 -32564.272   1744.232 -18.670  < 2e-16 ***\nPROX_PARK                 -5712.625   1483.885  -3.850 0.000119 ***\nPROX_MALL                -14717.388   2007.818  -7.330 2.47e-13 ***\nPROX_SUPERMARKET         -26881.938   4189.624  -6.416 1.46e-10 ***\nWITHIN_350M_KINDERGARTEN   8520.472    632.812  13.464  < 2e-16 ***\nWITHIN_350M_CHILDCARE     -4510.650    354.015 -12.741  < 2e-16 ***\nWITHIN_350M_BUS             813.493    222.574   3.655 0.000259 ***\nWITHIN_1KM_PRISCH         -8010.834    491.512 -16.298  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 61650 on 10320 degrees of freedom\nMultiple R-squared:  0.7373,    Adjusted R-squared:  0.737 \nF-statistic:  2069 on 14 and 10320 DF,  p-value: < 2.2e-16\n\n\nCode for building the OLS model\n# explanations of f-statistic, etc. not important for predictive model\n\n\n\n\nCode to write price_mlr into rds file\n# write the data into an rds file (fitted data = estimated data, etc...)\nwrite_rds(price_mlr, \"data/model/price_mlr.rds\")"
  },
  {
    "objectID": "in-class_ex/in-class_ex09/in-class_ex09.html#gwr-predictive-method",
    "href": "in-class_ex/in-class_ex09/in-class_ex09.html#gwr-predictive-method",
    "title": "In-Class Exercise 9",
    "section": "5 GWR Predictive Method",
    "text": "5 GWR Predictive Method\n\n5.1 Coverting the sf dataframe to SpatialPointDataFrame\n\n\nCode to convert train_data into SpatialPointDataFrame\ntrain_data_sp <- as_Spatial(train_data)\ntrain_data_sp\n\n\nclass       : SpatialPointsDataFrame \nfeatures    : 10335 \nextent      : 11597.31, 42623.63, 28217.39, 48741.06  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 17\nnames       : resale_price, floor_area_sqm, storey_order, remaining_lease_mths,          PROX_CBD,     PROX_ELDERLYCARE,        PROX_HAWKER,           PROX_MRT,          PROX_PARK,   PROX_GOOD_PRISCH,        PROX_MALL,            PROX_CHAS,     PROX_SUPERMARKET, WITHIN_350M_KINDERGARTEN, WITHIN_350M_CHILDCARE, ... \nmin values  :       218000,             74,            1,                  555, 0.999393538715878, 1.98943787433087e-08, 0.0333358643817954, 0.0220407324774434, 0.0441643212802781, 0.0652540365486641,                0, 6.20621206270077e-09, 1.21715176356525e-07,                        0,                     0, ... \nmax values  :      1186888,            133,           17,                 1164,  19.6500691667807,     3.30163731686804,   2.86763031236184,   2.13060636038504,   2.41313695915468,   10.6223726149914, 2.27100643784442,    0.808332738794272,     1.57131703651196,                        7,                    20, ..."
  },
  {
    "objectID": "in-class_ex/in-class_ex09/in-class_ex09.html#prepare-coordinates-data",
    "href": "in-class_ex/in-class_ex09/in-class_ex09.html#prepare-coordinates-data",
    "title": "In-Class Exercise 9",
    "section": "6 Prepare coordinates data",
    "text": "6 Prepare coordinates data\n\n6.1 Extracting coordinates data\n\n\nCode to get coordinate data so ranger package can be used for RF\n# ranger doesn't understand simple feature dataframe\ncoords <- st_coordinates(mdata)\ncoords_train <- st_coordinates(train_data)\ncoords_test <- st_coordinates(test_data)\n\n\n\n\nCode to write coords data into rds files\n# write all output into rds for future use\ncoords_train <- write_rds(coords_train, \"data/model/coords_train.rds\")\ncoords_test <- write_rds(coords_test, \"data/model/coords_test.rds\")\n\n\n\n\n6.2 Dropping Geometry Field\n\n\nCode to drop geometry column\n# drop geometry column of the sf dataframe\ntrain_data <- train_data %>%\n  st_drop_geometry()"
  },
  {
    "objectID": "in-class_ex/in-class_ex09/in-class_ex09.html#calibrating-random-forest",
    "href": "in-class_ex/in-class_ex09/in-class_ex09.html#calibrating-random-forest",
    "title": "In-Class Exercise 9",
    "section": "7 Calibrating Random Forest",
    "text": "7 Calibrating Random Forest\n\n\nCode to calibrate RF\nset.seed(1234)\n\nrf <- ranger(resale_price ~ floor_area_sqm +\n                    storey_order + remaining_lease_mths +\n                    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                    PROX_MRT + PROX_PARK + PROX_MALL +\n                    PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                    WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                    WITHIN_1KM_PRISCH,\n                  data = train_data)\n\nprint(rf)\n\n\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths +      PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK +      PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      10335 \nNumber of independent variables:  14 \nMtry:                             3 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       728602496 \nR squared (OOB):                  0.9495728 \n\n\n\n\n\n\n\n\nTo note:\n\n\n\n\n\n\nNumber of trees = 500 (default) - i.e., number of subsets\nTarget node size = 5 (default) [you may increase if you want]\nMSE = 728602496 [Mean Squared Error] = RSS != Residual Standard Error in OLS model (for comparison please refer to sqroot of MSE)"
  },
  {
    "objectID": "in-class_ex/in-class_ex09/in-class_ex09.html#calibrating-geographically-weighted-random-forest",
    "href": "in-class_ex/in-class_ex09/in-class_ex09.html#calibrating-geographically-weighted-random-forest",
    "title": "In-Class Exercise 9",
    "section": "8 Calibrating Geographically Weighted Random Forest",
    "text": "8 Calibrating Geographically Weighted Random Forest\n\n\nCode to calibrate GWRF\n# eval:false to render the doc for submission\n\n# set seed\nset.seed(1234)\n\n# calibrate the model\ngwrf_adaptive <- grf(formula = resale_price ~ floor_area_sqm +\n                    storey_order + remaining_lease_mths +\n                    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                    PROX_MRT + PROX_PARK + PROX_MALL +\n                    PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                    WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                    WITHIN_1KM_PRISCH,\n                  dframe = train_data,\n                  bw = 55,\n                  kernel = \"adaptive\",\n                  coords = coords_train)\n\n# if kernel is adaptive, bw is number of observations (has to be integer)\n# if kernel is fixed, bw is distance (real number)\n# how to determine bw? -> borrow from GWR method, or you can use grf.bw(formula, dataset, kernel, coords)\n\n# if I want to know which models contribute the most, go see: gwrf_adaptive$Global.Model$variable.importance\n  # vi_df <- as.data.frame(gwrf_adaptive$Global.Model$variable.importance) [you can put this into your report using gtsummary()]\n\n\n\n\nCode to write the GWRF model in .rds file\n# write the output into rds file for future use\nwrite_rds(gwrf_adaptive, \"data/model/gwrf_adaptive.rds\")"
  },
  {
    "objectID": "in-class_ex/in-class_ex09/in-class_ex09.html#predicting-using-test-data",
    "href": "in-class_ex/in-class_ex09/in-class_ex09.html#predicting-using-test-data",
    "title": "In-Class Exercise 9",
    "section": "9 Predicting using test data",
    "text": "9 Predicting using test data\n\n9.1 Preparing the test data\n\n\nCode to prepare test data by including coords and dropping geometry\n# combine test data with its corresponding coordinates data\ntest_data <- cbind(test_data, coords_test) %>%\n  st_drop_geometry()\n\n# X and Y columns are in metres\n\n\n\n\n9.2 Predicting with test data\n\n\nCode to make predictions\n# put eval as false to render this code for submission\n# local.w helps to weight the local model compared to the global weight\ngwrf_pred <- predict.grf(gwrf_adaptive,\n                         test_data,\n                         x.var.name=\"X\",\n                         y.var.name=\"Y\",\n                         local.w=1,\n                         global.w=0)\n\n# output is a vector\n\n\n\n\n9.3 Convert prediction output into a dataframe\n\n\nCode to convert vector into dataframe\n# eval: false as I don't want this to run when rendering\n# we do this so we can combine the predicted values with the coordinates\ngwrf_pred_df <- as.data.frame(gwrf_pred)\n\n\n\n\n\n\n\n\nLesson Material\n\n\n\n\n\nWhat is Geospatial Predictive Modelling?\n\nRooted in the principle that the occurrences of events are limited in distribution.\nGeographically referenced data: occurreneces are neither uniform nor randomly distributed across space - geographical factors such as infrastructure influence where they occur.\n\nGeospatial Predictive Modelling - attempts to describe those influences by spatially correlating occurrences with environmental factors that represent those influences.\nRefer to Slide 5 to see difference between Explanatory and Predictive Models (focus should be on accuracy of the model)\n\n\n\nData Sampling - training, validation, and test dataset (for our case, validation not required)\n\n\ntraining data to develop classifiers\ntest data to test classifier\n\nModel Fitting - build different models or same model with different calibration methods (use AIC and BIC to fit the best models)\nModel Comparison - since there is a wide choice of classifiers and predictive methods we can use statistical methods such as: MSE, AIC, and BIC to compare models. Using training data [use test data]\nRecursive Partitioning: Random Forest (CART)\nAs an ML technique, it builds a model based on training dataset and uses that to make predictions or decisions.\n\n\n\nDo note that it takes multiple iterations of “Learn Model” to achieve stable results.\n\n\nIf you are using categorical data: Classification Trees (split based on weighted average entropy, must be mutually exhaustive), else it will be Regression Trees (using average for splitting rule).\nOrdinal vs Nominal: If your data is ordinal\nTo avoid over-fitting: minimum number of membership should be 5 (set restrictions so you don’t split all the way).\nRandom Forest:\n\nCreate subsets from our main dataset (subsets here refer to randomising the entire dataset and having multiple versions of it)\nUse each of them to calibrate the model\nThen I combine them together to derive a more stable model (Ensemble Method)\n\nIntroducing Geographically Weighted Random Forest\nNow we explicitly take the neighbour into consideration (not calibrate the global model, each of the properties you define which neighbours you want (i.e., adaptive or fixed mtd) and you use them to create the predictive model).\nSource: Lesson 9: Geographically Weighted Random Forest"
  }
]