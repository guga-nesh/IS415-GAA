---
title: "Hands-On Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method"
date: "06 March 2023"
date-modified: "`r Sys.Date()`"
number-sections: true
format: html
execute: 
  echo: true
  eval: true
  warning: false
editor: visual
---

## Exercise Overview

**Geographically weighted regression (GWR)** is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and an outcome of interest (also known as dependent variable). In this hands-on exercise, you will learn how to build [hedonic pricing](https://www.investopedia.com/terms/h/hedonicpricing.asp) models by using GWR methods. The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and locational data.

## Overview Of Data Used

| Type       | Name                  | Format | Description                                           |
|-------------|-------------|-------------|----------------------------------|
| Geospatial | MP14_SUBZONE_WEB_PL   | .shp   | URA Master Plan subzone boundary in shapefile format. |
| Aspatial   | condo_resale_2015.csv | .csv   | Specific details of individual Condo units in 2015.   |

## Leading relevant packages

-   [olsrr](https://olsrr.rsquaredacademy.com/) - for building OLS and performing diagnostic tests

-   [GWmodel](https://cran.r-project.org/web/packages/GWmodel/) - for calibrating geographical weighted family of models

    ::: {.callout-note collapse="true"}
    *Provides a collection of localised spatial statistical methods, namely: GW summary statistics, GW principal components analysis, GW discriminant analysis and various forms of GW regression; some of which are provided in basic and robust (outlier resistant) forms. Commonly, outputs or parameters of the GWmodel are mapped to provide a useful exploratory tool, which can often precede (and direct) a more traditional or sophisticated statistical analysis.*
    :::

-   [corrplot](https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html) - for multivariate data visualisation and analysis

-   **sf** - spatial data handling

-   **tidyverse** (**readr**, **ggplot2**, and **dyplyr**) - for handling attribute data

-   **tmap** - for choropleth mapping

```{r}
#| code-fold: true
#| code-summary: Show code
# do not load corrplot onto our memory using pacman

pacman::p_load(olsrr, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary)
```

## Geospatial Data Wrangling

```{r}
#| code-fold: true
#| code-summary: Show code

# import and update CRS information
mpsz = st_read(dsn = "data/geospatial", layer = "MP14_SUBZONE_WEB_PL") %>%
  st_transform(crs = 3414)

# check crs
st_crs(mpsz)
```

```{r}
#| code-fold: true
#| code-summary: Show code

# reveal the extent of mpsz by using st_bbox()
st_bbox(mpsz)
```

## Aspatial Data Wrangling

### Import & View Data

```{r}
#| code-fold: true
#| code-summary: Show code

# read file into a tibble data frame
condo_resale = read_csv("data/aspatial/Condo_resale_2015.csv")

# see glimpse
print(glimpse(condo_resale))

# see data in XCOORD column
print(head(condo_resale$LONGITUDE))

# see data in YCOORD column
print(head(condo_resale$LATITUDE))

# see summary of data
print(summary(condo_resale))
```

### Convert Data Frame into sf Object

```{r}
#| code-fold: true
#| code-summary: Show code

# transform df into sf object and use st_transform() to update the CRS
condo_resale.sf <- st_as_sf(condo_resale,
                            coords = c("LONGITUDE", "LATITUDE"),
                            crs=4326) %>%
  st_transform(crs=3414)

# view data
head(condo_resale.sf)
```

## Exploratory Data Analysis

We will be using **ggplot2** to visualise the distribution of the data. This is mainly to check for skewness and perform any transformation if necessary.

**Transform the dependent variable.**

```{r}
#| code-fold: true
#| code-summary: Show code

# let's check out the dependent variable first
before <- ggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

# since the data is right skewed, more condo units are transacted at a lower relatively lower price. We can also normalise the data by using log()
condo_resale.sf <- condo_resale.sf %>%
  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))

# view LOG_SELLING_PRICE
after <- ggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

# use ggpubr's ggarrange() to view the change
ggarrange(before, after, ncol=2)
```

**View the other features in the data set.**

```{r}
#| code-fold: true
#| code-summary: Show code

AREA_SQM <- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + 
  geom_histogram(bins=20, color="black", fill="light blue")

AGE <- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_CBD <- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_CHILDCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + 
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_ELDERLYCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_URA_GROWTH_AREA <- ggplot(data=condo_resale.sf, 
                               aes(x= `PROX_URA_GROWTH_AREA`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_HAWKER_MARKET <- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_KINDERGARTEN <- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_MRT <- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_PARK <- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_PRIMARY_SCH <- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_TOP_PRIMARY_SCH <- ggplot(data=condo_resale.sf, 
                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

ggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, 
          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,
          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  
          ncol = 3, nrow = 4)
```

**Reveal geospatial distribution of condo resale prices in Singapore.**

```{r}
#| code-fold: true
#| code-summary: Show code

# need to fix tmap_options - was not included in the Hands-On Document so not sure why this error is occurring here...
tmap_options(check.and.fix = TRUE)
```

```{r}
#| code-fold: true
#| code-summary: Show code

# turn on the interactive mode of tmap
tmap_mode("view")

# we use tm_dots() instead of bubbles
# set.zoom.limits argument sets the min and max zoom level to 11 and 14 respectively
tm_shape(mpsz)+
  tm_polygons() +
tm_shape(condo_resale.sf) +  
  tm_dots(col = "SELLING_PRICE",
          alpha = 0.6,
          style="quantile") +
  tm_view(set.zoom.limits = c(11,14))

# turn tmap mode back to plot
tmap_mode("plot")
```

We can see that most of the condos are around the southern region of Singapore.

## Hedonic Pricing Model using R

We will be using `lm()` to build the hedonic pricing models for condo resale units.

### Simple Linear Regression Method

```{r}
#| code-fold: true
#| code-summary: Show code

# build an SLR using SELLING_PRICE as y and AREA_SQM as x
# lm() returns class lm
condo.slr <- lm(formula=SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)
```

```{r}
#| code-fold: true
#| code-summary: Show code

# use summary() and anova() to get summary and analysis of variance table of the results
summary(condo.slr)
print("-----------------")
anova(condo.slr)
```

Hence, SELLING_PRICE can be explained using: $y = -258121.1 + 14719x1$

R-squared of 0.4518 reveals that the simple regression model built is able to explain about 45% of the resale prices. Since p-value is less than 0.0001 we will reject the null huypothesis that mean is a good estimator of SELLING_PRICE. This allows us to infer that the SLR model above is a good estimator of SELLING_PRICE.

Additionally, the report reveals that the p-values of both the estimates of the Intercept and AREA_SQM are smaller than 0.001. Hence, the null hypothesis that B0 and B1 are equal to 0 will be rejected. Hence, we can inter that B0 and B1 are good parameter estimates.

**Visualising the best fit curve on a scatterplot using `lm()`**

```{r}
#| code-fold: true
#| code-summary: Show code


ggplot(data=condo_resale.sf,  
       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +
  geom_point() +
  geom_smooth(method = lm)
```

The figure also reveals that there are a few statistical outliers with relatively high selling prices.

### Multiple Linear Regression Method

**Visualising the relationships of the independent variables**

```{r}
#| code-fold: true
#| code-summary: Show code

# this is done to ensure that the x variables used are not highly correlated to each other (quality of model will be compromised)
# we will use a correlation matrix to visualise this - the order argument is very important for mining the hidden structure and pattern of the matrix. Four main methods in corrplot: "AOE", "FPC", "hclust", "alphabet". AOE uses angular order of the eigenvectors method suggested by Michael Friendly.

corrplot::corrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = "AOE",
         tl.pos = "td", tl.cex = 0.5, method = "number", type = "upper")
```

From the scatterplot matrix it is clear that **FREEHOLD** is highly correlated to **LEASE_99YEAR**. Hence, we will remove one of them: **LEASE_99YEAR**.

**Building a hedomic pricing model using MLR method.**

```{r}
#| code-fold: true
#| code-summary: Show code

# using lm() to get the formula
condo.mlr <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + 
                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +
                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + 
                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + 
                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + 
                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, 
                data=condo_resale.sf)
summary(condo.mlr)
```

From the report above, we can clearly see that not all the independent variables are statistically significant. We will revise the model by removing the statistically insignificant variables.

**Preparing Publication Quality Table**

-   olsrr method

```{r}
#| code-fold: true
#| code-summary: Show code

# statistically insignificant variables removed
condo.mlr1 <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + 
                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +
                   PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + 
                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL    + PROX_BUS_STOP + 
                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,
                 data=condo_resale.sf)
ols_regress(condo.mlr1)
```

-   [gtsummary](https://www.danieldsjoberg.com/gtsummary/) method

```{r}
#| code-fold: true
#| code-summary: Show code

# gtsummary package provides an elegant and flexible way to create publication-ready summary tables in R
# model statistics can be included in the report by adding the add_glance_table() or add_glance_source_note() methods.
tbl_regression(condo.mlr1, 
               intercept = TRUE) %>% 
  add_glance_source_note(
    label = list(sigma ~ "\U03C3"),
    include = c(r.squared, adj.r.squared, 
                AIC, statistic,
                p.value, sigma))
```

**Checking for multicolinearity**

olsrr provides a collection of many useful methods for building better multiple linear regression models:

-   comprehensive regression output

-   residual diagnostics

-   measures of influence

-   heteroskedasticity tests

-   collinearity diagnostics

-   model fit assessment

-   variable contribution assessment

-   variable selection procedures

```{r}
#| code-fold: true
#| code-summary: Show code

# we will use ols_vif_tol() to test if there are signs of multicollinearity
ols_vif_tol(condo.mlr1)
```

Since all VIF \< 10, we can safely conclude that there are no signs of multicollinearity among the independent variables.

**Test for Non-Linearity**

```{r}
#| code-fold: true
#| code-summary: Show code

# it is important for us to test the assumption of linearity and additivity of the relationship between dependent and independent variables
ols_plot_resid_fit(condo.mlr1)
```

The figure above reveals that most of the data points are scattered around the 0 line. Hence, we can safely conclude that the relationships between the dependent variable and independent variables are linear.

**Test for Normality Assumption**

```{r}
#| code-fold: true
#| code-summary: Show code

ols_plot_resid_hist(condo.mlr1)

# for a more formal statistical test method - p-values of the 4 tests are way smaller than the alpha value of 0.05 hence we reject the H0 and infer that there is sufficient statistical evidence that residuals are not normally distributed
ols_test_normality(condo.mlr1)
```

The figure reveals that the residual of the MLR model resembles a normal distribution.

**Testing for Spatial Autocorrelation**

The hedonic model uses geographically referenced attributes. Hence, it is important to visualise the residuals of the hedonic pricing model.

```{r}
#| code-fold: true
#| code-summary: Show code

# to perform spatial autocorrelation test, we need to convert the sf data frame into a SpatialPointsDataFrame
mlr.output <- as.data.frame(condo.mlr1$residuals)
condo_resale.res.sf <- cbind(condo_resale.sf, 
                        condo.mlr1$residuals) %>%
rename(`MLR_RES` = `condo.mlr1.residuals`)

# we make this conversion since spdep package can only process sp conformed spatial data objects
condo_resale.sp <- as_Spatial(condo_resale.res.sf)
condo_resale.sp
```

```{r}
#| code-fold: true
#| code-summary: Show code

tmap_mode("view")
tm_shape(mpsz)+
  tmap_options(check.and.fix = TRUE) +
  tm_polygons(alpha = 0.4) +
tm_shape(condo_resale.res.sf) +  
  tm_dots(col = "MLR_RES",
          alpha = 0.6,
          style="quantile") +
  tm_view(set.zoom.limits = c(11,14))
tmap_mode("plot")
```

::: {.callout-note collapse="true"}
Need to check with prof, do we say there is spatial autocorrelation because the residual changes based on the spaces?
:::

The figure above reveals that there is a sign of spatial autocorrelation. To proof that our observation is indeed true, the Moran's I test will be performed.

**Moran's I Test**

```{r}
#| code-fold: true
#| code-summary: Show code

# compute distance-based weight matrix
nb <- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)
summary(nb)

# convert the neighbours list into spatial weights
nb_lw <- nb2listw(nb, style = 'W')
summary(nb_lw)

# perform Moran's I test
lm.morantest(condo.mlr1, nb_lw)
```

The Global Moran\'s I test for residual spatial autocorrelation shows that it\'s p-value is less than 0.00000000000000022 which is less than the alpha value of 0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.

Since the Observed Global Moran I = 0.1424418 which is greater than 0, we can infer than the residuals resemble cluster distribution.

## Building Hedonic Pricing Models using GWmodel

### Building Fixed Bandwidth GWR Model

```{r}
#| code-fold: true
#| code-summary: Show code

# there are 2 approaches to figuring out the optimal fixed bandwidth to use: CV and AIC (they are used to determine the stopping rule)
bw.fixed <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + 
                     PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + 
                     PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + 
                     PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + 
                     FAMILY_FRIENDLY + FREEHOLD, 
                   data=condo_resale.sp, 
                   approach="CV", 
                   kernel="gaussian", 
                   adaptive=FALSE, 
                   longlat=FALSE)
```

```{r}
#| code-fold: true
#| code-summary: Show code

# from the code above we can see that the recommended bandwidth is 971.3405m (why metres?)
# we can use that to calibrate our gwr model

gwr.fixed <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + 
                         PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + 
                         PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + 
                         PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + 
                         FAMILY_FRIENDLY + FREEHOLD, 
                       data=condo_resale.sp, 
                       bw=bw.fixed, 
                       kernel = 'gaussian', 
                       longlat = FALSE)

gwr.fixed
```

The model shows that the AICc of the GWR is 42263.61 which is significantly smaller than the global multiple linear regression model of 42967.1.

### Building Adaptive Bandwidth GWR Model

```{r}
#| code-fold: true
#| code-summary: Show code

# take note that the adaptive argument is true
bw.adaptive <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + 
                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + 
                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + 
                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + 
                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, 
                      data=condo_resale.sp, 
                      approach="CV", 
                      kernel="gaussian", 
                      adaptive=TRUE, 
                      longlat=FALSE)

gwr.adaptive <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + 
                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + 
                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + 
                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + 
                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, 
                          data=condo_resale.sp, bw=bw.adaptive, 
                          kernel = 'gaussian', 
                          adaptive=TRUE, 
                          longlat = FALSE)

gwr.adaptive
```

The report shows that the AICc of the adaptive distance GWR is 41982.22 which is even smaller than the AICc of the fixed distance gwr of 42263.61.

## Visualising GWR Output

In addition to regression residuals, the output feature class table includes fields for **observed** and **predicted y-values**, **condition number** (Helps evaluate local collinearity. Results associated with condition numbers larger than 30 may be unreliable), **local R2** (values from 0 to 1 - they indicate how well the local regression model fits observed y values), and **explanatory variable coefficients** and **standard errors** (Measures the reliability of each coefficient estimate. Confidence in those estimates are higher when standard errors are small in relation to the actual coefficient values. Large standard errors may indicate problems with local collinearity).

```{r}
#| code-fold: true
#| code-summary: Show code

# convert sdf into sf data.frame
condo_resale.sf.adaptive <- st_as_sf(gwr.adaptive$SDF) %>%
  st_transform(crs=3414)

condo_resale.sf.adaptive.svy21 <- st_transform(condo_resale.sf.adaptive, 3414)
condo_resale.sf.adaptive.svy21  

gwr.adaptive.output <- as.data.frame(gwr.adaptive$SDF)
condo_resale.sf.adaptive <- cbind(condo_resale.res.sf, as.matrix(gwr.adaptive.output))

glimpse(condo_resale.sf.adaptive)
```

```{r}
#| code-fold: true
#| code-summary: Show code

# see the summary stats of the predicted/estimated values of the model
summary(gwr.adaptive$SDF$yhat)
```

**Visualising R2**

```{r}
#| code-fold: true
#| code-summary: Show code

# create interactive point symbol map
tmap_mode("view")
tm_shape(mpsz)+
  tm_polygons(alpha = 0.1) +
tm_shape(condo_resale.sf.adaptive) +  
  tm_dots(col = "Local_R2",
          border.col = "gray60",
          border.lwd = 1) +
  tm_view(set.zoom.limits = c(11,14))
tmap_mode("plot")
```

::: {.callout-note collapse="true"}
Why visualise R\^2?
:::

**Visualising coefficient estimates**

```{r}
#| code-fold: true
#| code-summary: Show code


tmap_mode("view")
AREA_SQM_SE <- tm_shape(mpsz)+
  tm_polygons(alpha = 0.1) +
tm_shape(condo_resale.sf.adaptive) +  
  tm_dots(col = "AREA_SQM_SE",
          border.col = "gray60",
          border.lwd = 1) +
  tm_view(set.zoom.limits = c(11,14))

AREA_SQM_TV <- tm_shape(mpsz)+
  tm_polygons(alpha = 0.1) +
tm_shape(condo_resale.sf.adaptive) +  
  tm_dots(col = "AREA_SQM_TV",
          border.col = "gray60",
          border.lwd = 1) +
  tm_view(set.zoom.limits = c(11,14))

tmap_arrange(AREA_SQM_SE, AREA_SQM_TV, 
             asp=1, ncol=2,
             sync = TRUE)
```

```{r}
#| code-fold: true
#| code-summary: Show code

# visualise by URA Planning Region
tm_shape(mpsz[mpsz$REGION_N=="CENTRAL REGION", ])+
  tm_polygons()+
tm_shape(condo_resale.sf.adaptive) + 
  tm_bubbles(col = "Local_R2",
           size = 0.15,
           border.col = "gray60",
           border.lwd = 1)
```
